{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing Version with one row per author:\n",
    "\n",
    "### Features (as in paper):\n",
    "1. 11.140 ngram features: tf and tf-idf weighted word and character ngrams stemmed with Porter's stemmer\n",
    "2. type-token ratio\n",
    "3. ratio of comments in English\n",
    "4. ratio of British english vs. American English words\n",
    "5. 93 features from LIWC \n",
    "6. 26 PSYCH features (Preotiuc: Paraphrase Database and MRC Psycholinguistics Database)\n",
    "\n",
    "### Columns (from the description of the dataset):\n",
    "1. 'global':[7,10], #subreddits_commented, subreddits_commented_mbti, num_comments\n",
    "2. 'liwc':[10,103], #liwc\n",
    "3. 'word':[103,3938], #top1000 word ngram (1,2,3) per dimension based on chi2\n",
    "4. 'char':[3938,7243], #top1000 char ngrams (2,3) per dimension based on chi2\n",
    "5. 'sub':[7243,12228], #number of comments in each subreddit\n",
    "6. 'ent':[12228,12229], #entropy\n",
    "7. 'subtf':[12229,17214], #tf-idf on subreddits\n",
    "8. 'subcat':[17214,17249], #manually crafted subreddit categories\n",
    "9. 'lda50':[17249,17299], #50 LDA topics\n",
    "10. 'posts':[17299,17319], #posts statistics\n",
    "11. 'lda100':[17319,17419], #100 LDA topics\n",
    "12. 'psy':[17419,17443], #psycholinguistic features\n",
    "13. 'en':[17443,17444], #ratio of english comments\n",
    "14. 'ttr':[17444,17445], #type token ratio\n",
    "15. 'meaning':[17445,17447], #additional pyscholinguistic features\n",
    "16. 'time_diffs':[17447,17453], #commenting time diffs\n",
    "17. 'month':[17453,17465], #monthly distribution\n",
    "18. 'hour':[17465,17489], #hourly distribution\n",
    "19. 'day_of_week':[17489,17496], #daily distribution\n",
    "20. 'word_an':[17496,21496], #word ngrams selected by F-score\n",
    "21. 'word_an_tf':[21496,25496], #tf-idf ngrams selected by F-score\n",
    "22. 'char_an':[25496,29496], #char ngrams selected by F-score\n",
    "23. 'char_an_tf':[29496,33496], #tf-idf char ngrams selected by F-score\n",
    "24. 'brit_amer':[33496,33499], #british vs american english ratio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/sophia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/sophia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/sophia/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package tagsets to /home/sophia/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# import ssl\n",
    "\n",
    "# try:\n",
    "#     _create_unverified_https_context = ssl._create_unverified_context\n",
    "# except AttributeError:\n",
    "#     pass\n",
    "# else:\n",
    "#     ssl._create_default_https_context = _create_unverified_https_context\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('tagsets')\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.util import bigrams, ngrams\n",
    "import re\n",
    "import string\n",
    "from string import punctuation\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from collections import Counter\n",
    "from num2words import num2words \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import datetime\n",
    "import random\n",
    "random.seed(32)\n",
    "\n",
    "# close nltk download window to continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>body</th>\n",
       "      <th>downs</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>score</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>gilded</th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>ups</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_count_quoteless</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sabata11792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not seeing any break or signal lights and no p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1534890968</td>\n",
       "      <td>t5_3fqup</td>\n",
       "      <td>t3_995l9s</td>\n",
       "      <td>t1_e4lbrls</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>e4lkg2l</td>\n",
       "      <td>ATBGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Swarels</td>\n",
       "      <td>INTP</td>\n",
       "      <td>Multiverses, matrix theory, consciousness. Scr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1499749893</td>\n",
       "      <td>t5_2qhvl</td>\n",
       "      <td>t3_6mjw62</td>\n",
       "      <td>t1_dk26jre</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dk26vpo</td>\n",
       "      <td>INTP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>46</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pearlz176</td>\n",
       "      <td>Manchester United</td>\n",
       "      <td>Hope you've enjoyed the ride :D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1485613795</td>\n",
       "      <td>t5_2qi58</td>\n",
       "      <td>t3_5qnd1v</td>\n",
       "      <td>t1_dd0mdqg</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dd0nxif</td>\n",
       "      <td>soccer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rainbowhotpocket</td>\n",
       "      <td>Colts</td>\n",
       "      <td>Idk, in the AFC if i recall correctly since 20...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1466965660</td>\n",
       "      <td>t5_2qmg3</td>\n",
       "      <td>t3_4pypuh</td>\n",
       "      <td>t1_d4oulvo</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d4our0i</td>\n",
       "      <td>nfl</td>\n",
       "      <td>11.0</td>\n",
       "      <td>62</td>\n",
       "      <td>61</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amathyx</td>\n",
       "      <td>http://myanimelist.net/profile/amathy</td>\n",
       "      <td>22 hours later and the music is still going[co...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1495851189</td>\n",
       "      <td>t5_2qh22</td>\n",
       "      <td>t3_6ddiow</td>\n",
       "      <td>t3_6ddiow</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>di3inz7</td>\n",
       "      <td>anime</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>29</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>AureliusPendragon</td>\n",
       "      <td>�� You are your dragon. Slay yourself.</td>\n",
       "      <td>Fair enough.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1511890614</td>\n",
       "      <td>t5_32jqy</td>\n",
       "      <td>t3_7g4acj</td>\n",
       "      <td>t1_dqgo961</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dqgonrb</td>\n",
       "      <td>JordanPeterson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>ksvr</td>\n",
       "      <td>Bengals</td>\n",
       "      <td>maybe him and Marvin Lewis have the same secre...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1481133329</td>\n",
       "      <td>t5_2qmg3</td>\n",
       "      <td>t3_5h055f</td>\n",
       "      <td>t1_dawe1yo</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dawlszw</td>\n",
       "      <td>nfl</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>vipertongn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>how would you flash the kernel using stock rom...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1470043422</td>\n",
       "      <td>t5_39zt6</td>\n",
       "      <td>t3_4vk0ch</td>\n",
       "      <td>t1_d5z2og3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d5ze762</td>\n",
       "      <td>Nexus6P</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>lordoftheslums</td>\n",
       "      <td>Bulls</td>\n",
       "      <td>Which ever one of the Bulls/Celtics first roun...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1450723952</td>\n",
       "      <td>t5_2qo4s</td>\n",
       "      <td>t3_3xot3k</td>\n",
       "      <td>t3_3xot3k</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cy6ukte</td>\n",
       "      <td>nba</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>HellhoundsOnMyTrail</td>\n",
       "      <td>prototypical non-conformist</td>\n",
       "      <td>Obviously unstable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1467132062</td>\n",
       "      <td>t5_2rct2</td>\n",
       "      <td>t3_4qab38</td>\n",
       "      <td>t1_d4rdk6k</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d4rdn40</td>\n",
       "      <td>OkCupid</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  author                       author_flair_text  \\\n",
       "0            Sabata11792                                     NaN   \n",
       "1                Swarels                                    INTP   \n",
       "2              pearlz176                       Manchester United   \n",
       "3       rainbowhotpocket                                   Colts   \n",
       "4                amathyx   http://myanimelist.net/profile/amathy   \n",
       "..                   ...                                     ...   \n",
       "995    AureliusPendragon  �� You are your dragon. Slay yourself.   \n",
       "996                 ksvr                                 Bengals   \n",
       "997           vipertongn                                     NaN   \n",
       "998       lordoftheslums                                   Bulls   \n",
       "999  HellhoundsOnMyTrail             prototypical non-conformist   \n",
       "\n",
       "                                                  body  downs  created_utc  \\\n",
       "0    Not seeing any break or signal lights and no p...    NaN   1534890968   \n",
       "1    Multiverses, matrix theory, consciousness. Scr...    NaN   1499749893   \n",
       "2                      Hope you've enjoyed the ride :D    NaN   1485613795   \n",
       "3    Idk, in the AFC if i recall correctly since 20...    NaN   1466965660   \n",
       "4    22 hours later and the music is still going[co...    NaN   1495851189   \n",
       "..                                                 ...    ...          ...   \n",
       "995                                       Fair enough.    NaN   1511890614   \n",
       "996  maybe him and Marvin Lewis have the same secre...    0.0   1481133329   \n",
       "997  how would you flash the kernel using stock rom...    NaN   1470043422   \n",
       "998  Which ever one of the Bulls/Celtics first roun...    NaN   1450723952   \n",
       "999                                 Obviously unstable    NaN   1467132062   \n",
       "\n",
       "    subreddit_id    link_id   parent_id  score  controversiality  gilded  \\\n",
       "0       t5_3fqup  t3_995l9s  t1_e4lbrls    1.0                 0       0   \n",
       "1       t5_2qhvl  t3_6mjw62  t1_dk26jre    7.0                 0       0   \n",
       "2       t5_2qi58  t3_5qnd1v  t1_dd0mdqg    2.0                 0       0   \n",
       "3       t5_2qmg3  t3_4pypuh  t1_d4oulvo   11.0                 0       0   \n",
       "4       t5_2qh22  t3_6ddiow   t3_6ddiow    6.0                 0       0   \n",
       "..           ...        ...         ...    ...               ...     ...   \n",
       "995     t5_32jqy  t3_7g4acj  t1_dqgo961    2.0                 0       0   \n",
       "996     t5_2qmg3  t3_5h055f  t1_dawe1yo    1.0                 0       0   \n",
       "997     t5_39zt6  t3_4vk0ch  t1_d5z2og3    1.0                 0       0   \n",
       "998     t5_2qo4s  t3_3xot3k   t3_3xot3k    1.0                 0       0   \n",
       "999     t5_2rct2  t3_4qab38  t1_d4rdk6k    1.0                 0       0   \n",
       "\n",
       "          id       subreddit   ups  word_count  word_count_quoteless lang  \n",
       "0    e4lkg2l           ATBGE   NaN          19                    19   en  \n",
       "1    dk26vpo            INTP   NaN          51                    46   en  \n",
       "2    dd0nxif          soccer   NaN           6                     6   en  \n",
       "3    d4our0i             nfl  11.0          62                    61   en  \n",
       "4    di3inz7           anime   NaN          32                    29   en  \n",
       "..       ...             ...   ...         ...                   ...  ...  \n",
       "995  dqgonrb  JordanPeterson   NaN           2                     2   en  \n",
       "996  dawlszw             nfl   0.0          14                    14   en  \n",
       "997  d5ze762         Nexus6P   1.0          33                    32   en  \n",
       "998  cy6ukte             nba   1.0          32                    32   en  \n",
       "999  d4rdn40         OkCupid   1.0           2                     2   en  \n",
       "\n",
       "[1000 rows x 17 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/sophia/ma_py/pandora_bigfive1000.csv')\n",
    "# print(pandora.info(verbose=True))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change language to numeric representation\n",
    "def numeric_lang(df):\n",
    "    # change lang to numerical representation\n",
    "    language = df['lang'].values.tolist()\n",
    "    language = set(language)\n",
    "    language\n",
    "    df['language']= np.select([df.lang == 'en', df.lang == 'es', df.lang == 'nl'], \n",
    "                            [0, 1, 2], \n",
    "                            default=3)\n",
    "    # print(gramsdf['language'])\n",
    "    df = df.drop(columns=['lang'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>body</th>\n",
       "      <th>downs</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>score</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>...</th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>ups</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_count_quoteless</th>\n",
       "      <th>lang</th>\n",
       "      <th>time</th>\n",
       "      <th>weekday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sabata11792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not seeing any break or signal lights and no p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1534890968</td>\n",
       "      <td>t5_3fqup</td>\n",
       "      <td>t3_995l9s</td>\n",
       "      <td>t1_e4lbrls</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>e4lkg2l</td>\n",
       "      <td>ATBGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>en</td>\n",
       "      <td>2018-08-22T00:36:08</td>\n",
       "      <td>wednesday</td>\n",
       "      <td>08</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Swarels</td>\n",
       "      <td>INTP</td>\n",
       "      <td>Multiverses, matrix theory, consciousness. Scr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1499749893</td>\n",
       "      <td>t5_2qhvl</td>\n",
       "      <td>t3_6mjw62</td>\n",
       "      <td>t1_dk26jre</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>dk26vpo</td>\n",
       "      <td>INTP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>46</td>\n",
       "      <td>en</td>\n",
       "      <td>2017-07-11T07:11:33</td>\n",
       "      <td>tuesday</td>\n",
       "      <td>07</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pearlz176</td>\n",
       "      <td>Manchester United</td>\n",
       "      <td>Hope you've enjoyed the ride :D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1485613795</td>\n",
       "      <td>t5_2qi58</td>\n",
       "      <td>t3_5qnd1v</td>\n",
       "      <td>t1_dd0mdqg</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>dd0nxif</td>\n",
       "      <td>soccer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>en</td>\n",
       "      <td>2017-01-28T15:29:55</td>\n",
       "      <td>saturday</td>\n",
       "      <td>01</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rainbowhotpocket</td>\n",
       "      <td>Colts</td>\n",
       "      <td>Idk, in the AFC if i recall correctly since 20...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1466965660</td>\n",
       "      <td>t5_2qmg3</td>\n",
       "      <td>t3_4pypuh</td>\n",
       "      <td>t1_d4oulvo</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>d4our0i</td>\n",
       "      <td>nfl</td>\n",
       "      <td>11.0</td>\n",
       "      <td>62</td>\n",
       "      <td>61</td>\n",
       "      <td>en</td>\n",
       "      <td>2016-06-26T20:27:40</td>\n",
       "      <td>sunday</td>\n",
       "      <td>06</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amathyx</td>\n",
       "      <td>http://myanimelist.net/profile/amathy</td>\n",
       "      <td>22 hours later and the music is still going[co...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1495851189</td>\n",
       "      <td>t5_2qh22</td>\n",
       "      <td>t3_6ddiow</td>\n",
       "      <td>t3_6ddiow</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>di3inz7</td>\n",
       "      <td>anime</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>29</td>\n",
       "      <td>en</td>\n",
       "      <td>2017-05-27T04:13:09</td>\n",
       "      <td>saturday</td>\n",
       "      <td>05</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             author                      author_flair_text  \\\n",
       "0       Sabata11792                                    NaN   \n",
       "1           Swarels                                   INTP   \n",
       "2         pearlz176                      Manchester United   \n",
       "3  rainbowhotpocket                                  Colts   \n",
       "4           amathyx  http://myanimelist.net/profile/amathy   \n",
       "\n",
       "                                                body  downs  created_utc  \\\n",
       "0  Not seeing any break or signal lights and no p...    NaN   1534890968   \n",
       "1  Multiverses, matrix theory, consciousness. Scr...    NaN   1499749893   \n",
       "2                    Hope you've enjoyed the ride :D    NaN   1485613795   \n",
       "3  Idk, in the AFC if i recall correctly since 20...    NaN   1466965660   \n",
       "4  22 hours later and the music is still going[co...    NaN   1495851189   \n",
       "\n",
       "  subreddit_id    link_id   parent_id  score  controversiality  ...       id  \\\n",
       "0     t5_3fqup  t3_995l9s  t1_e4lbrls    1.0                 0  ...  e4lkg2l   \n",
       "1     t5_2qhvl  t3_6mjw62  t1_dk26jre    7.0                 0  ...  dk26vpo   \n",
       "2     t5_2qi58  t3_5qnd1v  t1_dd0mdqg    2.0                 0  ...  dd0nxif   \n",
       "3     t5_2qmg3  t3_4pypuh  t1_d4oulvo   11.0                 0  ...  d4our0i   \n",
       "4     t5_2qh22  t3_6ddiow   t3_6ddiow    6.0                 0  ...  di3inz7   \n",
       "\n",
       "  subreddit   ups  word_count  word_count_quoteless  lang  \\\n",
       "0     ATBGE   NaN          19                    19    en   \n",
       "1      INTP   NaN          51                    46    en   \n",
       "2    soccer   NaN           6                     6    en   \n",
       "3       nfl  11.0          62                    61    en   \n",
       "4     anime   NaN          32                    29    en   \n",
       "\n",
       "                  time    weekday month  year  \n",
       "0  2018-08-22T00:36:08  wednesday    08  2018  \n",
       "1  2017-07-11T07:11:33    tuesday    07  2017  \n",
       "2  2017-01-28T15:29:55   saturday    01  2017  \n",
       "3  2016-06-26T20:27:40     sunday    06  2016  \n",
       "4  2017-05-27T04:13:09   saturday    05  2017  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_timecolumns(df):\n",
    "    readable = []\n",
    "    weekday = []\n",
    "    month = []\n",
    "    year = []\n",
    "    for row in df['created_utc']:\n",
    "        item = datetime.datetime.fromtimestamp(row)\n",
    "        weekday_item = item.strftime('%A')\n",
    "        readable_item = datetime.datetime.fromtimestamp(row).isoformat()\n",
    "        month.append(str(readable_item[5:7]))\n",
    "        year.append(str(readable_item[0:4]))\n",
    "        readable.append(readable_item)\n",
    "        weekday.append(weekday_item.lower())\n",
    "    df['time'] = readable\n",
    "    df['weekday'] = weekday\n",
    "    df['month'] = month\n",
    "    df['year'] = year\n",
    "    return df\n",
    "\n",
    "pandora = create_timecolumns(df)\n",
    "pandora.head()\n",
    "# test = pandora.iloc[0]['time']\n",
    "# print(test)\n",
    "# print(test[0:4])\n",
    "# lst = pandora.weekday.tolist()\n",
    "# lstset = set(lst)\n",
    "# print(lstset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timecounter(lst, vocablst):\n",
    "    if vocablst == 'weekday':\n",
    "        vocab = ['monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday']\n",
    "    elif vocablst == 'month':\n",
    "        vocab = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "    elif vocablst == 'year':\n",
    "        vocab = ['2015', '2016', '2017', '2018', '2019']\n",
    "    else:\n",
    "        print(\"No valid input: vocab list\")\n",
    "    vectorizer = CountVectorizer(analyzer=\"word\", vocabulary=vocab)\n",
    "    vectors = vectorizer.fit_transform(lst)\n",
    "    v = vectors.toarray()\n",
    "#     is_all_zero = np.all((v == 0))\n",
    "#     names = vectorizer.get_feature_names()\n",
    "    return v\n",
    "\n",
    "# item = ['Sunday Tuesday']\n",
    "# print(item)\n",
    "# test = timecounter(item, 'weekday')\n",
    "# print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = df['subreddit'].tolist()\n",
    "lst = [item.lower() for item in lst]\n",
    "subredditset = set(lst)\n",
    "subredditlist = list(subredditset)\n",
    "\n",
    "def subredditcounter(lst, subredditlst):\n",
    "    vectorizer = CountVectorizer(analyzer=\"word\", vocabulary=subredditlist)\n",
    "    vectors = vectorizer.fit_transform(lst)\n",
    "    v = vectors.toarray()\n",
    "#     is_all_zero = np.all((v == 0))\n",
    "#     print(\"is all zero? \", is_all_zero)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>complete_body</th>\n",
       "      <th>doc_body</th>\n",
       "      <th>all_utc</th>\n",
       "      <th>mean_controversiality</th>\n",
       "      <th>mean_gilded</th>\n",
       "      <th>num_subreddits</th>\n",
       "      <th>subreddit_dist</th>\n",
       "      <th>weekday_dist</th>\n",
       "      <th>month_dist</th>\n",
       "      <th>year_dist</th>\n",
       "      <th>all_lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>-BigSexy-</td>\n",
       "      <td>Oooh i see</td>\n",
       "      <td>[Oooh i see]</td>\n",
       "      <td>[1510236798]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 1, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>-BlitzN9ne</td>\n",
       "      <td>**Quality** material right here</td>\n",
       "      <td>[**Quality** material right here]</td>\n",
       "      <td>[1549708109]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 1]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>-CrestiaBell</td>\n",
       "      <td>A slidewhistle or a meow-meow board That's bec...</td>\n",
       "      <td>[A slidewhistle or a meow-meow board, That's b...</td>\n",
       "      <td>[1538664591, 1475867279, 1505862626, 151267621...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 0, 1, 3, 2, 0, 0]</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 2]</td>\n",
       "      <td>[0, 2, 3, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>-tactical-throw-away</td>\n",
       "      <td>Sorry for your feelings. Kek &amp;lt;------- This ...</td>\n",
       "      <td>[Sorry for your feelings., Kek &amp;lt;------- Thi...</td>\n",
       "      <td>[1498536785, 1486701409, 1506834463]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 0, 0, 1, 0, 1]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>[0, 0, 3, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>137288</td>\n",
       "      <td>Carly's so glad to get your .0000003 cents Exc...</td>\n",
       "      <td>[Carly's so glad to get your .0000003 cents, E...</td>\n",
       "      <td>[1536611153, 1550537879, 1516548513, 1523299682]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[2, 1, 0, 0, 0, 0, 1]</td>\n",
       "      <td>[1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 3, 1]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>xanthraxoid</td>\n",
       "      <td>I'd really like this video to include some inf...</td>\n",
       "      <td>[I'd really like this video to include some in...</td>\n",
       "      <td>[1469892161, 1486826547, 1498046590, 1550346594]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 3, 0]</td>\n",
       "      <td>[0, 2, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 1, 2, 0, 1]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>xenomouse</td>\n",
       "      <td>You're a guy, aren't you? I can definitely see...</td>\n",
       "      <td>[You're a guy, aren't you? I can definitely se...</td>\n",
       "      <td>[1506710219, 1502740906, 1517847908, 1506874589]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[2, 0, 0, 0, 1, 0, 1]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0]</td>\n",
       "      <td>[0, 0, 3, 1, 0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>xeroctr3</td>\n",
       "      <td>man even the thought of it makes me depressed....</td>\n",
       "      <td>[man even the thought of it makes me depressed...</td>\n",
       "      <td>[1521414051]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>xzack18</td>\n",
       "      <td>Not all of us are out to kill</td>\n",
       "      <td>[Not all of us are out to kill]</td>\n",
       "      <td>[1533749569]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>zugzwang_03</td>\n",
       "      <td>Institutions should accommodate religious or s...</td>\n",
       "      <td>[Institutions should accommodate religious or ...</td>\n",
       "      <td>[1514216199, 1459000262, 1500701643, 151759545...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 0, 2, 0, 1, 2, 0]</td>\n",
       "      <td>[0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1]</td>\n",
       "      <td>[0, 3, 2, 1, 0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>429 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   author                                      complete_body  \\\n",
       "906             -BigSexy-                                         Oooh i see   \n",
       "145            -BlitzN9ne                    **Quality** material right here   \n",
       "367          -CrestiaBell  A slidewhistle or a meow-meow board That's bec...   \n",
       "295  -tactical-throw-away  Sorry for your feelings. Kek &lt;------- This ...   \n",
       "791                137288  Carly's so glad to get your .0000003 cents Exc...   \n",
       "..                    ...                                                ...   \n",
       "324           xanthraxoid  I'd really like this video to include some inf...   \n",
       "954             xenomouse  You're a guy, aren't you? I can definitely see...   \n",
       "208              xeroctr3  man even the thought of it makes me depressed....   \n",
       "990               xzack18                      Not all of us are out to kill   \n",
       "936           zugzwang_03  Institutions should accommodate religious or s...   \n",
       "\n",
       "                                              doc_body  \\\n",
       "906                                       [Oooh i see]   \n",
       "145                  [**Quality** material right here]   \n",
       "367  [A slidewhistle or a meow-meow board, That's b...   \n",
       "295  [Sorry for your feelings., Kek &lt;------- Thi...   \n",
       "791  [Carly's so glad to get your .0000003 cents, E...   \n",
       "..                                                 ...   \n",
       "324  [I'd really like this video to include some in...   \n",
       "954  [You're a guy, aren't you? I can definitely se...   \n",
       "208  [man even the thought of it makes me depressed...   \n",
       "990                    [Not all of us are out to kill]   \n",
       "936  [Institutions should accommodate religious or ...   \n",
       "\n",
       "                                               all_utc  mean_controversiality  \\\n",
       "906                                       [1510236798]                    0.0   \n",
       "145                                       [1549708109]                    0.0   \n",
       "367  [1538664591, 1475867279, 1505862626, 151267621...                    0.0   \n",
       "295               [1498536785, 1486701409, 1506834463]                    0.0   \n",
       "791   [1536611153, 1550537879, 1516548513, 1523299682]                    0.0   \n",
       "..                                                 ...                    ...   \n",
       "324   [1469892161, 1486826547, 1498046590, 1550346594]                    0.0   \n",
       "954   [1506710219, 1502740906, 1517847908, 1506874589]                    0.0   \n",
       "208                                       [1521414051]                    0.0   \n",
       "990                                       [1533749569]                    0.0   \n",
       "936  [1514216199, 1459000262, 1500701643, 151759545...                    0.0   \n",
       "\n",
       "     mean_gilded  num_subreddits  \\\n",
       "906          0.0               1   \n",
       "145          0.0               1   \n",
       "367          0.0               4   \n",
       "295          0.0               1   \n",
       "791          0.0               1   \n",
       "..           ...             ...   \n",
       "324          0.0               4   \n",
       "954          0.0               2   \n",
       "208          0.0               1   \n",
       "990          0.0               1   \n",
       "936          0.0               5   \n",
       "\n",
       "                                        subreddit_dist           weekday_dist  \\\n",
       "906  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [0, 0, 0, 1, 0, 0, 0]   \n",
       "145  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [0, 0, 0, 0, 0, 1, 0]   \n",
       "367  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [1, 0, 1, 3, 2, 0, 0]   \n",
       "295  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [0, 1, 0, 0, 1, 0, 1]   \n",
       "791  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [2, 1, 0, 0, 0, 0, 1]   \n",
       "..                                                 ...                    ...   \n",
       "324  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [0, 0, 1, 0, 0, 3, 0]   \n",
       "954  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [2, 0, 0, 0, 1, 0, 1]   \n",
       "208  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [1, 0, 0, 0, 0, 0, 0]   \n",
       "990  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [0, 0, 1, 0, 0, 0, 0]   \n",
       "936  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [1, 0, 2, 0, 1, 2, 0]   \n",
       "\n",
       "                               month_dist        year_dist  all_lang  \n",
       "906  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]  [0, 0, 1, 0, 0]         1  \n",
       "145  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  [0, 0, 0, 0, 1]         1  \n",
       "367  [1, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 2]  [0, 2, 3, 1, 1]         1  \n",
       "295  [0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0]  [0, 0, 3, 0, 0]         1  \n",
       "791  [1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0]  [0, 0, 0, 3, 1]         1  \n",
       "..                                    ...              ...       ...  \n",
       "324  [0, 2, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0]  [0, 1, 2, 0, 1]         2  \n",
       "954  [0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0]  [0, 0, 3, 1, 0]         1  \n",
       "208  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  [0, 0, 0, 1, 0]         1  \n",
       "990  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]  [0, 0, 0, 1, 0]         1  \n",
       "936  [0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1]  [0, 3, 2, 1, 0]         1  \n",
       "\n",
       "[429 rows x 12 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_authordf(df): \n",
    "    df = numeric_lang(df)\n",
    "    # body\n",
    "    df['complete_body'] = df.groupby(['author'])['body'].transform(lambda x : ' '. join(x))\n",
    "    df['doc_body'] = df.groupby(['author'])['body'].transform(lambda x : '§'. join(x))\n",
    "    df['doc_body'] =  df['doc_body'].apply(lambda x: x.split(\"§\"))\n",
    "    \n",
    "    # language\n",
    "    df['lang'] = df['language'].apply(lambda x: str(x))\n",
    "    df['all_lang'] = df.groupby(['author'])['lang'].transform(lambda x : len(set(x)))\n",
    "    # created_utc\n",
    "    df['utc_lst'] = df['created_utc'].apply(lambda x: str(x))\n",
    "    df['all_utc'] = df.groupby(['author'])['utc_lst'].transform(lambda x : ' '. join(x))\n",
    "    df['all_utc'] = df['all_utc'].apply(lambda x: x.split())\n",
    "    # controversiality\n",
    "    df['mean_controversiality'] = df.groupby(['author']).agg({'controversiality': ['mean']})\n",
    "    df['mean_controversiality'] = df['mean_controversiality'].fillna(0)\n",
    "    # gilded\n",
    "    df['mean_gilded'] = df.groupby(['author']).agg({'gilded': ['mean']})\n",
    "    df['mean_gilded'] = df['mean_gilded'].fillna(0)\n",
    "    # number of subreddits\n",
    "    df['num_subreddits'] = df.groupby(['author'])['subreddit'].transform(lambda x : ' '. join(x))\n",
    "    df['num_subreddits'] = df['num_subreddits'].apply(lambda x: len(set(x.split())))\n",
    "    # number of comments per subreddit\n",
    "    df['subreddit'] = df['subreddit'].apply(lambda x: [x.lower()])\n",
    "    df['subreddit'] = df['subreddit'].apply(lambda x: ''.join(x))\n",
    "    df['subreddit_dist'] = df.groupby(['author'])['subreddit'].transform(lambda x : ' '. join(x))\n",
    "    subreddit_predist = subredditcounter(df['subreddit'], subredditlist)\n",
    "    subreddit_predist = subreddit_predist.tolist()\n",
    "#     subreddit_arr = [np.array(lst) for lst in subreddit]\n",
    "    df['subreddit_dist'] = subreddit_predist\n",
    "    # time\n",
    "    df = create_timecolumns(df)\n",
    "    df['weekday_dist'] = df.groupby(['author'])['weekday'].transform(lambda x : ' '. join(x))\n",
    "    weekday = timecounter(df['weekday_dist'], 'weekday')\n",
    "    weekday = weekday.tolist()\n",
    "#     weekday_arr = [np.array(lst) for lst in weekday]\n",
    "    df['weekday_dist'] = weekday\n",
    "    df['month_dist'] = df.groupby(['author'])['month'].transform(lambda x : ' '. join(x))\n",
    "    month = timecounter(df['month_dist'], 'month')\n",
    "    month = month.tolist()\n",
    "    month_arr = [np.array(lst) for lst in month]\n",
    "    df['month_dist'] = month_arr\n",
    "    df['year_dist'] = df.groupby(['author'])['year'].transform(lambda x : ' '. join(x))\n",
    "    year = timecounter(df['year_dist'], 'year')\n",
    "    year = year.tolist()\n",
    "    year_arr = [np.array(lst) for lst in year]\n",
    "    df['year_dist'] = year_arr\n",
    "    \n",
    "    newdf = df[['author', 'complete_body', 'doc_body', 'all_utc', 'mean_controversiality', \n",
    "                'mean_gilded', 'num_subreddits', 'subreddit_dist', 'weekday_dist', \n",
    "                'month_dist', 'year_dist', 'all_lang']]\n",
    "    newdf = newdf.sort_values(by='author')\n",
    "    newdf = newdf.drop_duplicates(subset=['author'])\n",
    "    return newdf\n",
    "\n",
    "\n",
    "pandora = create_authordf(df)\n",
    "pandora\n",
    "# print(type(pandora.iloc[0]['subreddit_dist']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 429 entries, 906 to 936\n",
      "Data columns (total 12 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   author                 429 non-null    object \n",
      " 1   complete_body          429 non-null    object \n",
      " 2   doc_body               429 non-null    object \n",
      " 3   all_utc                429 non-null    object \n",
      " 4   mean_controversiality  429 non-null    float64\n",
      " 5   mean_gilded            429 non-null    float64\n",
      " 6   num_subreddits         429 non-null    int64  \n",
      " 7   subreddit_dist         429 non-null    object \n",
      " 8   weekday_dist           429 non-null    object \n",
      " 9   month_dist             429 non-null    object \n",
      " 10  year_dist              429 non-null    object \n",
      " 11  all_lang               429 non-null    int64  \n",
      "dtypes: float64(2), int64(2), object(8)\n",
      "memory usage: 43.6+ KB\n"
     ]
    }
   ],
   "source": [
    "pandora.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>complete_body</th>\n",
       "      <th>doc_body</th>\n",
       "      <th>all_utc</th>\n",
       "      <th>mean_controversiality</th>\n",
       "      <th>mean_gilded</th>\n",
       "      <th>num_subreddits</th>\n",
       "      <th>all_lang</th>\n",
       "      <th>monday</th>\n",
       "      <th>tuesday</th>\n",
       "      <th>...</th>\n",
       "      <th>tinder</th>\n",
       "      <th>tropicalweather</th>\n",
       "      <th>aftereffects</th>\n",
       "      <th>cfbofftopic</th>\n",
       "      <th>200yearsago</th>\n",
       "      <th>trashy</th>\n",
       "      <th>askscience</th>\n",
       "      <th>weakpots</th>\n",
       "      <th>infj</th>\n",
       "      <th>uvtrade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>-BigSexy-</td>\n",
       "      <td>Oooh i see</td>\n",
       "      <td>[Oooh i see]</td>\n",
       "      <td>[1510236798]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>-BlitzN9ne</td>\n",
       "      <td>**Quality** material right here</td>\n",
       "      <td>[**Quality** material right here]</td>\n",
       "      <td>[1549708109]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>-CrestiaBell</td>\n",
       "      <td>A slidewhistle or a meow-meow board That's bec...</td>\n",
       "      <td>[A slidewhistle or a meow-meow board, That's b...</td>\n",
       "      <td>[1538664591, 1475867279, 1505862626, 151267621...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>-tactical-throw-away</td>\n",
       "      <td>Sorry for your feelings. Kek &amp;lt;------- This ...</td>\n",
       "      <td>[Sorry for your feelings., Kek &amp;lt;------- Thi...</td>\n",
       "      <td>[1498536785, 1486701409, 1506834463]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>137288</td>\n",
       "      <td>Carly's so glad to get your .0000003 cents Exc...</td>\n",
       "      <td>[Carly's so glad to get your .0000003 cents, E...</td>\n",
       "      <td>[1536611153, 1550537879, 1516548513, 1523299682]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 463 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   author                                      complete_body  \\\n",
       "906             -BigSexy-                                         Oooh i see   \n",
       "145            -BlitzN9ne                    **Quality** material right here   \n",
       "367          -CrestiaBell  A slidewhistle or a meow-meow board That's bec...   \n",
       "295  -tactical-throw-away  Sorry for your feelings. Kek &lt;------- This ...   \n",
       "791                137288  Carly's so glad to get your .0000003 cents Exc...   \n",
       "\n",
       "                                              doc_body  \\\n",
       "906                                       [Oooh i see]   \n",
       "145                  [**Quality** material right here]   \n",
       "367  [A slidewhistle or a meow-meow board, That's b...   \n",
       "295  [Sorry for your feelings., Kek &lt;------- Thi...   \n",
       "791  [Carly's so glad to get your .0000003 cents, E...   \n",
       "\n",
       "                                               all_utc  mean_controversiality  \\\n",
       "906                                       [1510236798]                    0.0   \n",
       "145                                       [1549708109]                    0.0   \n",
       "367  [1538664591, 1475867279, 1505862626, 151267621...                    0.0   \n",
       "295               [1498536785, 1486701409, 1506834463]                    0.0   \n",
       "791   [1536611153, 1550537879, 1516548513, 1523299682]                    0.0   \n",
       "\n",
       "     mean_gilded  num_subreddits  all_lang  monday  tuesday  ...  tinder  \\\n",
       "906          0.0               1         1       0        0  ...       0   \n",
       "145          0.0               1         1       0        0  ...       0   \n",
       "367          0.0               4         1       1        0  ...       0   \n",
       "295          0.0               1         1       0        1  ...       0   \n",
       "791          0.0               1         1       2        1  ...       0   \n",
       "\n",
       "     tropicalweather  aftereffects  cfbofftopic  200yearsago  trashy  \\\n",
       "906                0             0            0            0       0   \n",
       "145                0             0            0            0       0   \n",
       "367                0             0            0            0       0   \n",
       "295                0             0            0            0       0   \n",
       "791                0             0            0            0       0   \n",
       "\n",
       "     askscience  weakpots  infj  uvtrade  \n",
       "906           0         0     0        0  \n",
       "145           0         0     0        0  \n",
       "367           0         0     0        0  \n",
       "295           0         0     0        0  \n",
       "791           0         0     0        0  \n",
       "\n",
       "[5 rows x 463 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekday = ['monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday']\n",
    "month = ['january', 'february', 'march', 'april', 'may', 'june', 'juli', 'august', 'september', 'october', 'november', 'december']\n",
    "year = ['2015', '2016', '2017', '2018', '2019']\n",
    "\n",
    "def onecolumnperdatapoint(df, column, namelist):\n",
    "    for i in range(len(namelist)):\n",
    "#         df[namelist[i]] = df[column].apply(lambda x:[row[i] for row in x])\n",
    "        df[namelist[i]] = df[column].apply(lambda x:[x[i]])\n",
    "        df[namelist[i]] = [item[0] for item in df[namelist[i]]]\n",
    "    return df\n",
    "\n",
    "pandora = onecolumnperdatapoint(pandora, 'weekday_dist', weekday)\n",
    "pandora = onecolumnperdatapoint(pandora, 'month_dist', month)\n",
    "pandora = onecolumnperdatapoint(pandora, 'year_dist', year)\n",
    "pandora = onecolumnperdatapoint(pandora, 'subreddit_dist', subredditlist)\n",
    "pandora.drop(['weekday_dist', 'month_dist', 'year_dist', 'subreddit_dist'], axis=1, inplace=True)\n",
    "pandora.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataframe:  422\n",
      "NaN in df?  False\n",
      "Sum of NaN in agreeableness 0\n",
      "Sum of NaN in openness 0\n",
      "Sum of NaN in conscientiousness 0\n",
      "Sum of NaN in extraversion 0\n",
      "Sum of NaN in neuroticism 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>author</th>\n",
       "      <th>complete_body</th>\n",
       "      <th>doc_body</th>\n",
       "      <th>all_utc</th>\n",
       "      <th>mean_controversiality</th>\n",
       "      <th>mean_gilded</th>\n",
       "      <th>num_subreddits</th>\n",
       "      <th>all_lang</th>\n",
       "      <th>monday</th>\n",
       "      <th>...</th>\n",
       "      <th>trashy</th>\n",
       "      <th>askscience</th>\n",
       "      <th>weakpots</th>\n",
       "      <th>infj</th>\n",
       "      <th>uvtrade</th>\n",
       "      <th>agreeableness</th>\n",
       "      <th>openness</th>\n",
       "      <th>conscientiousness</th>\n",
       "      <th>extraversion</th>\n",
       "      <th>neuroticism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-BigSexy-</td>\n",
       "      <td>Oooh i see</td>\n",
       "      <td>[Oooh i see]</td>\n",
       "      <td>[1510236798]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-BlitzN9ne</td>\n",
       "      <td>**Quality** material right here</td>\n",
       "      <td>[**Quality** material right here]</td>\n",
       "      <td>[1549708109]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-CrestiaBell</td>\n",
       "      <td>A slidewhistle or a meow-meow board That's bec...</td>\n",
       "      <td>[A slidewhistle or a meow-meow board, That's b...</td>\n",
       "      <td>[1538664591, 1475867279, 1505862626, 151267621...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-tactical-throw-away</td>\n",
       "      <td>Sorry for your feelings. Kek &amp;lt;------- This ...</td>\n",
       "      <td>[Sorry for your feelings., Kek &amp;lt;------- Thi...</td>\n",
       "      <td>[1498536785, 1486701409, 1506834463]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>137288</td>\n",
       "      <td>Carly's so glad to get your .0000003 cents Exc...</td>\n",
       "      <td>[Carly's so glad to get your .0000003 cents, E...</td>\n",
       "      <td>[1536611153, 1550537879, 1516548513, 1523299682]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>424</td>\n",
       "      <td>xanthraxoid</td>\n",
       "      <td>I'd really like this video to include some inf...</td>\n",
       "      <td>[I'd really like this video to include some in...</td>\n",
       "      <td>[1469892161, 1486826547, 1498046590, 1550346594]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>425</td>\n",
       "      <td>xenomouse</td>\n",
       "      <td>You're a guy, aren't you? I can definitely see...</td>\n",
       "      <td>[You're a guy, aren't you? I can definitely se...</td>\n",
       "      <td>[1506710219, 1502740906, 1517847908, 1506874589]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>426</td>\n",
       "      <td>xeroctr3</td>\n",
       "      <td>man even the thought of it makes me depressed....</td>\n",
       "      <td>[man even the thought of it makes me depressed...</td>\n",
       "      <td>[1521414051]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>427</td>\n",
       "      <td>xzack18</td>\n",
       "      <td>Not all of us are out to kill</td>\n",
       "      <td>[Not all of us are out to kill]</td>\n",
       "      <td>[1533749569]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>428</td>\n",
       "      <td>zugzwang_03</td>\n",
       "      <td>Institutions should accommodate religious or s...</td>\n",
       "      <td>[Institutions should accommodate religious or ...</td>\n",
       "      <td>[1514216199, 1459000262, 1500701643, 151759545...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>422 rows × 469 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                author  \\\n",
       "0        0             -BigSexy-   \n",
       "1        1            -BlitzN9ne   \n",
       "2        2          -CrestiaBell   \n",
       "3        3  -tactical-throw-away   \n",
       "4        4                137288   \n",
       "..     ...                   ...   \n",
       "417    424           xanthraxoid   \n",
       "418    425             xenomouse   \n",
       "419    426              xeroctr3   \n",
       "420    427               xzack18   \n",
       "421    428           zugzwang_03   \n",
       "\n",
       "                                         complete_body  \\\n",
       "0                                           Oooh i see   \n",
       "1                      **Quality** material right here   \n",
       "2    A slidewhistle or a meow-meow board That's bec...   \n",
       "3    Sorry for your feelings. Kek &lt;------- This ...   \n",
       "4    Carly's so glad to get your .0000003 cents Exc...   \n",
       "..                                                 ...   \n",
       "417  I'd really like this video to include some inf...   \n",
       "418  You're a guy, aren't you? I can definitely see...   \n",
       "419  man even the thought of it makes me depressed....   \n",
       "420                      Not all of us are out to kill   \n",
       "421  Institutions should accommodate religious or s...   \n",
       "\n",
       "                                              doc_body  \\\n",
       "0                                         [Oooh i see]   \n",
       "1                    [**Quality** material right here]   \n",
       "2    [A slidewhistle or a meow-meow board, That's b...   \n",
       "3    [Sorry for your feelings., Kek &lt;------- Thi...   \n",
       "4    [Carly's so glad to get your .0000003 cents, E...   \n",
       "..                                                 ...   \n",
       "417  [I'd really like this video to include some in...   \n",
       "418  [You're a guy, aren't you? I can definitely se...   \n",
       "419  [man even the thought of it makes me depressed...   \n",
       "420                    [Not all of us are out to kill]   \n",
       "421  [Institutions should accommodate religious or ...   \n",
       "\n",
       "                                               all_utc  mean_controversiality  \\\n",
       "0                                         [1510236798]                    0.0   \n",
       "1                                         [1549708109]                    0.0   \n",
       "2    [1538664591, 1475867279, 1505862626, 151267621...                    0.0   \n",
       "3                 [1498536785, 1486701409, 1506834463]                    0.0   \n",
       "4     [1536611153, 1550537879, 1516548513, 1523299682]                    0.0   \n",
       "..                                                 ...                    ...   \n",
       "417   [1469892161, 1486826547, 1498046590, 1550346594]                    0.0   \n",
       "418   [1506710219, 1502740906, 1517847908, 1506874589]                    0.0   \n",
       "419                                       [1521414051]                    0.0   \n",
       "420                                       [1533749569]                    0.0   \n",
       "421  [1514216199, 1459000262, 1500701643, 151759545...                    0.0   \n",
       "\n",
       "     mean_gilded  num_subreddits  all_lang  monday  ...  trashy  askscience  \\\n",
       "0            0.0               1         1       0  ...       0           0   \n",
       "1            0.0               1         1       0  ...       0           0   \n",
       "2            0.0               4         1       1  ...       0           0   \n",
       "3            0.0               1         1       0  ...       0           0   \n",
       "4            0.0               1         1       2  ...       0           0   \n",
       "..           ...             ...       ...     ...  ...     ...         ...   \n",
       "417          0.0               4         2       0  ...       0           0   \n",
       "418          0.0               2         1       2  ...       0           0   \n",
       "419          0.0               1         1       1  ...       0           0   \n",
       "420          0.0               1         1       0  ...       0           0   \n",
       "421          0.0               5         1       1  ...       0           0   \n",
       "\n",
       "     weakpots  infj  uvtrade  agreeableness  openness  conscientiousness  \\\n",
       "0           0     0        0           39.0      92.0                1.0   \n",
       "1           0     0        0           50.0      85.0               15.0   \n",
       "2           0     0        0           50.0      85.0               50.0   \n",
       "3           0     0        0            2.0      92.0               31.0   \n",
       "4           0     0        0           10.0      87.0               49.0   \n",
       "..        ...   ...      ...            ...       ...                ...   \n",
       "417         0     0        0           86.0      45.0                8.0   \n",
       "418         0     1        0           26.0      93.0               49.0   \n",
       "419         0     0        0            3.0      75.0               27.0   \n",
       "420         0     0        0            4.0      19.0               11.0   \n",
       "421         0     0        0           10.0      41.0               86.0   \n",
       "\n",
       "     extraversion  neuroticism  \n",
       "0            18.0          4.0  \n",
       "1            50.0         30.0  \n",
       "2            85.0         50.0  \n",
       "3            60.0         53.0  \n",
       "4             7.0         87.0  \n",
       "..            ...          ...  \n",
       "417          62.0         72.0  \n",
       "418          70.0         16.0  \n",
       "419           3.0         77.0  \n",
       "420          27.0         16.0  \n",
       "421          83.0         18.0  \n",
       "\n",
       "[422 rows x 469 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors = pd.read_csv('/home/sophia/ma_py/author_profiles.csv')\n",
    "# find missing data in big five traits\n",
    "# authorslst = authors['author'].tolist()\n",
    "# print(\"Author search: \", 'DarthHedonist' in authorslst)\n",
    "# print(\"Author search: \", 'FonsoTheWhitesican' in authorslst)\n",
    "# print(\"Author search: \", 'chaosking121' in authorslst)\n",
    "\n",
    "bigfive = authors[['author','agreeableness','openness','conscientiousness','extraversion','neuroticism']]\n",
    "bigfive = bigfive.dropna()\n",
    "# print(bigfive[bigfive['author'] == \"DarthHedonist\"])\n",
    "\n",
    "# pandoradf = pd.merge(pandora, bigfive, how='left', on='author')\n",
    "pandoradf = pandora.merge(bigfive, how='left', on=['author'])\n",
    "# pandoradf = pandoradf.dropna()\n",
    "pandoradf = pandoradf.sort_values(by='author')\n",
    "pandoradf = pandoradf[pandoradf['agreeableness'].notna()]\n",
    "pandoradf = pandoradf.reset_index()\n",
    "\n",
    "\n",
    "print(\"Length of dataframe: \", len(pandoradf))\n",
    "print(\"NaN in df? \", pandoradf.isnull().any().any())\n",
    "print(\"Sum of NaN in agreeableness\", pandoradf['agreeableness'].isnull().values.sum())\n",
    "print(\"Sum of NaN in openness\", pandoradf['openness'].isnull().values.sum())\n",
    "print(\"Sum of NaN in conscientiousness\", pandoradf['conscientiousness'].isnull().values.sum())\n",
    "print(\"Sum of NaN in extraversion\", pandoradf['extraversion'].isnull().values.sum())\n",
    "print(\"Sum of NaN in neuroticism\", pandoradf['neuroticism'].isnull().values.sum())\n",
    "# nan_values = pandoradf[pandoradf['neuroticism'].isna()]\n",
    "# nan_values\n",
    "pandoradf\n",
    "# pandoradf[pandoradf.isnull().any(axis=1)]\n",
    "\n",
    "# number of entries does not fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 422 entries, 0 to 421\n",
      "Data columns (total 469 columns):\n",
      " #    Column                 Dtype  \n",
      "---   ------                 -----  \n",
      " 0    index                  int64  \n",
      " 1    author                 object \n",
      " 2    complete_body          object \n",
      " 3    doc_body               object \n",
      " 4    all_utc                object \n",
      " 5    mean_controversiality  float64\n",
      " 6    mean_gilded            float64\n",
      " 7    num_subreddits         int64  \n",
      " 8    all_lang               int64  \n",
      " 9    monday                 int64  \n",
      " 10   tuesday                int64  \n",
      " 11   wednesday              int64  \n",
      " 12   thursday               int64  \n",
      " 13   friday                 int64  \n",
      " 14   saturday               int64  \n",
      " 15   sunday                 int64  \n",
      " 16   january                int64  \n",
      " 17   february               int64  \n",
      " 18   march                  int64  \n",
      " 19   april                  int64  \n",
      " 20   may                    int64  \n",
      " 21   june                   int64  \n",
      " 22   juli                   int64  \n",
      " 23   august                 int64  \n",
      " 24   september              int64  \n",
      " 25   october                int64  \n",
      " 26   november               int64  \n",
      " 27   december               int64  \n",
      " 28   2015                   int64  \n",
      " 29   2016                   int64  \n",
      " 30   2017                   int64  \n",
      " 31   2018                   int64  \n",
      " 32   2019                   int64  \n",
      " 33   scifi                  int64  \n",
      " 34   solutiongambling       int64  \n",
      " 35   bdsmcommunity          int64  \n",
      " 36   ethtrader              int64  \n",
      " 37   muacirclejerk          int64  \n",
      " 38   raisedbyborderlines    int64  \n",
      " 39   amiibo                 int64  \n",
      " 40   ratemymayor            int64  \n",
      " 41   cringe                 int64  \n",
      " 42   lifeprotips            int64  \n",
      " 43   mmorpg                 int64  \n",
      " 44   bloodborne             int64  \n",
      " 45   videos                 int64  \n",
      " 46   designerreps           int64  \n",
      " 47   technology             int64  \n",
      " 48   personalfinance        int64  \n",
      " 49   fo4                    int64  \n",
      " 50   teenagers              int64  \n",
      " 51   wishlist               int64  \n",
      " 52   science                int64  \n",
      " 53   lgg3                   int64  \n",
      " 54   casualconversation     int64  \n",
      " 55   grandorder             int64  \n",
      " 56   starterpacks           int64  \n",
      " 57   buildapcsales          int64  \n",
      " 58   datingoverthirty       int64  \n",
      " 59   liberalgunowners       int64  \n",
      " 60   estp                   int64  \n",
      " 61   elderscrollsonline     int64  \n",
      " 62   pokemongouk            int64  \n",
      " 63   dccomics               int64  \n",
      " 64   mobiusff               int64  \n",
      " 65   taylorswift            int64  \n",
      " 66   starcitizen            int64  \n",
      " 67   infp                   int64  \n",
      " 68   magictcg               int64  \n",
      " 69   mhocstrangersbar       int64  \n",
      " 70   manga                  int64  \n",
      " 71   ranmelectionverify     int64  \n",
      " 72   choosingbeggars        int64  \n",
      " 73   edc                    int64  \n",
      " 74   tf2                    int64  \n",
      " 75   mlplounge              int64  \n",
      " 76   gamingsuggestions      int64  \n",
      " 77   mhocmeta               int64  \n",
      " 78   pcgaming               int64  \n",
      " 79   interestingasfuck      int64  \n",
      " 80   askouija               int64  \n",
      " 81   neoliberal             int64  \n",
      " 82   schizoid               int64  \n",
      " 83   cringeanarchy          int64  \n",
      " 84   apple                  int64  \n",
      " 85   nootropics             int64  \n",
      " 86   pubgmobile             int64  \n",
      " 87   intresseklubben        int64  \n",
      " 88   thewalkingdead         int64  \n",
      " 89   the_donald             int64  \n",
      " 90   assassinscreed         int64  \n",
      " 91   thebachelor            int64  \n",
      " 92   enneagram              int64  \n",
      " 93   justcause              int64  \n",
      " 94   england                int64  \n",
      " 95   bullcity               int64  \n",
      " 96   puzzleanddragons       int64  \n",
      " 97   thevoice               int64  \n",
      " 98   mhocpress              int64  \n",
      " 99   habs                   int64  \n",
      " 100  techsupport            int64  \n",
      " 101  mhocedm                int64  \n",
      " 102  crackstatus            int64  \n",
      " 103  funny                  int64  \n",
      " 104  wearethemusicmakers    int64  \n",
      " 105  gso                    int64  \n",
      " 106  writing                int64  \n",
      " 107  drugs                  int64  \n",
      " 108  excel                  int64  \n",
      " 109  vaporents              int64  \n",
      " 110  korea                  int64  \n",
      " 111  dota2                  int64  \n",
      " 112  bangtan                int64  \n",
      " 113  foreverunwanted        int64  \n",
      " 114  weddingsunder10k       int64  \n",
      " 115  anime                  int64  \n",
      " 116  circlebroke2           int64  \n",
      " 117  nintendo               int64  \n",
      " 118  ffbraveexvius          int64  \n",
      " 119  ottawa                 int64  \n",
      " 120  starcraft              int64  \n",
      " 121  relationship_advice    int64  \n",
      " 122  whatisthisthing        int64  \n",
      " 123  sociopath              int64  \n",
      " 124  mhocmp                 int64  \n",
      " 125  entp                   int64  \n",
      " 126  tipofmyjoystick        int64  \n",
      " 127  premiere               int64  \n",
      " 128  realestate             int64  \n",
      " 129  pathofexile            int64  \n",
      " 130  popheads               int64  \n",
      " 131  slatestarcodex         int64  \n",
      " 132  tennis                 int64  \n",
      " 133  dishonored             int64  \n",
      " 134  cfb                    int64  \n",
      " 135  xboxone                int64  \n",
      " 136  linkinpark             int64  \n",
      " 137  progresspics           int64  \n",
      " 138  battlefront            int64  \n",
      " 139  nofap                  int64  \n",
      " 140  fantasyfootball        int64  \n",
      " 141  askwomenadvice         int64  \n",
      " 142  business               int64  \n",
      " 143  programming            int64  \n",
      " 144  leagueoflegends        int64  \n",
      " 145  manga_collection       int64  \n",
      " 146  secularbuddhism        int64  \n",
      " 147  ssbpm                  int64  \n",
      " 148  intj                   int64  \n",
      " 149  mbti                   int64  \n",
      " 150  short                  int64  \n",
      " 151  demotivational         int64  \n",
      " 152  voteblue               int64  \n",
      " 153  funkopop               int64  \n",
      " 154  mma                    int64  \n",
      " 155  entrepreneur           int64  \n",
      " 156  n64                    int64  \n",
      " 157  smashbros              int64  \n",
      " 158  comedycemetery         int64  \n",
      " 159  orthodoxchristianity   int64  \n",
      " 160  mhocholyrood           int64  \n",
      " 161  pcmasterrace           int64  \n",
      " 162  loseit                 int64  \n",
      " 163  avpd                   int64  \n",
      " 164  fpga                   int64  \n",
      " 165  4chan                  int64  \n",
      " 166  ootp                   int64  \n",
      " 167  waltonchain            int64  \n",
      " 168  osx                    int64  \n",
      " 169  halo                   int64  \n",
      " 170  news                   int64  \n",
      " 171  fatlogic               int64  \n",
      " 172  freefolk               int64  \n",
      " 173  delaware               int64  \n",
      " 174  bikinibottomtwitter    int64  \n",
      " 175  paradoxplaza           int64  \n",
      " 176  friendsafari           int64  \n",
      " 177  shittyfoodporn         int64  \n",
      " 178  balisong               int64  \n",
      " 179  2007scape              int64  \n",
      " 180  denmark                int64  \n",
      " 181  boxing                 int64  \n",
      " 182  startledcats           int64  \n",
      " 183  edmonton               int64  \n",
      " 184  askreddit              int64  \n",
      " 185  learnicelandic         int64  \n",
      " 186  languagelearning       int64  \n",
      " 187  ukpolitics             int64  \n",
      " 188  dodgers                int64  \n",
      " 189  danganronpa            int64  \n",
      " 190  sexsells               int64  \n",
      " 191  watches                int64  \n",
      " 192  waltdisneyworld        int64  \n",
      " 193  frugal                 int64  \n",
      " 194  samharris              int64  \n",
      " 195  australianmakeup       int64  \n",
      " 196  formula1               int64  \n",
      " 197  subredditdrama         int64  \n",
      " 198  navyseals              int64  \n",
      " 199  electricdaisycarnival  int64  \n",
      " 200  fitness                int64  \n",
      " 201  joerogan               int64  \n",
      " 202  politicaldiscussion    int64  \n",
      " 203  changemyview           int64  \n",
      " 204  learnmath              int64  \n",
      " 205  jungiantypology        int64  \n",
      " 206  wwii                   int64  \n",
      " 207  jordan_peterson_memes  int64  \n",
      " 208  rupaulsdragrace        int64  \n",
      " 209  nirvana                int64  \n",
      " 210  rottweiler             int64  \n",
      " 211  mstormont              int64  \n",
      " 212  conspiracy             int64  \n",
      " 213  pokemon                int64  \n",
      " 214  schizophrenia          int64  \n",
      " 215  mls                    int64  \n",
      " 216  hockey                 int64  \n",
      " 217  bjj                    int64  \n",
      " 218  nomansskythegame       int64  \n",
      " 219  raspberry_pi           int64  \n",
      " 220  ipad                   int64  \n",
      " 221  canadapolitics         int64  \n",
      " 222  meditation             int64  \n",
      " 223  detroit                int64  \n",
      " 224  depression             int64  \n",
      " 225  budgetfood             int64  \n",
      " 226  homebrewing            int64  \n",
      " 227  harrypotter            int64  \n",
      " 228  tinytower              int64  \n",
      " 229  bible                  int64  \n",
      " 230  glitch_in_the_matrix   int64  \n",
      " 231  atbge                  int64  \n",
      " 232  fantasybaseball        int64  \n",
      " 233  borderlands            int64  \n",
      " 234  overwatch              int64  \n",
      " 235  askwomen               int64  \n",
      " 236  squaredcircle          int64  \n",
      " 237  colts                  int64  \n",
      " 238  thecapitolclub         int64  \n",
      " 239  unethicallifeprotips   int64  \n",
      " 240  android                int64  \n",
      " 241  guildwars2             int64  \n",
      " 242  nostalgia              int64  \n",
      " 243  marijuana              int64  \n",
      " 244  dnd                    int64  \n",
      " 245  r4r                    int64  \n",
      " 246  whitesox               int64  \n",
      " 247  mentalhealth           int64  \n",
      " 248  naruto                 int64  \n",
      " 249  minecraftsuggestions   int64  \n",
      " 250  seriousconversation    int64  \n",
      " 251  gameofthrones          int64  \n",
      " 252  whatstheword           int64  \n",
      " 253  vitapiracy             int64  \n",
      " 254  anxiety                int64  \n",
      " 255  actrade                int64  \n",
      " 256  gendercritical         int64  \n",
      " 257  kotakuinaction         int64  \n",
      " 258  askeurope              int64  \n",
      " 259  wtf                    int64  \n",
      " 260  tumblrinaction         int64  \n",
      " 261  mindhunter             int64  \n",
      " 262  nba                    int64  \n",
      " 263  liverpoolfc            int64  \n",
      " 264  watchpeopledie         int64  \n",
      " 265  handstyles             int64  \n",
      " 266  incels                 int64  \n",
      " 267  politics               int64  \n",
      " 268  aspergers              int64  \n",
      " 269  occult                 int64  \n",
      " 270  riverdale              int64  \n",
      " 271  nationals              int64  \n",
      " 272  soccer                 int64  \n",
      " 273  ocd                    int64  \n",
      " 274  lifetimelittlewomen    int64  \n",
      " 275  food                   int64  \n",
      " 276  lgbt                   int64  \n",
      " 277  persona5               int64  \n",
      " 278  trollychromosome       int64  \n",
      " 279  scotland               int64  \n",
      " 280  ffxiv                  int64  \n",
      " 281  niceguys               int64  \n",
      " 282  monsterhunterworld     int64  \n",
      " 283  terraria               int64  \n",
      " 284  lifeisstrange          int64  \n",
      " 285  washingtonwizards      int64  \n",
      " 286  woahdude               int64  \n",
      " 287  chineselanguage        int64  \n",
      " 288  jordanpeterson         int64  \n",
      " 289  sketchdaily            int64  \n",
      " 290  tifu                   int64  \n",
      " 291  italy                  int64  \n",
      " 292  random_acts_of_amazon  int64  \n",
      " 293  iama                   int64  \n",
      " 294  blackpeopletwitter     int64  \n",
      " 295  hacking                int64  \n",
      " 296  supernatural           int64  \n",
      " 297  adhd                   int64  \n",
      " 298  books                  int64  \n",
      " 299  publicfreakout         int64  \n",
      " 300  tipofmytongue          int64  \n",
      " 301  boardgames             int64  \n",
      " 302  ck2gameofthrones       int64  \n",
      " 303  nfl                    int64  \n",
      " 304  gaymers                int64  \n",
      " 305  deathgrips             int64  \n",
      " 306  philosophy             int64  \n",
      " 307  nexus6p                int64  \n",
      " 308  drama                  int64  \n",
      " 309  songwriters            int64  \n",
      " 310  oopsdidntmeanto        int64  \n",
      " 311  capitalismvsocialism   int64  \n",
      " 312  youtubehaiku           int64  \n",
      " 313  bigbrother             int64  \n",
      " 314  raisedbynarcissists    int64  \n",
      " 315  askmen                 int64  \n",
      " 316  collegebaseball        int64  \n",
      " 317  television             int64  \n",
      " 318  purplepilldebate       int64  \n",
      " 319  mylittlepony           int64  \n",
      " 320  oregairusnafu          int64  \n",
      " 321  anythinggoesnews       int64  \n",
      " 322  angola                 int64  \n",
      " 323  cfl                    int64  \n",
      " 324  todayilearned          int64  \n",
      " 325  foodforthought         int64  \n",
      " 326  randomactsofgaming     int64  \n",
      " 327  xwingtmg               int64  \n",
      " 328  art                    int64  \n",
      " 329  mildlyinteresting      int64  \n",
      " 330  deadbedrooms           int64  \n",
      " 331  oldschoolcool          int64  \n",
      " 332  conservativemeta       int64  \n",
      " 333  the_farage             int64  \n",
      " 334  spicy                  int64  \n",
      " 335  sevenkingdoms          int64  \n",
      " 336  trollxchromosomes      int64  \n",
      " 337  coldwarpowers          int64  \n",
      " 338  bisexual               int64  \n",
      " 339  ironthronepowers       int64  \n",
      " 340  femradebates           int64  \n",
      " 341  bindingofisaac         int64  \n",
      " 342  ladybonersgw           int64  \n",
      " 343  twobestfriendsplay     int64  \n",
      " 344  relationships          int64  \n",
      " 345  gatekeeping            int64  \n",
      " 346  futurology             int64  \n",
      " 347  mariomaker             int64  \n",
      " 348  hookah                 int64  \n",
      " 349  askanamerican          int64  \n",
      " 350  rocketleague           int64  \n",
      " 351  movies                 int64  \n",
      " 352  wholesomememes         int64  \n",
      " 353  pics                   int64  \n",
      " 354  fullcommunism          int64  \n",
      " 355  darksouls              int64  \n",
      " 356  wow                    int64  \n",
      " 357  rarepuppers            int64  \n",
      " 358  fnafcringe             int64  \n",
      " 359  sexover30              int64  \n",
      " 360  europe                 int64  \n",
      " 361  worldnews              int64  \n",
      " 362  askacademia            int64  \n",
      " 363  smite                  int64  \n",
      " 364  scp                    int64  \n",
      " 365  theworldisflat         int64  \n",
      " 366  kcroyals               int64  \n",
      " 367  tuckedinkitties        int64  \n",
      " 368  clashroyale            int64  \n",
      " 369  sidehugs               int64  \n",
      " 370  imdbfilmgeneral        int64  \n",
      " 371  learnjapanese          int64  \n",
      " 372  adviceanimals          int64  \n",
      " 373  gifs                   int64  \n",
      " 374  webdev                 int64  \n",
      " 375  celebs                 int64  \n",
      " 376  femalefashionadvice    int64  \n",
      " 377  castleclash            int64  \n",
      " 378  australia              int64  \n",
      " 379  fantasy                int64  \n",
      " 380  asexuality             int64  \n",
      " 381  stupidpol              int64  \n",
      " 382  sandersforpresident    int64  \n",
      " 383  collapse               int64  \n",
      " 384  dndnext                int64  \n",
      " 385  enfp                   int64  \n",
      " 386  childfree              int64  \n",
      " 387  mtf                    int64  \n",
      " 388  bythemods              int64  \n",
      " 389  wouldyourather         int64  \n",
      " 390  battlefront2           int64  \n",
      " 391  reddevils              int64  \n",
      " 392  okcupid                int64  \n",
      " 393  starwarsbattlefront    int64  \n",
      " 394  jokes                  int64  \n",
      " 395  gaming                 int64  \n",
      " 396  ratemyaudio            int64  \n",
      " 397  thefighterandthekid    int64  \n",
      " 398  canada                 int64  \n",
      " 399  tinyhouses             int64  \n",
      " 400  explainlikeimfive      int64  \n",
      " 401  nygiants               int64  \n",
      " 402  electronic_cigarette   int64  \n",
      " 403  needafriend            int64  \n",
      " 404  unpopularopinion       int64  \n",
      " 405  creepy                 int64  \n",
      " 406  darksouls3             int64  \n",
      " 407  xbox                   int64  \n",
      " 408  edh                    int64  \n",
      " 409  ukpersonalfinance      int64  \n",
      " 410  baseball               int64  \n",
      " 411  intp                   int64  \n",
      " 412  cringepics             int64  \n",
      " 413  nottheonion            int64  \n",
      " 414  labouruk               int64  \n",
      " 415  de                     int64  \n",
      " 416  fatpeoplehate          int64  \n",
      " 417  tacn                   int64  \n",
      " 418  marvelstrikeforce      int64  \n",
      " 419  skincareaddiction      int64  \n",
      " 420  instacartshoppers      int64  \n",
      " 421  splatoon               int64  \n",
      " 422  mhoc                   int64  \n",
      " 423  nostupidquestions      int64  \n",
      " 424  cooking                int64  \n",
      " 425  gundeals               int64  \n",
      " 426  coolguides             int64  \n",
      " 427  imgoingtohellforthis   int64  \n",
      " 428  raining                int64  \n",
      " 429  completeanarchy        int64  \n",
      " 430  unresolvedmysteries    int64  \n",
      " 431  rwby                   int64  \n",
      " 432  modelushouse           int64  \n",
      " 433  samplesize             int64  \n",
      " 434  chapotraphouse         int64  \n",
      " 435  vexillology            int64  \n",
      " 436  canadian_ecigarette    int64  \n",
      " 437  roadcam                int64  \n",
      " 438  stevenuniverse         int64  \n",
      " 439  theamazingrace         int64  \n",
      " 440  mensrights             int64  \n",
      " 441  jontron                int64  \n",
      " 442  sex                    int64  \n",
      " 443  starwars               int64  \n",
      " 444  badeconomics           int64  \n",
      " 445  makeupaddiction        int64  \n",
      " 446  askseddit              int64  \n",
      " 447  mariners               int64  \n",
      " 448  debatereligion         int64  \n",
      " 449  truereddit             int64  \n",
      " 450  rainbow6               int64  \n",
      " 451  estj                   int64  \n",
      " 452  opendirectories        int64  \n",
      " 453  diabetes               int64  \n",
      " 454  tinder                 int64  \n",
      " 455  tropicalweather        int64  \n",
      " 456  aftereffects           int64  \n",
      " 457  cfbofftopic            int64  \n",
      " 458  200yearsago            int64  \n",
      " 459  trashy                 int64  \n",
      " 460  askscience             int64  \n",
      " 461  weakpots               int64  \n",
      " 462  infj                   int64  \n",
      " 463  uvtrade                int64  \n",
      " 464  agreeableness          float64\n",
      " 465  openness               float64\n",
      " 466  conscientiousness      float64\n",
      " 467  extraversion           float64\n",
      " 468  neuroticism            float64\n",
      "dtypes: float64(7), int64(458), object(4)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "pandoradf.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigfive_cat(df):\n",
    "    # change big five to binary representation\n",
    "    df['agree'] = df['agreeableness'].apply(lambda x: 0 if x<50 else 1)\n",
    "    df['openn'] = df['openness'].apply(lambda x: 0 if x<50 else 1)\n",
    "    df['consc'] = df['conscientiousness'].apply(lambda x: 0 if x<50 else 1)\n",
    "    df['extra'] = df['extraversion'].apply(lambda x: 0 if x<50 else 1)\n",
    "    df['neuro'] = df['neuroticism'].apply(lambda x: 0 if x<50 else 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjust representations of some columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_stopwordlist(df, mode):\n",
    "    if mode == 'NLTK':\n",
    "        stopwordList = stopwords.words('english')\n",
    "    if mode == 'NLTK-neg':\n",
    "        stopwordList = stopwords.words('english')\n",
    "        stopwordList.remove('no')\n",
    "        stopwordList.remove('nor')\n",
    "        stopwordList.remove('not')\n",
    "    return stopwordList\n",
    "\n",
    "# stopwordList = choose_stopwordlist(pandoradf, mode='NLTK-neg')\n",
    "\n",
    "# print(stopwordList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "1. lower \n",
    "2. tokenize\n",
    "3. numbers to words\n",
    "4. delete special tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def senttokenize(df):\n",
    "    sentbody = []\n",
    "    for row in df['doc_body']:\n",
    "        sentitem = []\n",
    "        for item in row:\n",
    "            sentences = sent_tokenize(item)\n",
    "            sentitem.append(sentences)\n",
    "        sentbody.append(sentitem)\n",
    "    df['senttokens'] = sentbody\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_special(df):\n",
    "    # lower, remove special characters, remove stopwords\n",
    "#     df['probody'] = df['probody'].apply(lambda x: [char.lower() for word in x for char in word.split() if char.isalnum()])\n",
    "#     pandora['probody'] = pandora['probody'].apply(lambda x: [text for row in x for text in row.split() if (text not in stopwordList)])\n",
    "    newrow = []\n",
    "    for row in tqdm(df['probody']):\n",
    "        newcomment = []\n",
    "        for comment in row:\n",
    "            text_pre = \"\"\n",
    "            for character in comment:\n",
    "                if character.isalnum() or character.isspace():\n",
    "                    character = character.lower()\n",
    "                    text_pre += character\n",
    "                else:\n",
    "                    text_pre += \" \"\n",
    "            newcomment.append(text_pre)\n",
    "        newrow.append(newcomment)   \n",
    "    df['probody'] = newrow\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(df, stopwordList):\n",
    "    newprobody = []\n",
    "    for row in tqdm(df['probody']):\n",
    "        newrowprobody = []\n",
    "        for comment in row:\n",
    "            words = [word for word in comment.split() if (word not in stopwordList)]\n",
    "            newcomment = ' '.join(words)\n",
    "            newrowprobody.append(newcomment)\n",
    "        newprobody.append(newrowprobody)\n",
    "    df['probody'] = newprobody\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokenize(df):    \n",
    "    newbody_complete = []\n",
    "    newprobody_complete = []\n",
    "    # num2words\n",
    "    for row in tqdm(df['probody']):\n",
    "        newbody = []\n",
    "        newprobody = []\n",
    "        for sentence in row:\n",
    "            # string to list\n",
    "            inputtext = sentence.split()\n",
    "            numlist = []\n",
    "            for i in range(len(inputtext)):\n",
    "                if inputtext[i].isnumeric():\n",
    "                    numlist.append(i)\n",
    "            for number in numlist:\n",
    "                inputtext[number] = num2words(inputtext[number])\n",
    "\n",
    "            # list to string\n",
    "            inputtext = [word for word in inputtext if word.isalpha()]\n",
    "            celltext = ' '.join(inputtext)\n",
    "            newprobody.append(celltext)\n",
    "            # tokenize\n",
    "            words = word_tokenize(celltext)\n",
    "            newbody.append(words)\n",
    "        newbody_complete.append(newbody)\n",
    "        newprobody_complete.append(newprobody)\n",
    "    df['probody'] = newprobody_complete\n",
    "    df['tokens'] = newbody_complete\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "# Porter Stemmer\n",
    "def stemming(df):\n",
    "    ps = PorterStemmer()\n",
    "#     df['tokens'] = df['tokens'].progress_apply(lambda x:([ps.stem(word)for row in x for word in row.split() ]))\n",
    "    for row in tqdm(df['tokens']):\n",
    "        for comment in row:\n",
    "            words = [ps.stem(word) for word in comment]\n",
    "            comment = ' '.join(words)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordering(df):\n",
    "    cols_tomove = ['index', 'author', 'complete_body', 'doc_body', 'probody', 'tokens', 'senttokens', 'agreeableness', 'openness', 'conscientiousness', 'extraversion', 'neuroticism', 'agree', 'openn', 'consc', 'extra', 'neuro']\n",
    "    orderdf  = df[cols_tomove + [col for col in df.columns if col not in cols_tomove]]\n",
    "#     orderdf.info(verbose=True)\n",
    "    return orderdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decontract...\n",
      "Tokenize Sentences...\n",
      "Lower words and remove special characters...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "621ba8afea704bd58301dab0b89d8637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove stopwords...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bbf7355f8d641b9be39c62bc2382da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change numbers to words and tokenize words...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e685167adadc458abc371766c4c9fd31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porters Stemmer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29bea6bae30e44189da82a33d29f4337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order df...\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>author</th>\n",
       "      <th>complete_body</th>\n",
       "      <th>doc_body</th>\n",
       "      <th>probody</th>\n",
       "      <th>tokens</th>\n",
       "      <th>senttokens</th>\n",
       "      <th>agreeableness</th>\n",
       "      <th>openness</th>\n",
       "      <th>conscientiousness</th>\n",
       "      <th>...</th>\n",
       "      <th>neuro</th>\n",
       "      <th>all_utc</th>\n",
       "      <th>mean_controversiality</th>\n",
       "      <th>mean_gilded</th>\n",
       "      <th>num_subreddits</th>\n",
       "      <th>subreddit_dist</th>\n",
       "      <th>weekday_dist</th>\n",
       "      <th>month_dist</th>\n",
       "      <th>year_dist</th>\n",
       "      <th>all_lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-BigSexy-</td>\n",
       "      <td>Oooh i see</td>\n",
       "      <td>[Oooh i see]</td>\n",
       "      <td>[oooh see]</td>\n",
       "      <td>[[oooh, see]]</td>\n",
       "      <td>[[Oooh i see]]</td>\n",
       "      <td>39.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1510236798]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 1, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-BlitzN9ne</td>\n",
       "      <td>**Quality** material right here</td>\n",
       "      <td>[**Quality** material right here]</td>\n",
       "      <td>[quality material right]</td>\n",
       "      <td>[[quality, material, right]]</td>\n",
       "      <td>[[**Quality** material right here]]</td>\n",
       "      <td>50.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1549708109]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 1]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-CrestiaBell</td>\n",
       "      <td>A slidewhistle or a meow-meow board That's bec...</td>\n",
       "      <td>[A slidewhistle or a meow-meow board, That's b...</td>\n",
       "      <td>[slidewhistle meow meow board, watch cartoon s...</td>\n",
       "      <td>[[slidewhistle, meow, meow, board], [watch, ca...</td>\n",
       "      <td>[[A slidewhistle or a meow-meow board], [That'...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1538664591, 1475867279, 1505862626, 151267621...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 2]</td>\n",
       "      <td>[0, 2, 3, 1, 1]</td>\n",
       "      <td>0 0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-tactical-throw-away</td>\n",
       "      <td>Sorry for your feelings. Kek &amp;lt;------- This ...</td>\n",
       "      <td>[Sorry for your feelings., Kek &amp;lt;------- Thi...</td>\n",
       "      <td>[sorry feelings, kek lt onekek kek kek kek, no...</td>\n",
       "      <td>[[sorry, feelings], [kek, lt, onekek, kek, kek...</td>\n",
       "      <td>[[Sorry for your feelings.], [Kek &amp;lt;------- ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1498536785, 1486701409, 1506834463]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>[0, 0, 3, 0, 0]</td>\n",
       "      <td>0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>137288</td>\n",
       "      <td>Carly's so glad to get your .0000003 cents Exc...</td>\n",
       "      <td>[Carly's so glad to get your .0000003 cents, E...</td>\n",
       "      <td>[carly glad get three cents, except uk debuted...</td>\n",
       "      <td>[[carly, glad, get, three, cents], [except, uk...</td>\n",
       "      <td>[[Carly's so glad to get your .0000003 cents],...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1536611153, 1550537879, 1516548513, 1523299682]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 3, 1]</td>\n",
       "      <td>0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>424</td>\n",
       "      <td>xanthraxoid</td>\n",
       "      <td>I'd really like this video to include some inf...</td>\n",
       "      <td>[I'd really like this video to include some in...</td>\n",
       "      <td>[would really like video include information c...</td>\n",
       "      <td>[[would, really, like, video, include, informa...</td>\n",
       "      <td>[[I'd really like this video to include some i...</td>\n",
       "      <td>86.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1469892161, 1486826547, 1498046590, 1550346594]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 2, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 1, 2, 0, 1]</td>\n",
       "      <td>0 0 3 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>425</td>\n",
       "      <td>xenomouse</td>\n",
       "      <td>You're a guy, aren't you? I can definitely see...</td>\n",
       "      <td>[You're a guy, aren't you? I can definitely se...</td>\n",
       "      <td>[guy not definitely see would make boy scene f...</td>\n",
       "      <td>[[guy, not, definitely, see, would, make, boy,...</td>\n",
       "      <td>[[You're a guy, aren't you?, I can definitely ...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1506710219, 1502740906, 1517847908, 1506874589]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0]</td>\n",
       "      <td>[0, 0, 3, 1, 0]</td>\n",
       "      <td>0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>426</td>\n",
       "      <td>xeroctr3</td>\n",
       "      <td>man even the thought of it makes me depressed....</td>\n",
       "      <td>[man even the thought of it makes me depressed...</td>\n",
       "      <td>[man even thought makes depressed loving someo...</td>\n",
       "      <td>[[man, even, thought, makes, depressed, loving...</td>\n",
       "      <td>[[man even the thought of it makes me depresse...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1521414051]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>427</td>\n",
       "      <td>xzack18</td>\n",
       "      <td>Not all of us are out to kill</td>\n",
       "      <td>[Not all of us are out to kill]</td>\n",
       "      <td>[not us kill]</td>\n",
       "      <td>[[not, us, kill]]</td>\n",
       "      <td>[[Not all of us are out to kill]]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1533749569]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>428</td>\n",
       "      <td>zugzwang_03</td>\n",
       "      <td>Institutions should accommodate religious or s...</td>\n",
       "      <td>[Institutions should accommodate religious or ...</td>\n",
       "      <td>[institutions accommodate religious serious me...</td>\n",
       "      <td>[[institutions, accommodate, religious, seriou...</td>\n",
       "      <td>[[Institutions should accommodate religious or...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1514216199, 1459000262, 1500701643, 151759545...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1]</td>\n",
       "      <td>[0, 3, 2, 1, 0]</td>\n",
       "      <td>0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>422 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                author  \\\n",
       "0        0             -BigSexy-   \n",
       "1        1            -BlitzN9ne   \n",
       "2        2          -CrestiaBell   \n",
       "3        3  -tactical-throw-away   \n",
       "4        4                137288   \n",
       "..     ...                   ...   \n",
       "417    424           xanthraxoid   \n",
       "418    425             xenomouse   \n",
       "419    426              xeroctr3   \n",
       "420    427               xzack18   \n",
       "421    428           zugzwang_03   \n",
       "\n",
       "                                         complete_body  \\\n",
       "0                                           Oooh i see   \n",
       "1                      **Quality** material right here   \n",
       "2    A slidewhistle or a meow-meow board That's bec...   \n",
       "3    Sorry for your feelings. Kek &lt;------- This ...   \n",
       "4    Carly's so glad to get your .0000003 cents Exc...   \n",
       "..                                                 ...   \n",
       "417  I'd really like this video to include some inf...   \n",
       "418  You're a guy, aren't you? I can definitely see...   \n",
       "419  man even the thought of it makes me depressed....   \n",
       "420                      Not all of us are out to kill   \n",
       "421  Institutions should accommodate religious or s...   \n",
       "\n",
       "                                              doc_body  \\\n",
       "0                                         [Oooh i see]   \n",
       "1                    [**Quality** material right here]   \n",
       "2    [A slidewhistle or a meow-meow board, That's b...   \n",
       "3    [Sorry for your feelings., Kek &lt;------- Thi...   \n",
       "4    [Carly's so glad to get your .0000003 cents, E...   \n",
       "..                                                 ...   \n",
       "417  [I'd really like this video to include some in...   \n",
       "418  [You're a guy, aren't you? I can definitely se...   \n",
       "419  [man even the thought of it makes me depressed...   \n",
       "420                    [Not all of us are out to kill]   \n",
       "421  [Institutions should accommodate religious or ...   \n",
       "\n",
       "                                               probody  \\\n",
       "0                                           [oooh see]   \n",
       "1                             [quality material right]   \n",
       "2    [slidewhistle meow meow board, watch cartoon s...   \n",
       "3    [sorry feelings, kek lt onekek kek kek kek, no...   \n",
       "4    [carly glad get three cents, except uk debuted...   \n",
       "..                                                 ...   \n",
       "417  [would really like video include information c...   \n",
       "418  [guy not definitely see would make boy scene f...   \n",
       "419  [man even thought makes depressed loving someo...   \n",
       "420                                      [not us kill]   \n",
       "421  [institutions accommodate religious serious me...   \n",
       "\n",
       "                                                tokens  \\\n",
       "0                                        [[oooh, see]]   \n",
       "1                         [[quality, material, right]]   \n",
       "2    [[slidewhistle, meow, meow, board], [watch, ca...   \n",
       "3    [[sorry, feelings], [kek, lt, onekek, kek, kek...   \n",
       "4    [[carly, glad, get, three, cents], [except, uk...   \n",
       "..                                                 ...   \n",
       "417  [[would, really, like, video, include, informa...   \n",
       "418  [[guy, not, definitely, see, would, make, boy,...   \n",
       "419  [[man, even, thought, makes, depressed, loving...   \n",
       "420                                  [[not, us, kill]]   \n",
       "421  [[institutions, accommodate, religious, seriou...   \n",
       "\n",
       "                                            senttokens  agreeableness  \\\n",
       "0                                       [[Oooh i see]]           39.0   \n",
       "1                  [[**Quality** material right here]]           50.0   \n",
       "2    [[A slidewhistle or a meow-meow board], [That'...           50.0   \n",
       "3    [[Sorry for your feelings.], [Kek &lt;------- ...            2.0   \n",
       "4    [[Carly's so glad to get your .0000003 cents],...           10.0   \n",
       "..                                                 ...            ...   \n",
       "417  [[I'd really like this video to include some i...           86.0   \n",
       "418  [[You're a guy, aren't you?, I can definitely ...           26.0   \n",
       "419  [[man even the thought of it makes me depresse...            3.0   \n",
       "420                  [[Not all of us are out to kill]]            4.0   \n",
       "421  [[Institutions should accommodate religious or...           10.0   \n",
       "\n",
       "     openness  conscientiousness  ...  neuro  \\\n",
       "0        92.0                1.0  ...      0   \n",
       "1        85.0               15.0  ...      0   \n",
       "2        85.0               50.0  ...      1   \n",
       "3        92.0               31.0  ...      1   \n",
       "4        87.0               49.0  ...      1   \n",
       "..        ...                ...  ...    ...   \n",
       "417      45.0                8.0  ...      1   \n",
       "418      93.0               49.0  ...      0   \n",
       "419      75.0               27.0  ...      1   \n",
       "420      19.0               11.0  ...      0   \n",
       "421      41.0               86.0  ...      0   \n",
       "\n",
       "                                               all_utc  mean_controversiality  \\\n",
       "0                                         [1510236798]                    0.0   \n",
       "1                                         [1549708109]                    0.0   \n",
       "2    [1538664591, 1475867279, 1505862626, 151267621...                    0.0   \n",
       "3                 [1498536785, 1486701409, 1506834463]                    0.0   \n",
       "4     [1536611153, 1550537879, 1516548513, 1523299682]                    0.0   \n",
       "..                                                 ...                    ...   \n",
       "417   [1469892161, 1486826547, 1498046590, 1550346594]                    0.0   \n",
       "418   [1506710219, 1502740906, 1517847908, 1506874589]                    0.0   \n",
       "419                                       [1521414051]                    0.0   \n",
       "420                                       [1533749569]                    0.0   \n",
       "421  [1514216199, 1459000262, 1500701643, 151759545...                    0.0   \n",
       "\n",
       "     mean_gilded  num_subreddits  \\\n",
       "0            0.0               1   \n",
       "1            0.0               1   \n",
       "2            0.0               4   \n",
       "3            0.0               1   \n",
       "4            0.0               1   \n",
       "..           ...             ...   \n",
       "417          0.0               4   \n",
       "418          0.0               2   \n",
       "419          0.0               1   \n",
       "420          0.0               1   \n",
       "421          0.0               5   \n",
       "\n",
       "                                        subreddit_dist           weekday_dist  \\\n",
       "0    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [0, 0, 0, 0, 0, 0, 0]   \n",
       "1    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [0, 0, 0, 0, 0, 0, 0]   \n",
       "2    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [0, 0, 0, 0, 0, 0, 0]   \n",
       "3    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [0, 0, 0, 0, 0, 0, 0]   \n",
       "4    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [0, 0, 0, 0, 0, 0, 0]   \n",
       "..                                                 ...                    ...   \n",
       "417  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [0, 0, 0, 0, 0, 0, 0]   \n",
       "418  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [0, 0, 0, 0, 0, 0, 0]   \n",
       "419  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [0, 0, 0, 0, 0, 0, 0]   \n",
       "420  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [0, 0, 0, 0, 0, 0, 0]   \n",
       "421  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                               month_dist        year_dist       all_lang  \n",
       "0    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]  [0, 0, 1, 0, 0]              0  \n",
       "1    [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  [0, 0, 0, 0, 1]              0  \n",
       "2    [1, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 2]  [0, 2, 3, 1, 1]  0 0 0 0 0 0 0  \n",
       "3    [0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0]  [0, 0, 3, 0, 0]          0 0 0  \n",
       "4    [1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0]  [0, 0, 0, 3, 1]        0 0 0 0  \n",
       "..                                    ...              ...            ...  \n",
       "417  [0, 2, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0]  [0, 1, 2, 0, 1]        0 0 3 0  \n",
       "418  [0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0]  [0, 0, 3, 1, 0]        0 0 0 0  \n",
       "419  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  [0, 0, 0, 1, 0]              0  \n",
       "420  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]  [0, 0, 0, 1, 0]              0  \n",
       "421  [0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1]  [0, 3, 2, 1, 0]    0 0 0 0 0 0  \n",
       "\n",
       "[422 rows x 26 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(df):\n",
    "    # adjust some column representations\n",
    "    df = bigfive_cat(df)\n",
    "    # choose stopwordlist with or without negation\n",
    "    stopwordList = choose_stopwordlist(df, mode='NLTK-neg')\n",
    "    # decontract abbreviations (e.g., n't to not)\n",
    "    print(\"Decontract...\")\n",
    "    df['probody'] = df['doc_body'].apply(lambda x:([decontracted(x) for x in x]))\n",
    "    # create sentence tokens\n",
    "    print(\"Tokenize Sentences...\")\n",
    "    df = senttokenize(df)\n",
    "    # lower, remove stopwords, num2words, tokenize\n",
    "    print(\"Lower words and remove special characters...\")\n",
    "    df = lower_special(df)\n",
    "    print(\"Remove stopwords...\")\n",
    "    df = remove_stopwords(df, stopwordList)\n",
    "    print(\"Change numbers to words and tokenize words...\")\n",
    "    df = num_tokenize(df)\n",
    "    # porters stemmer\n",
    "    print(\"Porters Stemmer...\")\n",
    "    df = stemming(df)\n",
    "    print(\"Order df...\")\n",
    "    df = ordering(df)\n",
    "    print(\"Done!\")\n",
    "    return df\n",
    "\n",
    "predf = preprocess(pandoradf)\n",
    "\n",
    "predf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 422 entries, 0 to 421\n",
      "Data columns (total 26 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   index                  422 non-null    int64  \n",
      " 1   author                 422 non-null    object \n",
      " 2   complete_body          422 non-null    object \n",
      " 3   doc_body               422 non-null    object \n",
      " 4   probody                422 non-null    object \n",
      " 5   tokens                 422 non-null    object \n",
      " 6   senttokens             422 non-null    object \n",
      " 7   agreeableness          422 non-null    float64\n",
      " 8   openness               422 non-null    float64\n",
      " 9   conscientiousness      422 non-null    float64\n",
      " 10  extraversion           422 non-null    float64\n",
      " 11  neuroticism            422 non-null    float64\n",
      " 12  agree                  422 non-null    int64  \n",
      " 13  openn                  422 non-null    int64  \n",
      " 14  consc                  422 non-null    int64  \n",
      " 15  extra                  422 non-null    int64  \n",
      " 16  neuro                  422 non-null    int64  \n",
      " 17  all_utc                422 non-null    object \n",
      " 18  mean_controversiality  422 non-null    float64\n",
      " 19  mean_gilded            422 non-null    float64\n",
      " 20  num_subreddits         422 non-null    int64  \n",
      " 21  subreddit_dist         422 non-null    object \n",
      " 22  weekday_dist           422 non-null    object \n",
      " 23  month_dist             422 non-null    object \n",
      " 24  year_dist              422 non-null    object \n",
      " 25  all_lang               422 non-null    object \n",
      "dtypes: float64(7), int64(7), object(12)\n",
      "memory usage: 85.8+ KB\n"
     ]
    }
   ],
   "source": [
    "predf.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predf.to_pickle(\"preprocessed_author.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
