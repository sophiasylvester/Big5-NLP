{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier for the augmented dataset with adapted cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from time import time\n",
    "import datetime\n",
    "import random\n",
    "random.seed(32)\n",
    "import sklearn\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, VarianceThreshold\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, roc_curve, plot_roc_curve, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in augmented dataset in two parts: original and fake authors separated\n",
    "filepath = \"aug_b5feat_label_new.pkl\"\n",
    "with open(filepath, 'rb') as f:\n",
    "    new_augdf = pickle.load(f)\n",
    "    \n",
    "new_augdf['trait'] = new_augdf['trait'].astype('int16')\n",
    "new_augdf['wordngram'] = new_augdf['wordngram'].astype('float32')\n",
    "new_augdf['charngram'] = new_augdf['charngram'].astype('float32')\n",
    "new_augdf['x_feat'] = new_augdf['x_feat'].astype('float32')\n",
    "new_augdf['lin_feat'] = new_augdf['lin_feat'].astype('float32')\n",
    "new_augdf['psych'] = new_augdf['psych'].astype('float32')\n",
    "new_augdf['empath'] = new_augdf['empath'].astype('float32')\n",
    "new_augdf['post'] = new_augdf['post'].astype('float32')\n",
    "new_augdf['subtf'] = new_augdf['subtf'].astype('float32')\n",
    "new_augdf['lda50'] = new_augdf['lda50'].astype('float64')\n",
    "new_augdf['lda100'] = new_augdf['lda100'].astype('float64')\n",
    "\n",
    "new_augdf.drop(['text'], axis=1, level=0, inplace=True)\n",
    "\n",
    "filepath = \"aug_b5feat_label_original.pkl\"\n",
    "with open(filepath, 'rb') as f:\n",
    "    ori_augdf = pickle.load(f)\n",
    "ori_augdf.name = 'augmented_df'\n",
    "\n",
    "ori_augdf['trait'] = ori_augdf['trait'].astype('int16')\n",
    "ori_augdf['wordngram'] = ori_augdf['wordngram'].astype('float32')\n",
    "ori_augdf['charngram'] = ori_augdf['charngram'].astype('float32')\n",
    "ori_augdf['x_feat'] = ori_augdf['x_feat'].astype('float32')\n",
    "ori_augdf['lin_feat'] = ori_augdf['lin_feat'].astype('float32')\n",
    "ori_augdf['psych'] = ori_augdf['psych'].astype('float32')\n",
    "ori_augdf['empath'] = ori_augdf['empath'].astype('float32')\n",
    "ori_augdf['post'] = ori_augdf['post'].astype('float32')\n",
    "ori_augdf['subtf'] = ori_augdf['subtf'].astype('float32')\n",
    "ori_augdf['lda50'] = ori_augdf['lda50'].astype('float64')\n",
    "ori_augdf['lda100'] = ori_augdf['lda100'].astype('float64')\n",
    "\n",
    "ori_augdf.drop(['text'], axis=1, level=0, inplace=True)\n",
    "ori_augdf['trait'].dtypes\n",
    "ori_augdf.name = 'augmented_df'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset in features and target variable depending on which trait to focus on\n",
    "def trait(df, trait_name):\n",
    "    featuredf = df.drop(['trait'], axis=1, level=0)\n",
    "    feature_cols = featuredf.columns.tolist()\n",
    "    \n",
    "    x = df[feature_cols] \n",
    "    \n",
    "    if trait_name == 'agreeableness':\n",
    "        y = df['trait', 'big5_a']\n",
    "    elif trait_name == 'openness':\n",
    "        y = df['trait', 'big5_o']\n",
    "    elif trait_name == 'conscientiousness':\n",
    "        y = df['trait', 'big5_c']\n",
    "    elif trait_name == 'extraversion':\n",
    "        y = df['trait', 'big5_e']\n",
    "    elif trait_name == 'neuroticism':\n",
    "        y = df['trait', 'big5_n']   \n",
    "    return x,y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for nested stratified cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get names of the features\n",
    "def get_names(x, pipeline):\n",
    "    features = pipeline.named_steps['feature_selection']\n",
    "    names = x.columns[features.get_support(indices=True)]\n",
    "    return names\n",
    "\n",
    "def save_predictors(names, predictors_fold1, predictors_fold2, predictors_fold3, predictors_fold4, predictors_fold5, j):\n",
    "    if j==1:\n",
    "        predictors_fold1.append(list(names))\n",
    "    elif j==2:\n",
    "        predictors_fold2.append(list(names))\n",
    "    elif j==3:\n",
    "        predictors_fold3.append(list(names))\n",
    "    elif j==4:\n",
    "        predictors_fold4.append(list(names))\n",
    "    elif j==5:\n",
    "        predictors_fold5.append(list(names))\n",
    "    return predictors_fold1, predictors_fold2, predictors_fold3, predictors_fold4, predictors_fold5\n",
    "\n",
    "def save_acc_folds(acc, acc_fold1, acc_fold2, acc_fold3, acc_fold4, acc_fold5, j):\n",
    "    if j==1:\n",
    "        acc_fold1.append(acc)\n",
    "    elif j==2:\n",
    "        acc_fold2.append(acc)\n",
    "    elif j==3:\n",
    "        acc_fold3.append(acc)\n",
    "    elif j==4:\n",
    "        acc_fold4.append(acc)\n",
    "    elif j==5:\n",
    "        acc_fold5.append(acc)\n",
    "    return acc_fold1, acc_fold2, acc_fold3, acc_fold4, acc_fold5\n",
    "\n",
    "def save_auc_folds(auc, auc_fold1, auc_fold2, auc_fold3, auc_fold4, auc_fold5, j):\n",
    "    if j==1:\n",
    "        auc_fold1.append(auc)\n",
    "    elif j==2:\n",
    "        auc_fold2.append(auc)\n",
    "    elif j==3:\n",
    "        auc_fold3.append(auc)\n",
    "    elif j==4:\n",
    "        auc_fold4.append(auc)\n",
    "    elif j==5:\n",
    "        auc_fold5.append(auc)\n",
    "    return auc_fold1, auc_fold2, auc_fold3, auc_fold4, auc_fold5\n",
    "\n",
    "def save_f1score_folds(f1_macro, f1score_fold1, f1score_fold2, f1score_fold3, f1score_fold4, f1score_fold5, j):\n",
    "    if j==1:\n",
    "        f1score_fold1.append(f1_macro)\n",
    "    elif j==2:\n",
    "        f1score_fold2.append(f1_macro)\n",
    "    elif j==3:\n",
    "        f1score_fold3.append(f1_macro)\n",
    "    elif j==4:\n",
    "        f1score_fold4.append(f1_macro)\n",
    "    elif j==5:\n",
    "        f1score_fold5.append(f1_macro)\n",
    "    return f1score_fold1, f1score_fold2, f1score_fold3, f1score_fold4, f1score_fold5\n",
    "\n",
    "\n",
    "def save_params_folds(foldparams, params_fold1, params_fold2, params_fold3, params_fold4, params_fold5, j):\n",
    "    if j==1:\n",
    "        params_fold1.append(foldparams)\n",
    "    elif j==2:\n",
    "        params_fold2.append(foldparams)\n",
    "    elif j==3:\n",
    "        params_fold3.append(foldparams)\n",
    "    elif j==4:\n",
    "        params_fold4.append(foldparams)\n",
    "    elif j==5:\n",
    "        params_fold5.append(foldparams)\n",
    "    return params_fold1, params_fold2, params_fold3, params_fold4, params_fold5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_aug(df, traits, option, fs, dim, n_feat, replication=False, new_augdf=None):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        tstart = time()\n",
    "        print(\"Current time: \", str(datetime.datetime.now()))\n",
    "        print(\"Classifier: \", option, \"\\n\")\n",
    "        outputname = \"b5_\" +df.name +\"_\" +str(option) +\"_\" +str(fs) +\"_PCA\" +str(dim) +\"_\"+str(n_feat)\n",
    "        output = {'Traits': traits}\n",
    "        \n",
    "        # empty lists to save data in csv\n",
    "        acc_traits, f1_traits, cm_traits, auc_traits = [], [], [], []\n",
    "        acc_fold1, acc_fold2, acc_fold3, acc_fold4, acc_fold5 = [],[],[],[],[]\n",
    "        auc_fold1, auc_fold2, auc_fold3, auc_fold4, auc_fold5 = [],[],[],[],[]\n",
    "        f1score_fold1, f1score_fold2, f1score_fold3, f1score_fold4, f1score_fold5 = [],[],[],[],[]\n",
    "        params_fold1, params_fold2, params_fold3, params_fold4, params_fold5 = [],[],[],[],[]\n",
    "        predictors_fold1, predictors_fold2, predictors_fold3, predictors_fold4, predictors_fold5 = [],[],[],[],[]\n",
    "\n",
    "        print(\"\\nTrait to predict: \", traits, \"(\", option, \")\\n\")\n",
    "        x,y = trait(df, traits)\n",
    "        \n",
    "        # outer loop\n",
    "        cv_outer = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "        cv_outer_lst = cv_outer.split(x, y)\n",
    "        \n",
    "        # empty lists for saving\n",
    "        f1macro_lst, accuracy_lst, tpr_lst, ytrue_lst, ypred_lst, auc_lst = [],[],[],[],[],[]\n",
    "        \n",
    "        # for ROC curve\n",
    "        mean_fpr = np.linspace(0, 1, 101)\n",
    "\n",
    "        plt.figure(figsize=(7, 7))\n",
    "        p = Path('/home/sophia/ma_py/Big5-NLP/results/augmented/')\n",
    "        \n",
    "        # count folds\n",
    "        j=1\n",
    "        \n",
    "        # begin nested cv\n",
    "        for train_idx, val_idx in cv_outer_lst:\n",
    "            train_data, val_data = x.iloc[train_idx], x.iloc[val_idx]\n",
    "            train_target, val_target = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "            print(\"Fold No.\", j)\n",
    "\n",
    "            # add augmented data to training\n",
    "            featuredf, traitdf = trait(new_augdf, traits)\n",
    "            for original in train_data.index:\n",
    "                res = [idx for idx in new_augdf.index if idx[0:(len(original))] == original]\n",
    "                datarows = featuredf.loc[res][:]\n",
    "                targetrows = traitdf.loc[res][:]\n",
    "                train_data = train_data.append(datarows)\n",
    "                train_target = train_target.append(targetrows)\n",
    "\n",
    "            print(\"After augmentation length of train and test: \", len(train_data), len(val_data))\n",
    "            print(\"After augmentation total users in this fold: \", (len(train_data) + len(val_data)))\n",
    "            print(\"\\n\")\n",
    "            \n",
    "            clf = Pipeline([\n",
    "                  ('variance_threshold', VarianceThreshold()),\n",
    "                  ('scaler', StandardScaler()),\n",
    "                  ('feature_selection',  SelectKBest(f_classif, k=n_feat)),\n",
    "                  ('classification', LogisticRegression(class_weight='balanced', n_jobs=-1, max_iter=1000))\n",
    "                ])\n",
    "            # inner loop\n",
    "            cv_inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "            params = {'classification__solver': ['lbfgs', 'liblinear', 'saga'], \n",
    "                      'classification__C': [10**x for x in range(-3,5)]}\n",
    "            gd_search = GridSearchCV(clf, params, scoring = 'f1_macro', n_jobs=-1, cv=cv_inner).fit(train_data, train_target)\n",
    "            best_model = gd_search.best_estimator_\n",
    "            if dim == False:\n",
    "                names = get_names(train_data, best_model)\n",
    "                predictors_fold1, predictors_fold2, predictors_fold3, predictors_fold4, predictors_fold5 = save_predictors(names, predictors_fold1, predictors_fold2, predictors_fold3, predictors_fold4, predictors_fold5, j)\n",
    "            \n",
    "            # fit data on best model (inner loop)\n",
    "            clfnew = best_model.fit(train_data, train_target)\n",
    "            y_pred = clfnew.predict(val_data)\n",
    "            y_score = clfnew.predict_proba(val_data)\n",
    "            \n",
    "            # ROC plot\n",
    "            fpr, tpr, _ = roc_curve(val_target, y_score[:, 1])\n",
    "\n",
    "            plt.plot(fpr, tpr, 'b', alpha=0.15)\n",
    "            tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "            tpr[0] = 0.0\n",
    "            tpr_lst.append(tpr)\n",
    "\n",
    "            # confusion matrix\n",
    "            cm = confusion_matrix(val_target, y_pred)\n",
    "            cm_traits.append(cm)\n",
    "\n",
    "            # save macro F1 and accuracy values\n",
    "            f1_macro = f1_score(val_target, y_pred, average='macro')\n",
    "            f1macro_lst.append(f1_macro)\n",
    "            f1score_fold1, f1score_fold2, f1score_fold3, f1score_fold4, f1score_fold5 = save_f1score_folds(f1_macro, f1score_fold1, f1score_fold2, f1score_fold3, f1score_fold4, f1score_fold5, j)\n",
    "            acc = accuracy_score(val_target, y_pred)\n",
    "            accuracy_lst.append(acc)\n",
    "            acc_fold1, acc_fold2, acc_fold3, acc_fold4, acc_fold5 = save_acc_folds(acc, acc_fold1, acc_fold2, acc_fold3, acc_fold4, acc_fold5, j)\n",
    "            auc = roc_auc_score(val_target, y_score[:, 1])\n",
    "            auc_lst.append(auc)\n",
    "            auc_fold1, auc_fold2, auc_fold3, auc_fold4, auc_fold5 = save_auc_folds(auc, auc_fold1, auc_fold2, auc_fold3, auc_fold4, auc_fold5, j)\n",
    "            foldparams = gd_search.best_params_\n",
    "            params_fold1, params_fold2, params_fold3, params_fold4, params_fold5 = save_params_folds(foldparams, params_fold1, params_fold2, params_fold3, params_fold4, params_fold5, j)\n",
    "\n",
    "            j+=1\n",
    "\n",
    "\n",
    "     # Training final model (outer loop)\n",
    "        auc_avg = np.mean(auc_lst)\n",
    "        auc_std = np.std(auc_lst)\n",
    "        auc_traits.append(round(auc_avg, 4))\n",
    "        print(\"Average auc score (std): \", auc_avg, auc_std)\n",
    "        acc_avg = np.mean(accuracy_lst)\n",
    "        acc_traits.append(round(acc_avg, 4))\n",
    "        print(\"Average accuracy: \", acc_avg)\n",
    "        f1macro_avg = np.mean(f1macro_lst)\n",
    "        f1_traits.append(round(f1macro_avg, 4))\n",
    "        print(\"\\n\\nAverage f1 macro score: \", f1macro_avg)\n",
    "\n",
    "        tprs = np.array(tpr_lst)\n",
    "        mean_tprs = tprs.mean(axis=0)\n",
    "        std = tprs.std(axis=0)\n",
    "        tprs_upper = np.minimum(mean_tprs + std, 1)\n",
    "        tprs_lower = mean_tprs - std\n",
    "        \n",
    "        # save auc and tprs for roc curve plots with comparison\n",
    "        np.save(Path(p, outputname + \"_\" + traits + '_auc.npy'), auc_avg)\n",
    "        np.save(Path(p, outputname + \"_\" + traits + '_meantprs.npy'), mean_tprs)\n",
    "\n",
    "\n",
    "        plt.plot(mean_fpr, mean_tprs, 'b',  label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (auc_avg, auc_std))\n",
    "        plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=0.3)\n",
    "\n",
    "        title1 = \"ROC plot for trait \" + traits\n",
    "        plt.plot([0, 1], [0, 1],'r--', label='Chance')\n",
    "        plt.xlim([-0.01, 1.01])\n",
    "        plt.ylim([-0.01, 1.01])\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.axes().set_aspect('equal', 'datalim')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.title(title1)\n",
    "        plt.savefig(Path(p, outputname + \"_\" + traits + '_roc_plot.png'))\n",
    "        plt.show()\n",
    "\n",
    "        print(\"Number of users in testing: \", np.sum(cm_traits))\n",
    "        title2 = \"Confusion matrix for trait \" + traits\n",
    "        plt.figure(figsize=(7, 7))\n",
    "        mean_cm = np.sum(cm_traits, axis=0, dtype='int')\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=mean_cm).plot(cmap=plt.cm.Blues, values_format = '.4f')\n",
    "        disp.ax_.set_title(title2)\n",
    "        plt.savefig(Path(p, outputname + \"_\" + traits + '_cm.png'))\n",
    "        plt.show()\n",
    "\n",
    "    print(\"Total accuracy: \", np.mean(acc_traits), \"Total F1 macro: \", np.mean(f1_traits))\n",
    "    output.update({'acc': acc_traits, 'f1_macro': f1_traits, 'auc': auc_traits})\n",
    "    output.update({'acc_fold1': acc_fold1, 'acc_fold2': acc_fold2, 'acc_fold3': acc_fold3, 'acc_fold4': acc_fold4, 'acc_fold5': acc_fold5})\n",
    "    output.update({'f1score_fold1': f1score_fold1, 'f1score_fold2': f1score_fold2, 'f1score_fold3': f1score_fold3, 'f1score_fold4': f1score_fold4, 'f1score_fold5': f1score_fold5})\n",
    "    output.update({'auc_fold1': auc_fold1, 'auc_fold2': auc_fold2, 'auc_fold3': auc_fold3, 'auc_fold4': auc_fold4, 'auc_fold5': auc_fold5})\n",
    "    output.update({'params_fold1': params_fold1, 'params_fold2': params_fold2, 'params_fold3': params_fold3, 'params_fold4': params_fold4, 'params_fold5': params_fold5})\n",
    "    if dim==False:\n",
    "        output.update({'predictors_fold1': predictors_fold1, 'predictors_fold2': predictors_fold2, 'predictors_fold3': predictors_fold3, 'predictors_fold4': predictors_fold4, 'predictors_fold5': predictors_fold5})\n",
    "    outputdf = pd.DataFrame(output)\n",
    "    outputdf.to_csv(Path(p, outputname + \"_\" + traits + '.csv'), index=False)\n",
    "    \n",
    "    print(\"Time for entire process: %0.2fs\" % (time() - tstart))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmented dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classify_aug(ori_augdf, 'openness', 'mlp', 'anova', dim=False, n_feat=30, new_augdf=new_augdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classify_aug(ori_augdf, 'conscientiousness', 'mlp', 'anova', dim=False, n_feat=30, new_augdf=new_augdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classify_aug(ori_augdf, 'extraversion', 'mlp', 'anova', dim=False, n_feat=30, new_augdf=new_augdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classify_aug(ori_augdf, 'agreeableness', 'mlp', 'anova', dim=False, n_feat=30, new_augdf=new_augdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classify_aug(ori_augdf, 'neuroticism', 'mlp', 'anova', dim=False, n_feat=30, new_augdf=new_augdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify training data to detect over- and underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_train(df, traits, option, fs, dim, n_feat, replication=False, new_augdf=None):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        tstart = time()\n",
    "        print(\"Current time: \", str(datetime.datetime.now()))\n",
    "        print(\"Classifier: \", option, \"\\n\")\n",
    "        outputname = \"b5_\" +df.name +\"_\" +str(option) +\"_\" +str(fs) +\"_PCA\" +str(dim) +\"_\"+str(n_feat)\n",
    "        output = {'Traits': traits}\n",
    "        \n",
    "        # empty lists to save data in csv\n",
    "        acc_traits, f1_traits, cm_traits, auc_traits = [], [], [], []\n",
    "        acc_fold1, acc_fold2, acc_fold3, acc_fold4, acc_fold5 = [],[],[],[],[]\n",
    "        auc_fold1, auc_fold2, auc_fold3, auc_fold4, auc_fold5 = [],[],[],[],[]\n",
    "        f1score_fold1, f1score_fold2, f1score_fold3, f1score_fold4, f1score_fold5 = [],[],[],[],[]\n",
    "        params_fold1, params_fold2, params_fold3, params_fold4, params_fold5 = [],[],[],[],[]\n",
    "        predictors_fold1, predictors_fold2, predictors_fold3, predictors_fold4, predictors_fold5 = [],[],[],[],[]\n",
    "\n",
    "        print(\"\\nTrait to predict: \", traits, \"(\", option, \")\\n\")\n",
    "        x,y = trait(df, traits)\n",
    "        \n",
    "        # outer loop\n",
    "        cv_outer = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "        cv_outer_lst = cv_outer.split(x, y)\n",
    "        \n",
    "        # empty lists for saving\n",
    "        f1macro_lst, accuracy_lst, tpr_lst, ytrue_lst, ypred_lst, auc_lst = [],[],[],[],[],[]\n",
    "        \n",
    "        # for ROC curve\n",
    "        mean_fpr = np.linspace(0, 1, 101)\n",
    "        plt.figure(figsize=(7, 7))\n",
    "        p = Path('/home/sophia/ma_py/Big5-NLP/results/')\n",
    "        \n",
    "        # count folds\n",
    "        j=1\n",
    "        \n",
    "        # begin nested cv\n",
    "        for train_idx, val_idx in cv_outer_lst:\n",
    "            train_data, val_data = x.iloc[train_idx], x.iloc[val_idx]\n",
    "            train_target, val_target = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "            print(\"Fold No.\", j)\n",
    "\n",
    "            # add augmented data to training\n",
    "            featuredf, traitdf = trait(new_augdf, traits)\n",
    "            for original in train_data.index:\n",
    "                res = [idx for idx in new_augdf.index if idx[0:(len(original))] == original]\n",
    "                datarows = featuredf.loc[res][:]\n",
    "                targetrows = traitdf.loc[res][:]\n",
    "                train_data = train_data.append(datarows)\n",
    "                train_target = train_target.append(targetrows)\n",
    "\n",
    "            print(\"After augmentation length of train and test: \", len(train_data), len(val_data))\n",
    "            print(\"After augmentation total users in this fold: \", (len(train_data) + len(val_data)))\n",
    "            print(\"\\n\")\n",
    "            \n",
    "            clf = Pipeline([\n",
    "                  ('variance_threshold', VarianceThreshold()),\n",
    "                  ('scaler', StandardScaler()),\n",
    "                  ('feature_selection',  SelectKBest(f_classif, k=n_feat)),\n",
    "                  ('classification', LogisticRegression(class_weight='balanced', n_jobs=-1, max_iter=1000))\n",
    "                ])\n",
    "            # inner loop proceedings\n",
    "            cv_inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "            params = {'classification__solver': ['lbfgs', 'liblinear', 'saga'], \n",
    "                      'classification__C': [10**x for x in range(-3,5)]}\n",
    "            gd_search = GridSearchCV(clf, params, scoring = 'f1_macro', n_jobs=-1, cv=cv_inner).fit(train_data, train_target)\n",
    "            best_model = gd_search.best_estimator_\n",
    "            if dim == False:\n",
    "                names = get_names(train_data, best_model)\n",
    "                predictors_fold1, predictors_fold2, predictors_fold3, predictors_fold4, predictors_fold5 = save_predictors(names, predictors_fold1, predictors_fold2, predictors_fold3, predictors_fold4, predictors_fold5, j)\n",
    "            \n",
    "            # fit data on best model (inner loop)\n",
    "            clfnew = best_model.fit(train_data, train_target)\n",
    "            y_pred = clfnew.predict(train_data)\n",
    "            y_score = clfnew.predict_proba(train_data)\n",
    "            \n",
    "            # ROC plot\n",
    "            fpr, tpr, _ = roc_curve(train_target, y_score[:, 1])\n",
    "\n",
    "            plt.plot(fpr, tpr, 'b', alpha=0.15)\n",
    "            tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "            tpr[0] = 0.0\n",
    "            tpr_lst.append(tpr)\n",
    "\n",
    "            # confusion matrix\n",
    "            cm = confusion_matrix(train_target, y_pred)\n",
    "            cm_traits.append(cm)\n",
    "\n",
    "            # save macro F1 and accuracy values\n",
    "            f1_macro = f1_score(train_target, y_pred, average='macro')\n",
    "            f1macro_lst.append(f1_macro)\n",
    "            f1score_fold1, f1score_fold2, f1score_fold3, f1score_fold4, f1score_fold5 = save_f1score_folds(f1_macro, f1score_fold1, f1score_fold2, f1score_fold3, f1score_fold4, f1score_fold5, j)\n",
    "            acc = accuracy_score(train_target, y_pred)\n",
    "            accuracy_lst.append(acc)\n",
    "            acc_fold1, acc_fold2, acc_fold3, acc_fold4, acc_fold5 = save_acc_folds(acc, acc_fold1, acc_fold2, acc_fold3, acc_fold4, acc_fold5, j)\n",
    "            auc = roc_auc_score(train_target, y_score[:, 1])\n",
    "            auc_lst.append(auc)\n",
    "            auc_fold1, auc_fold2, auc_fold3, auc_fold4, auc_fold5 = save_auc_folds(auc, auc_fold1, auc_fold2, auc_fold3, auc_fold4, auc_fold5, j)\n",
    "            foldparams = gd_search.best_params_\n",
    "            params_fold1, params_fold2, params_fold3, params_fold4, params_fold5 = save_params_folds(foldparams, params_fold1, params_fold2, params_fold3, params_fold4, params_fold5, j)\n",
    "\n",
    "            j+=1\n",
    "\n",
    "\n",
    "     # Training final model (outer loop)\n",
    "        auc_avg = np.mean(auc_lst)\n",
    "        auc_std = np.std(auc_lst)\n",
    "        auc_traits.append(round(auc_avg, 4))\n",
    "        print(\"Average auc score (std): \", auc_avg, auc_std)\n",
    "        acc_avg = np.mean(accuracy_lst)\n",
    "        acc_traits.append(round(acc_avg, 4))\n",
    "        print(\"Average accuracy: \", acc_avg)\n",
    "        f1macro_avg = np.mean(f1macro_lst)\n",
    "        f1_traits.append(round(f1macro_avg, 4))\n",
    "        print(\"\\n\\nAverage f1 macro score: \", f1macro_avg)\n",
    "\n",
    "        tprs = np.array(tpr_lst)\n",
    "        mean_tprs = tprs.mean(axis=0)\n",
    "        std = tprs.std(axis=0)\n",
    "        tprs_upper = np.minimum(mean_tprs + std, 1)\n",
    "        tprs_lower = mean_tprs - std\n",
    "        \n",
    "        # save auc and tprs for roc plot with comparison\n",
    "        np.save(Path(p, outputname + \"_\" + trait_name + '_auc.npy'), auc_avg)\n",
    "        np.save(Path(p, outputname + \"_\" + traits + '_meantprs.npy'), mean_tprs)\n",
    "\n",
    "\n",
    "        plt.plot(mean_fpr, mean_tprs, 'b', label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (auc_avg, auc_std))\n",
    "        plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=0.3)\n",
    "\n",
    "        title1 = \"ROC plot for trait \" + traits\n",
    "        plt.plot([0, 1], [0, 1],'r--', label='Chance')\n",
    "        plt.xlim([-0.01, 1.01])\n",
    "        plt.ylim([-0.01, 1.01])\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.axes().set_aspect('equal', 'datalim')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.title(title1)\n",
    "#         plt.savefig(Path(p, outputname + \"_\" + traits + '_roc_plot.png'))\n",
    "        plt.show()\n",
    "\n",
    "        print(\"Number of users in testing: \", np.sum(cm_traits))\n",
    "        title2 = \"Confusion matrix for trait \" + traits\n",
    "        plt.figure(figsize=(7, 7))\n",
    "        mean_cm = np.sum(cm_traits, axis=0, dtype='int')\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=mean_cm).plot(cmap=plt.cm.Blues, values_format = '.4f')\n",
    "        disp.ax_.set_title(title2)\n",
    "#         plt.savefig(Path(p, outputname + \"_\" + traits + '_cm.png'))\n",
    "        plt.show()\n",
    "\n",
    "    print(\"Total accuracy: \", np.mean(acc_traits), \"Total F1 macro: \", np.mean(f1_traits))\n",
    "    output.update({'acc': acc_traits, 'f1_macro': f1_traits, 'auc': auc_traits})\n",
    "    output.update({'acc_fold1': acc_fold1, 'acc_fold2': acc_fold2, 'acc_fold3': acc_fold3, 'acc_fold4': acc_fold4, 'acc_fold5': acc_fold5})\n",
    "    output.update({'f1score_fold1': f1score_fold1, 'f1score_fold2': f1score_fold2, 'f1score_fold3': f1score_fold3, 'f1score_fold4': f1score_fold4, 'f1score_fold5': f1score_fold5})\n",
    "    output.update({'auc_fold1': auc_fold1, 'auc_fold2': auc_fold2, 'auc_fold3': auc_fold3, 'auc_fold4': auc_fold4, 'auc_fold5': auc_fold5})\n",
    "    output.update({'params_fold1': params_fold1, 'params_fold2': params_fold2, 'params_fold3': params_fold3, 'params_fold4': params_fold4, 'params_fold5': params_fold5})\n",
    "    if dim==False:\n",
    "        output.update({'predictors_fold1': predictors_fold1, 'predictors_fold2': predictors_fold2, 'predictors_fold3': predictors_fold3, 'predictors_fold4': predictors_fold4, 'predictors_fold5': predictors_fold5})\n",
    "    outputdf = pd.DataFrame(output)\n",
    "#     outputdf.to_csv(Path(p, outputname + \"_\" + traits + '.csv'), index=False)\n",
    "    return outputdf\n",
    "    \n",
    "    print(\"Time for entire process: %0.2fs\" % (time() - tstart))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classify_train(ori_augdf, 'openness', 'log', 'anova', dim=False, n_feat=30, new_augdf=new_augdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_train(ori_augdf, 'conscientiousness', 'log', 'anova', dim=False, n_feat=30, new_augdf=new_augdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_train(ori_augdf, 'extraversion', 'log', 'anova', dim=False, n_feat=30, new_augdf=new_augdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_train(ori_augdf, 'agreeableness', 'log', 'anova', dim=False, n_feat=30, new_augdf=new_augdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_train(ori_augdf, 'neuroticism', 'log', 'anova', dim=False, n_feat=30, new_augdf=new_augdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression on augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df, trait_name):\n",
    "    featuredf = df.drop(['trait'], axis=1, level=0)\n",
    "    try:\n",
    "        featuredf.drop(['text'], axis=1, level=0, inplace=True)\n",
    "    except KeyError:\n",
    "        pass\n",
    "    try:\n",
    "        featuredf.drop(['data'], axis=1, level=0, inplace=True)\n",
    "    except KeyError:\n",
    "        pass\n",
    "    feature_cols = featuredf.columns.tolist()\n",
    "    \n",
    "    x = df[feature_cols]     \n",
    "    y = df['trait', trait_name]\n",
    "    return x,y \n",
    "\n",
    "def get_classifier(classifier):\n",
    "    if classifier == 'linear':\n",
    "        return LinearRegression(n_jobs=-1)\n",
    "    elif classifier == 'rfc_reg':\n",
    "        return RandomForestRegressor(n_jobs=-1)\n",
    "    elif classifier == 'boost_reg':\n",
    "        return GradientBoostingRegressor(random_state=0)\n",
    "\n",
    "    \n",
    "def get_featureselection(fs, classifier, n_feat):\n",
    "    if fs == 'anova':\n",
    "        return SelectKBest(f_classif, k=n_feat)\n",
    "    if fs == 'mutual':\n",
    "        return SelectKBest(mutual_info_classif, k=n_feat)\n",
    "    if fs == 'sequential_forward':\n",
    "        return SequentialFeatureSelector(get_classifier(classifier), n_features_to_select=n_feat, direction='forward', n_jobs=-1)\n",
    "    if fs == 'sequential_backward':\n",
    "        return SequentialFeatureSelector(get_classifier(classifier), n_features_to_select=n_feat, direction='backward', n_jobs=-1)\n",
    "\n",
    "\n",
    "    \n",
    "def create_pipeline_cv(classifier, fs, dim, n_feat):\n",
    "    if dim:\n",
    "        pipeline = Pipeline([\n",
    "              ('variance_threshold', VarianceThreshold()),\n",
    "              ('scaler', StandardScaler()),\n",
    "              ('pca', PCA(n_components=100)),\n",
    "              ('feature_selection',  get_featureselection(fs, classifier, n_feat)),\n",
    "              ('classification', get_classifier(classifier))\n",
    "            ])\n",
    "    else:\n",
    "        pipeline = Pipeline([\n",
    "              ('variance_threshold', VarianceThreshold()),\n",
    "              ('scaler', StandardScaler()),\n",
    "              ('feature_selection',  get_featureselection(fs, classifier, n_feat)),\n",
    "              ('classification', get_classifier(classifier))\n",
    "            ])\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def define_outputname(traits, df, option, fs, dim, n_feat, train=False):\n",
    "    if train:\n",
    "        if len(traits) ==1:\n",
    "            outputname =  \"train_\" +df.name +\"_\" +str(option) +\"_\" +str(fs) +\"_PCA\" +str(dim) +\"_\"+str(n_feat)\n",
    "        else:\n",
    "            outputname =  \"train_\" +df.name +\"_\" +str(option) +\"_\" +str(fs) +\"_PCA\" +str(dim) +\"_\"+str(n_feat)\n",
    " \n",
    "    else:\n",
    "        if len(traits) ==1:\n",
    "            outputname = str(option) +\"_\" +str(fs) +\"_PCA\" +str(dim) +\"_\"+str(n_feat)\n",
    "        else:\n",
    "            outputname = str(option) +\"_\"   +str(fs) +\"_PCA\" +str(dim) +\"_\"+str(n_feat)\n",
    "\n",
    "    return outputname\n",
    "\n",
    "\n",
    "def linear_plot(val_target, y_pred, outputname, trait_name):\n",
    "    linear_plot = sns.regplot(x=val_target, y=y_pred, ci=None,  scatter_kws={\"color\": \"blue\"}, line_kws={\"color\": \"red\"})\n",
    "    # color=\"b\"\n",
    "#     plt.savefig(Path(p, outputname + \"_\" + trait_name + '_ytruepred_plot.png'))\n",
    "    return linear_plot\n",
    "\n",
    "def save_coefficients(coefficients, coef_fold1, coef_fold2, coef_fold3, coef_fold4, coef_fold5, j):\n",
    "    if j==1:\n",
    "        coef_fold1.append(list(coefficients))\n",
    "    elif j==2:\n",
    "        coef_fold2.append(list(coefficients))\n",
    "    elif j==3:\n",
    "        coef_fold3.append(list(coefficients))\n",
    "    elif j==4:\n",
    "        coef_fold4.append(list(coefficients))\n",
    "    elif j==5:\n",
    "        coef_fold5.append(list(coefficients))\n",
    "    return coef_fold1, coef_fold2, coef_fold3, coef_fold4, coef_fold5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regress(df, traits, clf_lst, fs, dim, n_feat,newaugdf, train=False):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        print(\"Current time: \", str(datetime.datetime.now()))\n",
    "        tstart=time()\n",
    "        for option in clf_lst:\n",
    "            print(\"Classifier: \", option, \"\\n\")\n",
    "            outputname = define_outputname(traits, df, option, fs, dim, n_feat)\n",
    "            output = {'Traits': traits}\n",
    "            \n",
    "            # empty lists to save data in csv\n",
    "            predictors_fold1, predictors_fold2, predictors_fold3, predictors_fold4, predictors_fold5 = [],[],[],[],[]\n",
    "            rsquared_traits, mse_traits = [], []\n",
    "            if option == 'linear':\n",
    "                coef_fold1, coef_fold2, coef_fold3, coef_fold4, coef_fold5  = [],[],[],[],[]\n",
    "\n",
    "    \n",
    "            for trait_name in traits:\n",
    "                print(\"\\nTrait to predict: \", trait_name, \"(\", option, \")\\n\")\n",
    "                x,y = split(df, trait_name)\n",
    "                cv_outer = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "                cv_outer_lst = cv_outer.split(x)\n",
    "                \n",
    "                # empty lists for saving        \n",
    "                rsquared_lst, mse_lst, ytrue_lst, ypred_lst = [],[],[],[]\n",
    "\n",
    "                plt.figure(figsize=(7, 7))\n",
    "                p = Path('/home/sophia/ma_py/Big5-NLP/results/')\n",
    "                j=1\n",
    "                for train_idx, val_idx in cv_outer_lst:\n",
    "                    train_data, val_data = x.iloc[train_idx], x.iloc[val_idx]\n",
    "                    train_target, val_target = y.iloc[train_idx], y.iloc[val_idx]\n",
    "                    \n",
    "                    # add augmented data to training\n",
    "                    featuredf, traitdf = split(new_augdf, trait_name)\n",
    "                    for original in train_data.index:\n",
    "                        res = [idx for idx in new_augdf.index if idx[0:(len(original))] == original]\n",
    "                        datarows = featuredf.loc[res][:]\n",
    "                        targetrows = traitdf.loc[res][:]\n",
    "                        train_data = train_data.append(datarows)\n",
    "                        train_target = train_target.append(targetrows)\n",
    "                    \n",
    "                    print(\"Fold No. \", j)\n",
    "                    print(\"Length of train and test: \", len(train_data), len(val_data))\n",
    "                    print(\"Total users in this fold: \", (len(train_data) + len(val_data)))\n",
    "            \n",
    "                    # create pipeline\n",
    "                    clf = create_pipeline_cv(option, fs, dim, n_feat)\n",
    "                    clfnew = clf.fit(train_data, train_target)\n",
    "                    if dim == False:\n",
    "                        names = get_names(train_data, clfnew)\n",
    "                        predictors_fold1, predictors_fold2, predictors_fold3, predictors_fold4, predictors_fold5 = save_predictors(names, predictors_fold1, predictors_fold2, predictors_fold3, predictors_fold4, predictors_fold5, j)\n",
    "                    \n",
    "                    if train: \n",
    "                        y_pred = clfnew.predict(train_data)\n",
    "                        score = clf.score(train_data, train_target)\n",
    "                        mse = mean_squared_error(train_target, y_pred)\n",
    "                        ytrue_lst.append(train_target)\n",
    "                        \n",
    "                    else:\n",
    "                        y_pred = clfnew.predict(val_data)\n",
    "                        score = clf.score(val_data, val_target)\n",
    "                        mse = mean_squared_error(val_target, y_pred)\n",
    "                        ytrue_lst.append(val_target)\n",
    "                        \n",
    "                    ypred_lst.append(y_pred)\n",
    "                        \n",
    "                    if option == 'linear':\n",
    "                        coefficients = clf.named_steps['classification'].coef_\n",
    "                        coef_fold1, coef_fold2, coef_fold3, coef_fold4, coef_fold5 = save_coefficients(coefficients, coef_fold1, coef_fold2, coef_fold3, coef_fold4, coef_fold5, j)\n",
    "                    rsquared_lst.append(score)\n",
    "                    mse_lst.append(mse)\n",
    "\n",
    "\n",
    "\n",
    "                    j+=1\n",
    "                    \n",
    "                    \n",
    "                  # Average results\n",
    "                r_avg = np.mean(rsquared_lst)\n",
    "                rsquared_traits.append(round(r_avg, 4))\n",
    "                mse_avg = np.mean(mse_lst)\n",
    "                mse_traits.append(round(mse_avg, 4))\n",
    "                print(\"Average score (R squared): \", r_avg, \"\\nAverage MSE: \", mse_avg)\n",
    "\n",
    "                all_ytrue = np.concatenate(ytrue_lst)\n",
    "                all_ypred = np.concatenate(ypred_lst)\n",
    "                print(len(all_ytrue))\n",
    "                print(len(all_ypred))\n",
    "                title = 'Regression plot for trait ' + trait_name \n",
    "                plot = linear_plot(all_ytrue, all_ypred, outputname, trait_name)\n",
    "                plt.xlim([1, 101])\n",
    "                plt.ylim([1, 101])\n",
    "                plt.ylabel('True scores')\n",
    "                plt.xlabel('Predicted scores')\n",
    "                plt.axes().set_aspect('equal', 'datalim')\n",
    "                plt.title(title)\n",
    "                plt.savefig(Path(p, outputname + \"_\" + trait_name + '_linearplot.png'))\n",
    "                plt.show()\n",
    "\n",
    "            print(\"Total r squared: \", np.mean(rsquared_traits), \"Total MSE: \", np.mean(mse_traits))\n",
    "            output.update({'rsquared': rsquared_traits, 'MSE': mse_traits})\n",
    "            if dim==False:\n",
    "                output.update({'predictors_fold1': predictors_fold1, 'predictors_fold2': predictors_fold2, 'predictors_fold3': predictors_fold3, 'predictors_fold4': predictors_fold4, 'predictors_fold5': predictors_fold5})\n",
    "            if option=='linear':\n",
    "                output.update({'coef_fold1': coef_fold1, 'coef_fold2': coef_fold2, 'coef_fold3': coef_fold3, 'coef_fold4': coef_fold4, 'coef_fold5': coef_fold5})\n",
    "            outputdf = pd.DataFrame(output)\n",
    "            outputdf.to_csv(Path(p, outputname + '.csv'), index=False)\n",
    "            print(\"Time for entire process: %0.2fs\" % (time() - tstart))\n",
    "\n",
    "            \n",
    "\n",
    "big5_traits = ['openness', 'conscientiousness', 'extraversion', 'agreeableness', 'neuroticism']\n",
    "regres = ['linear', 'rfc_reg', 'boost_reg', 'mlp_reg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regress(ori_augdf, big5_traits, ['linear'], 'anova', dim=False, n_feat=10, newaugdf=new_augdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
