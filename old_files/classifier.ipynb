{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier\n",
    "\n",
    "1. Logistic regression (https://www.datacamp.com/community/tutorials/understanding-logistic-regression-python)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "functions:\n",
    "https://scikit-learn.org/stable/modules/feature_selection.html\n",
    "\n",
    "example:\n",
    "https://scikit-learn.org/stable/auto_examples/feature_selection/plot_feature_selection.html#sphx-glr-auto-examples-feature-selection-plot-feature-selection-py\n",
    "\n",
    "tut:\n",
    "https://medium.com/@GouthamPeri/pipeline-with-tuning-scikit-learn-b2789dca9dc2\n",
    "\n",
    "https://stackoverflow.com/questions/33376078/python-feature-selection-in-pipeline-how-determine-feature-names\n",
    "\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/model_selection/grid_search_text_feature_extraction.html#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/svm/plot_svm_anova.html#sphx-glr-auto-examples-svm-plot-svm-anova-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from time import time\n",
    "import random\n",
    "random.seed(32)\n",
    "import sklearn\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import f1_score, classification_report, precision_recall_curve, roc_auc_score, plot_roc_curve, confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1606 entries, -Areopagan- to zyzee\n",
      "Columns: 18201 entries, ('text', 'body') to ('lda', 'ldahundred')\n",
      "dtypes: float64(2091), int64(16103), object(7)\n",
      "memory usage: 223.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle(\"allfeat_df_allcomments.pkl\")\n",
    "df.info()\n",
    "\n",
    "\n",
    "# allfeat_df_allcomments\n",
    "# wordlists_lin_feat_df_withoutuserfeat_allcomments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">text</th>\n",
       "      <th>data</th>\n",
       "      <th colspan=\"3\" halign=\"left\">post</th>\n",
       "      <th>subreddit</th>\n",
       "      <th colspan=\"3\" halign=\"left\">time</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"3\" halign=\"left\">psych</th>\n",
       "      <th colspan=\"3\" halign=\"left\">lin_feat</th>\n",
       "      <th colspan=\"2\" halign=\"left\">psych</th>\n",
       "      <th colspan=\"2\" halign=\"left\">lda</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>doc_body</th>\n",
       "      <th>utc</th>\n",
       "      <th>score</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>gilded</th>\n",
       "      <th>num_subreddit</th>\n",
       "      <th>mean_time</th>\n",
       "      <th>median_time</th>\n",
       "      <th>max_time</th>\n",
       "      <th>...</th>\n",
       "      <th>valence</th>\n",
       "      <th>arousal</th>\n",
       "      <th>dominance</th>\n",
       "      <th>negations</th>\n",
       "      <th>articles</th>\n",
       "      <th>future</th>\n",
       "      <th>mrc_cmean</th>\n",
       "      <th>mrc_pmean</th>\n",
       "      <th>ldafifty</th>\n",
       "      <th>ldahundred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-Areopagan-</th>\n",
       "      <td>Your first and second question is the same que...</td>\n",
       "      <td>[Your first and second question is the same qu...</td>\n",
       "      <td>[1513882848, 1513744846, 1522253427, 151370438...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2.137261e+06</td>\n",
       "      <td>893447.0</td>\n",
       "      <td>6721687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067701</td>\n",
       "      <td>0.047306</td>\n",
       "      <td>0.066281</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-BigSexy-</th>\n",
       "      <td>I've been asked to cum everywhere with my ex j...</td>\n",
       "      <td>[I've been asked to cum everywhere with my ex ...</td>\n",
       "      <td>[1507650565, 1516397088, 1502590403, 151682490...</td>\n",
       "      <td>4.266714</td>\n",
       "      <td>0.020737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>147</td>\n",
       "      <td>1.003843e+04</td>\n",
       "      <td>760.0</td>\n",
       "      <td>1292061</td>\n",
       "      <td>...</td>\n",
       "      <td>11.312668</td>\n",
       "      <td>7.874620</td>\n",
       "      <td>11.121217</td>\n",
       "      <td>0.716124</td>\n",
       "      <td>1.496246</td>\n",
       "      <td>0.133000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-BlitzN9ne</th>\n",
       "      <td>I'm currently in the middle of making a Payday...</td>\n",
       "      <td>[I'm currently in the middle of making a Payda...</td>\n",
       "      <td>[1422166355, 1423504286, 1449881503, 145521567...</td>\n",
       "      <td>9.644956</td>\n",
       "      <td>0.014159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>116</td>\n",
       "      <td>4.830648e+04</td>\n",
       "      <td>793.5</td>\n",
       "      <td>3039780</td>\n",
       "      <td>...</td>\n",
       "      <td>5.300178</td>\n",
       "      <td>3.868446</td>\n",
       "      <td>5.229659</td>\n",
       "      <td>0.245310</td>\n",
       "      <td>0.523186</td>\n",
       "      <td>0.060885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-CrestiaBell</th>\n",
       "      <td>First and foremost I extend my condolences to ...</td>\n",
       "      <td>[First and foremost I extend my condolences to...</td>\n",
       "      <td>[1462304635, 1528773104, 1513663029, 148131600...</td>\n",
       "      <td>24.890662</td>\n",
       "      <td>0.017687</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>149</td>\n",
       "      <td>1.220542e+04</td>\n",
       "      <td>1365.0</td>\n",
       "      <td>594290</td>\n",
       "      <td>...</td>\n",
       "      <td>29.105901</td>\n",
       "      <td>20.767584</td>\n",
       "      <td>28.330990</td>\n",
       "      <td>0.479159</td>\n",
       "      <td>1.213482</td>\n",
       "      <td>0.076933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-dyad-</th>\n",
       "      <td>I failed both...I'm great at reading people ir...</td>\n",
       "      <td>[I failed both...I'm great at reading people i...</td>\n",
       "      <td>[1475875524, 1473096864, 1505168466, 150318014...</td>\n",
       "      <td>7.234043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>3.799737e+05</td>\n",
       "      <td>57538.0</td>\n",
       "      <td>6062289</td>\n",
       "      <td>...</td>\n",
       "      <td>1.376648</td>\n",
       "      <td>0.948765</td>\n",
       "      <td>1.345483</td>\n",
       "      <td>1.051064</td>\n",
       "      <td>1.765957</td>\n",
       "      <td>0.076596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 18201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           text  \\\n",
       "                                                           body   \n",
       "author                                                            \n",
       "-Areopagan-   Your first and second question is the same que...   \n",
       "-BigSexy-     I've been asked to cum everywhere with my ex j...   \n",
       "-BlitzN9ne    I'm currently in the middle of making a Payday...   \n",
       "-CrestiaBell  First and foremost I extend my condolences to ...   \n",
       "-dyad-        I failed both...I'm great at reading people ir...   \n",
       "\n",
       "                                                                 \\\n",
       "                                                       doc_body   \n",
       "author                                                            \n",
       "-Areopagan-   [Your first and second question is the same qu...   \n",
       "-BigSexy-     [I've been asked to cum everywhere with my ex ...   \n",
       "-BlitzN9ne    [I'm currently in the middle of making a Payda...   \n",
       "-CrestiaBell  [First and foremost I extend my condolences to...   \n",
       "-dyad-        [I failed both...I'm great at reading people i...   \n",
       "\n",
       "                                                           data       post  \\\n",
       "                                                            utc      score   \n",
       "author                                                                       \n",
       "-Areopagan-   [1513882848, 1513744846, 1522253427, 151370438...   2.000000   \n",
       "-BigSexy-     [1507650565, 1516397088, 1502590403, 151682490...   4.266714   \n",
       "-BlitzN9ne    [1422166355, 1423504286, 1449881503, 145521567...   9.644956   \n",
       "-CrestiaBell  [1462304635, 1528773104, 1513663029, 148131600...  24.890662   \n",
       "-dyad-        [1475875524, 1473096864, 1505168466, 150318014...   7.234043   \n",
       "\n",
       "                                            subreddit          time  \\\n",
       "             controversiality    gilded num_subreddit     mean_time   \n",
       "author                                                                \n",
       "-Areopagan-          0.000000  0.000000             1  2.137261e+06   \n",
       "-BigSexy-            0.020737  0.000000           147  1.003843e+04   \n",
       "-BlitzN9ne           0.014159  0.000000           116  4.830648e+04   \n",
       "-CrestiaBell         0.017687  0.000866           149  1.220542e+04   \n",
       "-dyad-               0.000000  0.000000             5  3.799737e+05   \n",
       "\n",
       "                                   ...      psych                        \\\n",
       "             median_time max_time  ...    valence    arousal  dominance   \n",
       "author                             ...                                    \n",
       "-Areopagan-     893447.0  6721687  ...   0.067701   0.047306   0.066281   \n",
       "-BigSexy-          760.0  1292061  ...  11.312668   7.874620  11.121217   \n",
       "-BlitzN9ne         793.5  3039780  ...   5.300178   3.868446   5.229659   \n",
       "-CrestiaBell      1365.0   594290  ...  29.105901  20.767584  28.330990   \n",
       "-dyad-           57538.0  6062289  ...   1.376648   0.948765   1.345483   \n",
       "\n",
       "              lin_feat                         psych                lda  \\\n",
       "             negations  articles    future mrc_cmean mrc_pmean ldafifty   \n",
       "author                                                                    \n",
       "-Areopagan-   3.200000  3.600000  0.400000       0.0       0.0       45   \n",
       "-BigSexy-     0.716124  1.496246  0.133000       0.0       0.0        9   \n",
       "-BlitzN9ne    0.245310  0.523186  0.060885       0.0       0.0       26   \n",
       "-CrestiaBell  0.479159  1.213482  0.076933       0.0       0.0        8   \n",
       "-dyad-        1.051064  1.765957  0.076596       0.0       0.0       12   \n",
       "\n",
       "                         \n",
       "             ldahundred  \n",
       "author                   \n",
       "-Areopagan-           4  \n",
       "-BigSexy-            42  \n",
       "-BlitzN9ne           99  \n",
       "-CrestiaBell         60  \n",
       "-dyad-               85  \n",
       "\n",
       "[5 rows x 18201 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictors = df.columns\n",
    "# i = 0\n",
    "# predictorsfile=open('featurelist.txt','w')\n",
    "# # predictorsfile.writelines(predictors)\n",
    "# for index in range(len(predictors)):\n",
    "#     predictorsfile.write(str(i))\n",
    "#     predictorsfile.write(predictors[index][0])\n",
    "#     predictorsfile.write(\" \")\n",
    "#     predictorsfile.write(predictors[index][1])\n",
    "#     predictorsfile.write('\\n')\n",
    "#     i+=1\n",
    "# predictorsfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # multilevel columns\n",
    "\n",
    "# lst1 = (5)*[\"data\"]\n",
    "# lst9 = (15-5)*[\"traits\"]\n",
    "# lst10 = [\"data\"]\n",
    "# lst2 = (21-17)*[\"global\"]\n",
    "# lst3 = (45-21)*[\"time\"]\n",
    "# lst4 = (16103-45)*[\"subreddits\"]\n",
    "# lst5 = (16116-16103)*[\"extra_features\"]\n",
    "# lst6 = (96308-16116)*[\"word_ngrams\"]\n",
    "# lst7 = (103829-96308)*[\"char_ngrams\"]\n",
    "# lst8 = (103889-103829)*[\"wordlists\"]\n",
    "# lst11 = 2 * [\"lda\"]\n",
    "# headers = lst1 + lst9  + lst10 + lst2 + lst3 + lst4 +lst5 + lst6 + lst7 + lst8 + lst11\n",
    "# columns = df.columns.values\n",
    "# print(len(headers))\n",
    "# print(len(columns))\n",
    "# arrays = [headers] + [columns]\n",
    "# df.columns=pd.MultiIndex.from_arrays(arrays)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = df['subreddits']\n",
    "# test\n",
    "# i=0\n",
    "# for i in range(len(test)):\n",
    "#     print(i)\n",
    "#     print(test.iloc[:, i].to_numpy().nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['traits', 'agree5'] = df['traits', 'agreeableness'].apply(lambda x: 0 if x<20 else(1 if x>19 and x<40 else(2 if x>39 and x<60 else(3 if x>59 and x<80 else 4))))\n",
    "# df['traits', 'openn5'] = df['traits', 'openness'].apply(lambda x: 0 if x<20 else(1 if x>19 and x<40 else(2 if x>39 and x<60 else(3 if x>59 and x<80 else 4))))\n",
    "# df['traits', 'consc5'] = df['traits', 'conscientiousness'].apply(lambda x: 0 if x<20 else(1 if x>19 and x<40 else(2 if x>39 and x<60 else(3 if x>59 and x<80 else 4))))\n",
    "# df['traits', 'extra5'] = df['traits', 'extraversion'].apply(lambda x: 0 if x<20 else(1 if x>19 and x<40 else(2 if x>39 and x<60 else(3 if x>59 and x<80 else 4))))\n",
    "# df['traits', 'neuro5'] = df['traits', 'neuroticism'].apply(lambda x: 0 if x<20 else(1 if x>19 and x<40 else(2 if x>39 and x<60 else(3 if x>59 and x<80 else 4))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.dropna(axis=0, how='all')\n",
    "# df = df.dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text', 'lda', 'post', 'trait', 'data', 'time', 'x_feat', 'lin_feat', 'empath', 'psych', 'subreddit', 'ngram'}\n"
     ]
    }
   ],
   "source": [
    "featurelst = []\n",
    "for i in range(len(predictors)):\n",
    "    featurelst.append(predictors[i][0])\n",
    "featureset = set(featurelst)\n",
    "print(featureset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_wordngrams_df = df[['trait', 'ngram']]\n",
    "log_charngrams_df = df[['trait', 'ngram']]\n",
    "log_wordlists_df =  df[['trait', 'x_feat', 'lin_feat', 'psych', 'empath']]\n",
    "log_posts_df = df[['trait', 'post', 'time', 'subreddit', 'lda']]\n",
    "log_postswithoutsubreddits_df = df[['trait', 'post', 'time', 'lda']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "droplst = []\n",
    "index = 17124\n",
    "for i in range(1000):\n",
    "    index = index+1\n",
    "    droplst.append(predictors[index][1])\n",
    "\n",
    "log_wordngrams_df = log_wordngrams_df.drop(droplst, axis=1, level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">trait</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">ngram</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>agreeableness</th>\n",
       "      <th>openness</th>\n",
       "      <th>conscientiousness</th>\n",
       "      <th>extraversion</th>\n",
       "      <th>neuroticism</th>\n",
       "      <th>big5_a</th>\n",
       "      <th>big5_o</th>\n",
       "      <th>big5_c</th>\n",
       "      <th>big5_e</th>\n",
       "      <th>big5_n</th>\n",
       "      <th>...</th>\n",
       "      <th>y</th>\n",
       "      <th>y s</th>\n",
       "      <th>ye_char</th>\n",
       "      <th>yea</th>\n",
       "      <th>yo</th>\n",
       "      <th>yon</th>\n",
       "      <th>yp</th>\n",
       "      <th>ype</th>\n",
       "      <th>yt</th>\n",
       "      <th>yth</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-Areopagan-</th>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020915</td>\n",
       "      <td>0.021700</td>\n",
       "      <td>0.007215</td>\n",
       "      <td>0.007525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-BigSexy-</th>\n",
       "      <td>39.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043505</td>\n",
       "      <td>0.004567</td>\n",
       "      <td>0.012574</td>\n",
       "      <td>0.004844</td>\n",
       "      <td>0.007757</td>\n",
       "      <td>0.002873</td>\n",
       "      <td>0.003249</td>\n",
       "      <td>0.001611</td>\n",
       "      <td>0.004111</td>\n",
       "      <td>0.003562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-BlitzN9ne</th>\n",
       "      <td>50.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055295</td>\n",
       "      <td>0.004506</td>\n",
       "      <td>0.019322</td>\n",
       "      <td>0.009267</td>\n",
       "      <td>0.009527</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.010355</td>\n",
       "      <td>0.007065</td>\n",
       "      <td>0.006066</td>\n",
       "      <td>0.005993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-CrestiaBell</th>\n",
       "      <td>50.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045581</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.012763</td>\n",
       "      <td>0.005753</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.007740</td>\n",
       "      <td>0.003121</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.006028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-dyad-</th>\n",
       "      <td>60.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049842</td>\n",
       "      <td>0.006174</td>\n",
       "      <td>0.013465</td>\n",
       "      <td>0.005015</td>\n",
       "      <td>0.006789</td>\n",
       "      <td>0.002236</td>\n",
       "      <td>0.016283</td>\n",
       "      <td>0.015979</td>\n",
       "      <td>0.008390</td>\n",
       "      <td>0.008055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zugzwang_03</th>\n",
       "      <td>10.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054066</td>\n",
       "      <td>0.006181</td>\n",
       "      <td>0.014229</td>\n",
       "      <td>0.004873</td>\n",
       "      <td>0.005862</td>\n",
       "      <td>0.004105</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>0.002287</td>\n",
       "      <td>0.004201</td>\n",
       "      <td>0.003870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuluthrone</th>\n",
       "      <td>17.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040346</td>\n",
       "      <td>0.002921</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>0.004398</td>\n",
       "      <td>0.011042</td>\n",
       "      <td>0.005837</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.003213</td>\n",
       "      <td>0.005250</td>\n",
       "      <td>0.004340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwelg</th>\n",
       "      <td>39.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012877</td>\n",
       "      <td>0.013360</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027605</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zymmaster</th>\n",
       "      <td>28.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049808</td>\n",
       "      <td>0.006375</td>\n",
       "      <td>0.019120</td>\n",
       "      <td>0.011743</td>\n",
       "      <td>0.006654</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.007465</td>\n",
       "      <td>0.006780</td>\n",
       "      <td>0.006262</td>\n",
       "      <td>0.005966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zyzee</th>\n",
       "      <td>88.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060042</td>\n",
       "      <td>0.003184</td>\n",
       "      <td>0.025228</td>\n",
       "      <td>0.006282</td>\n",
       "      <td>0.015666</td>\n",
       "      <td>0.013070</td>\n",
       "      <td>0.002163</td>\n",
       "      <td>0.002335</td>\n",
       "      <td>0.012794</td>\n",
       "      <td>0.009632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1606 rows × 1014 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     trait                                          \\\n",
       "             agreeableness openness conscientiousness extraversion   \n",
       "author                                                               \n",
       "-Areopagan-            0.0     99.0              96.0         60.0   \n",
       "-BigSexy-             39.0     92.0               1.0         18.0   \n",
       "-BlitzN9ne            50.0     85.0              15.0         50.0   \n",
       "-CrestiaBell          50.0     85.0              50.0         85.0   \n",
       "-dyad-                60.0     67.0              45.0         10.0   \n",
       "...                    ...      ...               ...          ...   \n",
       "zugzwang_03           10.0     41.0              86.0         83.0   \n",
       "zuluthrone            17.0     96.0              28.0         95.0   \n",
       "zwelg                 39.0     89.0              91.0         80.0   \n",
       "zymmaster             28.0     47.0              62.0         21.0   \n",
       "zyzee                 88.0     78.0              31.0         75.0   \n",
       "\n",
       "                                                             ...     ngram  \\\n",
       "             neuroticism big5_a big5_o big5_c big5_e big5_n  ...        y    \n",
       "author                                                       ...             \n",
       "-Areopagan-          1.0      0      1      1      1      0  ...  0.027200   \n",
       "-BigSexy-            4.0      0      1      0      0      0  ...  0.043505   \n",
       "-BlitzN9ne          30.0      1      1      0      1      0  ...  0.055295   \n",
       "-CrestiaBell        50.0      1      1      1      1      1  ...  0.045581   \n",
       "-dyad-              47.0      1      1      0      0      0  ...  0.049842   \n",
       "...                  ...    ...    ...    ...    ...    ...  ...       ...   \n",
       "zugzwang_03         18.0      0      0      1      1      0  ...  0.054066   \n",
       "zuluthrone          34.0      0      1      0      1      0  ...  0.040346   \n",
       "zwelg                3.0      0      1      1      1      0  ...  0.000000   \n",
       "zymmaster           49.0      0      0      1      0      0  ...  0.049808   \n",
       "zyzee               10.0      1      1      0      1      0  ...  0.060042   \n",
       "\n",
       "                                                                          \\\n",
       "                   y s   ye_char       yea        yo       yon        yp   \n",
       "author                                                                     \n",
       "-Areopagan-   0.000000  0.020915  0.021700  0.007215  0.007525  0.000000   \n",
       "-BigSexy-     0.004567  0.012574  0.004844  0.007757  0.002873  0.003249   \n",
       "-BlitzN9ne    0.004506  0.019322  0.009267  0.009527  0.006000  0.010355   \n",
       "-CrestiaBell  0.005556  0.012763  0.005753  0.012696  0.007740  0.003121   \n",
       "-dyad-        0.006174  0.013465  0.005015  0.006789  0.002236  0.016283   \n",
       "...                ...       ...       ...       ...       ...       ...   \n",
       "zugzwang_03   0.006181  0.014229  0.004873  0.005862  0.004105  0.003795   \n",
       "zuluthrone    0.002921  0.009208  0.004398  0.011042  0.005837  0.007990   \n",
       "zwelg         0.000000  0.012877  0.013360  0.000000  0.000000  0.027605   \n",
       "zymmaster     0.006375  0.019120  0.011743  0.006654  0.003903  0.007465   \n",
       "zyzee         0.003184  0.025228  0.006282  0.015666  0.013070  0.002163   \n",
       "\n",
       "                                            \n",
       "                   ype        yt       yth  \n",
       "author                                      \n",
       "-Areopagan-   0.000000  0.000000  0.000000  \n",
       "-BigSexy-     0.001611  0.004111  0.003562  \n",
       "-BlitzN9ne    0.007065  0.006066  0.005993  \n",
       "-CrestiaBell  0.001219  0.006251  0.006028  \n",
       "-dyad-        0.015979  0.008390  0.008055  \n",
       "...                ...       ...       ...  \n",
       "zugzwang_03   0.002287  0.004201  0.003870  \n",
       "zuluthrone    0.003213  0.005250  0.004340  \n",
       "zwelg         0.000000  0.000000  0.000000  \n",
       "zymmaster     0.006780  0.006262  0.005966  \n",
       "zyzee         0.002335  0.012794  0.009632  \n",
       "\n",
       "[1606 rows x 1014 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worddroplst = []\n",
    "wordindex = 16125\n",
    "for i in range(1000):\n",
    "    wordindex = wordindex+1\n",
    "    worddroplst.append(predictors[wordindex][1])\n",
    "\n",
    "log_charngrams_df = log_charngrams_df.drop(worddroplst, axis=1, level=1)\n",
    "log_charngrams_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_hist_true(df):\n",
    "    plt.figure(figsize = (16, 16))\n",
    "#     plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\n",
    "    plt.subplot(3, 2, 1)\n",
    "    plt.hist(df['trait', 'openness'], bins = 20)\n",
    "    plt.title('Agreeableness')\n",
    "    \n",
    "    plt.subplot(3, 2, 2)\n",
    "    plt.hist(df['trait', 'conscientiousness'], bins = 20)\n",
    "    plt.title('Openness')\n",
    "    \n",
    "    plt.subplot(3, 2, 3)\n",
    "    plt.hist(df['trait', 'extraversion'], bins = 20)\n",
    "    plt.title('Conscientiousness')\n",
    "    \n",
    "    plt.subplot(3, 2, 4)\n",
    "    plt.hist(df['trait', 'agreeableness'], bins = 20)\n",
    "    plt.title('Extraversion')\n",
    "    \n",
    "    plt.subplot(3, 2, 5)\n",
    "    plt.hist(df['trait', 'neuroticism'], bins = 20)\n",
    "    plt.title('Neuroticism')\n",
    "    \n",
    "    plt.suptitle(\"Histograms of the true trait values\")\n",
    "    plt.subplots_adjust(left=0.1, \n",
    "                    bottom=0.1,  \n",
    "                    right=0.9,  \n",
    "                    top=0.9,  \n",
    "                    wspace=0.4,  \n",
    "                    hspace=0.4) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset in features and target variable depending on which trait to focus on\n",
    "def trait(df, classes, trait_name):\n",
    "    featuredf = df.drop(['data', 'trait', 'text'], axis=1, level=0)\n",
    "    feature_cols = featuredf.columns.tolist()\n",
    "    \n",
    "    x = df[feature_cols] \n",
    "    \n",
    "    if classes=='binary':\n",
    "    \n",
    "        if trait_name == 'agreeableness':\n",
    "            y = df['trait', 'big5_o']\n",
    "        elif trait_name == 'openness':\n",
    "            y = df['trait', 'big5_c']\n",
    "        elif trait_name == 'conscientiousness':\n",
    "            y = df['trait', 'big5_e']\n",
    "        elif trait_name == 'extraversion':\n",
    "            y = df['trait', 'big5_a']\n",
    "        elif trait_name == 'neuroticism':\n",
    "            y = df['trait', 'big5_n']   \n",
    "    elif classes=='multi':\n",
    "        if trait_name == 'agreeableness':\n",
    "            y = df['trait', 'big5_o_multi']\n",
    "        elif trait_name == 'openness':\n",
    "            y = df['trait', 'big5_c_multi']\n",
    "        elif trait_name == 'conscientiousness':\n",
    "            y = df['trait', 'big5_e_multi']\n",
    "        elif trait_name == 'extraversion':\n",
    "            y = df['trait', 'big5_a_multi']\n",
    "        elif trait_name == 'neuroticism':\n",
    "            y = df['trait', 'big5_n_multi'] \n",
    "    elif classes=='linear':\n",
    "        if trait_name == 'agreeableness':\n",
    "            y = df['trait', 'agreeableness']\n",
    "        elif trait_name == 'openness':\n",
    "            y = df['trait', 'openness']\n",
    "        elif trait_name == 'conscientiousness':\n",
    "            y = df['trait', 'conscientiousness']\n",
    "        elif trait_name == 'extraversion':\n",
    "            y = df['trait', 'extraversion']\n",
    "        elif trait_name == 'neuroticism':\n",
    "            y = df['trait', 'neuroticism']  \n",
    "    return x,y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOVA feature selection for numeric input and categorical output\n",
    "\n",
    "def create_pipeline(x_train, y_train, classifier, num_feat, weighted):\n",
    "    if weighted==True: \n",
    "        if classifier == \"log\":\n",
    "            pipeline = Pipeline([\n",
    "              ('variance_threshold', VarianceThreshold()),\n",
    "              ('scaler', StandardScaler()),\n",
    "              ('feature_selection',  SelectKBest(f_classif, k=num_feat)),\n",
    "              ('classification', LogisticRegression(class_weight='balanced', max_iter = 200, n_jobs=-1))\n",
    "            ])\n",
    "        elif classifier == \"multilog\":\n",
    "            pipeline = Pipeline([\n",
    "              ('variance_threshold', VarianceThreshold()),\n",
    "              ('scaler', StandardScaler()),\n",
    "              ('feature_selection',  SelectKBest(f_classif, k=num_feat)),\n",
    "              \n",
    "              ('classification', LogisticRegression(class_weight='balanced', multi_class='multinomial', \n",
    "                                                    max_iter = 200, solver='lbfgs', n_jobs=-1))\n",
    "            ])\n",
    "        elif classifier == \"svm\":\n",
    "            pipeline = Pipeline([\n",
    "              ('variance_threshold', VarianceThreshold()),\n",
    "              ('scaler', StandardScaler()),\n",
    "              ('feature_selection',  SelectKBest(f_classif, k=num_feat)),\n",
    "              ('classification', svm.SVC(class_weight='balanced', max_iter = 1000))\n",
    "            ])\n",
    "\n",
    "    else:\n",
    "        if classifier == \"log\":\n",
    "            pipeline = Pipeline([\n",
    "              ('variance_threshold', VarianceThreshold()),\n",
    "              ('scaler', StandardScaler()),\n",
    "              ('feature_selection',  SelectKBest(f_classif, k=num_feat)),\n",
    "              ('classification', LogisticRegression(max_iter = 200, n_jobs=-1))\n",
    "            ])\n",
    "        elif classifier == \"multilog\":\n",
    "            pipeline = Pipeline([\n",
    "              ('variance_threshold', VarianceThreshold()),\n",
    "              ('scaler', StandardScaler()),\n",
    "              ('feature_selection',  SelectKBest(f_classif, k=num_feat)),\n",
    "              ('classification', LogisticRegression(multi_class='multinomial', max_iter = 200, solver='lbfgs', \n",
    "                                                    n_jobs=-1))\n",
    "            ])\n",
    "        elif classifier == \"mlp\":\n",
    "            pipeline = Pipeline([\n",
    "              ('variance_threshold', VarianceThreshold()),\n",
    "              ('scaler', StandardScaler()),\n",
    "              ('feature_selection',  SelectKBest(f_classif, k=num_feat)),\n",
    "              ('classification', MLPClassifier(hidden_layer_sizes=(3,)))\n",
    "            ])\n",
    "        elif classifier == \"svm\":\n",
    "            pipeline = Pipeline([\n",
    "              ('variance_threshold', VarianceThreshold()),\n",
    "              ('scaler', StandardScaler()),\n",
    "              ('feature_selection',  SelectKBest(f_classif, k=num_feat)),\n",
    "              ('classification', svm.SVC(max_iter = 1000))\n",
    "            ])\n",
    "        elif classifier == \"svmlinear\":\n",
    "            pipeline = Pipeline([\n",
    "              ('variance_threshold', VarianceThreshold()),\n",
    "              ('scaler', StandardScaler()),\n",
    "              ('feature_selection',  SelectKBest(f_classif, k=num_feat)),\n",
    "              ('classification', svm.LinearSVC(max_iter = 1000))\n",
    "            ])\n",
    "        elif classifier == \"knn\":\n",
    "            pipeline = Pipeline([\n",
    "              ('variance_threshold', VarianceThreshold()),\n",
    "              ('scaler', StandardScaler()),\n",
    "              ('feature_selection',  SelectKBest(f_classif, k=num_feat)),\n",
    "              ('classification', KNeighborsClassifier(n_neighbors=1, n_jobs=-1))\n",
    "            ])\n",
    "        elif classifier == \"linear\":\n",
    "            pipeline = Pipeline([\n",
    "              ('variance_threshold', VarianceThreshold()),\n",
    "              ('scaler', StandardScaler()),\n",
    "              ('feature_selection',  SelectKBest(f_classif, k=num_feat)),\n",
    "              ('classification', LinearRegression(n_jobs=-1))\n",
    "            ])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get names of 30 most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get names of the features\n",
    "def get_names(x, pipeline):\n",
    "    features = pipeline.named_steps['feature_selection']\n",
    "    names = x.columns[features.get_support(indices=True)]\n",
    "    return names\n",
    "# names = get_names(logpipe)\n",
    "# print(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pvalues(pipeline, x):\n",
    "#     x_indices = np.arange(x.shape[-1])\n",
    "#     selector = SelectKBest(f_classif, k=30)\n",
    "#     selector.fit(x_train, y_train)\n",
    "#     scores = -np.log10(selector.pvalues_)\n",
    "    features = pipeline.named_steps['feature_selection']\n",
    "    pvalues = features.pvalues_\n",
    "#     pvalues /= pvalues.max()\n",
    "    dfpvalues = pd.DataFrame(features.pvalues_)\n",
    "    dfscores = pd.DataFrame(features.scores_)\n",
    "    dfcolumns = pd.DataFrame(x.columns)\n",
    "    #concat two dataframes for better visualization \n",
    "    featureScores = pd.concat([dfcolumns,dfscores, dfpvalues],axis=1)\n",
    "    featureScores.columns = ['specs','score', 'pvalue']\n",
    "    featureScores.sort_values(by='pvalue')\n",
    "\n",
    "    plt.figure(figsize = (12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(pvalues, bins=20)\n",
    "    plt.title('All p-values')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    smallpvalues = pvalues[pvalues<0.1]\n",
    "    plt.hist(smallpvalues, bins=10)\n",
    "    plt.title('Small p-values')\n",
    "    \n",
    "    plt.suptitle(\"Histograms of the p-values\")\n",
    "    plt.subplots_adjust(left=0.1, \n",
    "                    bottom=0.1,  \n",
    "                    right=0.9,  \n",
    "                    top=0.9,  \n",
    "                    wspace=0.4,  \n",
    "                    hspace=0.4) \n",
    "    plt.show()\n",
    "    \n",
    "    return featureScores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def scores(y_test, y_pred, presentationtype):\n",
    "    \n",
    "    if presentationtype == \"scores\":\n",
    "        accuracy=metrics.accuracy_score(y_test, y_pred)\n",
    "        precision=metrics.precision_score(y_test, y_pred)\n",
    "        recall=metrics.recall_score(y_test, y_pred)\n",
    "        f_one=metrics.f1_score(y_test, y_pred)\n",
    "        return accuracy, precision, recall, f_one\n",
    "    if presentationtype == \"report\":\n",
    "        report = classification_report(y_test, y_pred)\n",
    "        return report\n",
    "\n",
    "\n",
    "def score_plot(logreg, y_test, x_test):\n",
    "    lr_probs = logreg.predict_proba(x_test)\n",
    "    # keep probabilities for the positive outcome only\n",
    "    lr_probs = lr_probs[:, 1]\n",
    "    # predict class values\n",
    "#     yhat = logreg.predict(x_test)\n",
    "    lr_precision, lr_recall, _ = precision_recall_curve(y_test, lr_probs)\n",
    "#     lr_f1, lr_auc = f1_score(y_test, yhat), auc(lr_recall, lr_precision)\n",
    "\n",
    "    # plot the precision-recall curves\n",
    "    no_skill = len(y_test[y_test==1]) / len(y_test)\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "    plt.plot(lr_recall, lr_precision, marker='.', label='Classifier')\n",
    "    # axis labels\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    # show the legend\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return lr_precision, lr_recall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score plot\n",
    "Smaller values on the x-axis of the plot indicate lower false positives and higher true negatives.\n",
    "\n",
    "\n",
    "Larger values on the y-axis of the plot indicate higher true positives and lower false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and print confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnfmatrix(clf, x_test, y_test, y_pred, plotting, detailed):\n",
    "    cnfpipe_matrix = confusion_matrix(y_test, y_pred)\n",
    "#     print(cnfpipe_matrix)\n",
    "#     disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cnfpipe_matrixcmap=plt.cm.Blues, normalize=normalize)\n",
    "#     disp.plot() \n",
    "    if detailed:\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        sumpositive = tp + fn\n",
    "        sumnegative = fp + tn\n",
    "        sumcorrect = tp + tn\n",
    "        sumwrong = fp + fn\n",
    "        sumall = tn+fp+fn+tp\n",
    "        print(\"TN, FP, FN, TP: \", tn, fp, fn, tp, \"\\nSum: \", sumall, \"\\nSum correct predictions: \", \n",
    "              sumcorrect, \"Percent: \", sumcorrect/sumall, \"\\nSum wrong predictions: \", sumwrong, \"\\tPercent: \",\n",
    "              sumwrong/sumall, \"\\nSum actual positives: \", sumpositive, \"\\tPercent: \", sumpositive/sumall,\n",
    "              \"\\nSum actual negatives: \", sumnegative, \"\\tPercent: \", sumnegative/sumall)\n",
    "\n",
    "    if plotting:\n",
    "#         %matplotlib inline\n",
    "#         class_names=[0,1] # name  of classes\n",
    "#         fig, ax = plt.subplots()\n",
    "#         tick_marks = np.arange(len(class_names))\n",
    "#         plt.xticks(tick_marks, class_names)\n",
    "#         plt.yticks(tick_marks, class_names)\n",
    "#         # create heatmap\n",
    "#         sns.heatmap(pd.DataFrame(cnfpipe_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "#         ax.xaxis.set_label_position(\"bottom\")\n",
    "#         disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cnfpipe_matrix, cmap=plt.cm.Blues, normalize=normalize)\n",
    "#         disp.plot() \n",
    "        plot_confusion_matrix(clf, x_test, y_test,\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize='true')\n",
    "#         disp.ax_.set_title('Confusion matrix')\n",
    "        plt.tight_layout()\n",
    "        plt.title('Confusion matrix', y=1.1)\n",
    "        plt.ylabel('Actual label')\n",
    "        plt.xlabel('Predicted label')\n",
    "#         disp.plot() \n",
    "        plt.show()\n",
    "        \n",
    "# cnfmatrix = create_cnfmatrix(y_test, y_pred, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_aucscore(clf, x_test, y_test, classes, plotting, detailed):\n",
    "    if detailed:\n",
    "        print(roc_auc_score(y, clf.predict_proba(x), multi_class='ovo'))\n",
    "        return score\n",
    "    \n",
    "    if plotting and classes == 'binary':\n",
    "        plot_roc_curve(clf, x_test, y_test)\n",
    "        plt.title('ROC Curve', y=1.1)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapper\n",
    "\n",
    "\n",
    "nested stratified cv:\n",
    "https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html#sphx-glr-auto-examples-model-selection-plot-nested-cross-validation-iris-py\n",
    "\n",
    "https://weina.me/nested-cross-validation/\n",
    "\n",
    "\n",
    "https://towardsdatascience.com/nested-cross-validation-hyperparameter-optimization-and-model-selection-5885d84acda\n",
    "https://gist.github.com/krsatyam1996/9640ed8baa20d3dc11822564710a8d71#file-nested_cv-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "traits = ['openness', 'conscientiousness', 'extraversion', 'agreeableness', 'neuroticism']\n",
    "\n",
    "def switching(trait):\n",
    "    switcher={\n",
    "            'openness':30,\n",
    "            'conscientiousness': 30,\n",
    "            'agreeableness': 30,\n",
    "            'extraversion': 30,\n",
    "            'neuroticism':30\n",
    "         }\n",
    "    return switcher.get(trait,\"Invalid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(df, classifier, classes, trainscores=False, plotting = False, weighted = False, detailed=False):\n",
    "    for trait_name in traits:\n",
    "        num_feat = switching(trait_name)\n",
    "        print(\"Trait to predict: \", trait_name)\n",
    "        x,y = trait(df, classes,trait_name)\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=0)\n",
    "#         scores = cross_val_scores(pipeline,X_train,y_train,cv=5,scoring='f1_macro')\n",
    "        if trainscores:\n",
    "            x_test = x_train\n",
    "            y_test = y_train\n",
    "        if detailed: \n",
    "            print(\"Number of authors in y_train: \", len(y_train))\n",
    "            print(\"Number of authors in y_test: \", len(y_test))\n",
    "        clf = create_pipeline(x_train, y_train, classifier, num_feat, weighted)\n",
    "        clf.fit(x_train, y_train)\n",
    "        y_pred=clf.predict(x_test)\n",
    "        if classes=='linear':\n",
    "            print(\"Score (Reg: r sqared, SVM: accuracy): \", clf.score(x_test, y_test))\n",
    "#             print(y_pred)    \n",
    "        else:\n",
    "            if detailed:\n",
    "                print(\"Number of authors in y_pred: \", len(y_pred))\n",
    "                names = get_names(x, clf)\n",
    "                print(\"Names of the top\", len(names), \"features: \\n\", names, \"\\n\")\n",
    "                pvalues = get_pvalues(clf, x)\n",
    "            #     print(\"p-values of\", len(pvalues), \"features: \\n\", pvalues, \"\\n\")\n",
    "                if trait_name==\"openness\":\n",
    "                    count = pvalues['pvalue'].le(0.02).sum()\n",
    "                if trait_name==\"conscientiousness\":\n",
    "                    count = pvalues['pvalue'].le(0.07).sum()\n",
    "                if trait_name==\"extraversion\":\n",
    "                    count = pvalues['pvalue'].le(0.05).sum()\n",
    "                if trait_name==\"agreeableness\":\n",
    "                    count = pvalues['pvalue'].le(0.04).sum()\n",
    "                if trait_name==\"neuroticism\":\n",
    "                    count = pvalues['pvalue'].le(0.04).sum()\n",
    "                print(\"Number of features with this threshold: \", count)\n",
    "        #         print(\"\\nP-Values: \\nNumber of features: \", 30)\n",
    "        #         print(pvalues.nsmallest(count,'pvalue'))\n",
    "                print(\"\\n\")\n",
    "            report = scores(y_test, y_pred, \"report\")\n",
    "            print(\"Classification report: \\n\", report)\n",
    "            if plotting: \n",
    "                cnfmatrix = create_cnfmatrix(clf, x_test, y_test, y_pred, plotting, detailed) \n",
    "                rocplot = roc_aucscore(clf, x_test, y_test, classes, plotting, detailed)\n",
    "        #     accuracy, precision, recall, f_one = scores(y_test, y_pred, \"scores\")\n",
    "        #     print(\"Scores:\\nAccuracy:\",accuracy, \"\\nPrecision:\",precision, \"\\nRecall:\",recall, \"\\nF1 score:\",f_one)\n",
    "                if (classifier == 'log' and classes == 'binary'):\n",
    "                    lr_precision, lr_recall = score_plot(clf, y_test, x_test)\n",
    "            plt.show()\n",
    "    #     print(\"Scores:\\nLR_Precision:\",lr_precision, \"\\nLR_Recall:\",lr_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper with nested stratified cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline_cv(classifier, num_feat):\n",
    "    if classifier == \"mcc\":\n",
    "        pipeline = Pipeline([\n",
    "          ('variance_threshold', VarianceThreshold()),\n",
    "          ('scaler', StandardScaler()),\n",
    "          ('feature_selection',  SelectKBest(f_classif, k=num_feat)),\n",
    "          ('classification', DummyClassifier(strategy=\"most_frequent\"))\n",
    "        ])\n",
    "    if classifier == \"log\":\n",
    "        pipeline = Pipeline([\n",
    "          ('variance_threshold', VarianceThreshold()),\n",
    "          ('scaler', StandardScaler()),\n",
    "          ('feature_selection',  SelectKBest(f_classif, k=num_feat)),\n",
    "          ('classification', LogisticRegression(class_weight='balanced'))\n",
    "        ])\n",
    "    elif classifier == \"multilog\":\n",
    "        pipeline = Pipeline([\n",
    "          ('variance_threshold', VarianceThreshold()),\n",
    "          ('scaler', StandardScaler()),\n",
    "          ('feature_selection',  SelectKBest(f_classif, k=num_feat)),\n",
    "          ('classification', LogisticRegression(multi_class='multinomial', n_jobs=-1))\n",
    "        ])\n",
    "    elif classifier == \"mlp\":\n",
    "        pipeline = Pipeline([\n",
    "          ('variance_threshold', VarianceThreshold()),\n",
    "          ('scaler', StandardScaler()),\n",
    "          ('feature_selection',  SelectKBest(f_classif, k=num_feat)),\n",
    "          ('classification', MLPClassifier())\n",
    "        ])\n",
    "#         n_layers_=3\n",
    "    elif classifier == \"svm\":\n",
    "        pipeline = Pipeline([\n",
    "          ('variance_threshold', VarianceThreshold()),\n",
    "          ('scaler', StandardScaler()),\n",
    "          ('feature_selection',  SelectKBest(f_classif, k=num_feat)),\n",
    "          ('classification', svm.SVC(class_weight='balanced', probability=True))\n",
    "        ])\n",
    "    elif classifier == \"svmlinear\":\n",
    "        pipeline = Pipeline([\n",
    "          ('variance_threshold', VarianceThreshold()),\n",
    "          ('scaler', StandardScaler()),\n",
    "          ('feature_selection',  SelectKBest(f_classif, k=num_feat)),\n",
    "          ('classification', svm.LinearSVC())\n",
    "        ])\n",
    "    elif classifier == \"knn\":\n",
    "        pipeline = Pipeline([\n",
    "          ('variance_threshold', VarianceThreshold()),\n",
    "          ('scaler', StandardScaler()),\n",
    "          ('feature_selection',  SelectKBest(f_classif, k=num_feat)),\n",
    "          ('classification', KNeighborsClassifier(n_neighbors=1, n_jobs=-1))\n",
    "        ])\n",
    "    elif classifier == \"linear\":\n",
    "        pipeline = Pipeline([\n",
    "          ('variance_threshold', VarianceThreshold()),\n",
    "          ('scaler', StandardScaler()),\n",
    "          ('feature_selection',  SelectKBest(f_classif, k=num_feat)),\n",
    "          ('classification', LinearRegression(n_jobs=-1))\n",
    "        ])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(classifier):\n",
    "    if classifier == 'log':\n",
    "        params = {'classification__solver': ['lbfgs', 'liblinear', 'saga'], \n",
    "                  'classification__max_iter': [100, 200, 500, 1000],\n",
    "                  'classification__C': [10**x for x in range(-3,5)]}\n",
    "    if classifier == 'multilog':\n",
    "        params = {'classification__class_weight': [None, 'balanced'], \n",
    "                  'classification__solver': ['lbfgs', 'saga'], \n",
    "                  'classification__max_iter': [100, 200, 500, 1000]}\n",
    "    elif classifier == 'mlp':\n",
    "        params = {'classification__hidden_layer_sizes': [(50,), (100,), (200,), (500,)]}\n",
    "    elif classifier == 'svm':\n",
    "        params = {'classification__kernel': ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'],\n",
    "                  'classification__gamma': ['scale', 'auto'], \n",
    "                  'classification__max_iter': [100, 200, 500, 1000],\n",
    "                  'classification__C': [10**x for x in range(-3,5)]}\n",
    "    elif classifier == 'mcc':\n",
    "        params = {}\n",
    "    return params\n",
    "# 'classification__class_weight': ['balanced'], \n",
    "\n",
    "def classify_cv(df, classes, clf_lst):\n",
    "    for option in tqdm(clf_lst):\n",
    "        print(\"Classifier: \", option, \"\\n\")\n",
    "        for trait_name in tqdm(traits):\n",
    "            num_feat = switching(trait_name)\n",
    "            print(\"\\nTrait to predict: \", trait_name, \"\\n\")\n",
    "            x,y = trait(df, classes, trait_name)          \n",
    "            \n",
    "            cv_outer = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "            cv_outer_lst = cv_outer.split(x, y)\n",
    "\n",
    "            f1macro_lst = []\n",
    "            for train_idx, val_idx in tqdm(cv_outer_lst):\n",
    "                train_data, val_data = x.iloc[train_idx], x.iloc[val_idx]\n",
    "                train_target, val_target = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "                print(\"\\n\\tCreate pipeline with\", option, \"...\")\n",
    "                clf = create_pipeline_cv(option, num_feat)\n",
    "                if option == 'log':\n",
    "                    cv_inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "                if option == 'svm' or option == 'mlp' or option == 'mcc':\n",
    "                    cv_inner = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "                params = get_params(option)\n",
    "                print(\"\\tStart grid search...\")\n",
    "                t0 = time()\n",
    "                gd_search = GridSearchCV(clf, params, scoring='f1_macro', n_jobs=-1, cv=cv_inner).fit(train_data, train_target)\n",
    "                print(\"\\tGrid search done in %0.3fs\" % (time() - t0))\n",
    "                print(\"\\tGet best model...\")\n",
    "                best_model = gd_search.best_estimator_\n",
    "                print(best_model)\n",
    "\n",
    "                print(\"\\tFit best model...\")\n",
    "                clfnew = best_model.fit(train_data, train_target)\n",
    "                y_pred = clfnew.predict(val_data)\n",
    "                f1_macro = f1_score(val_target, y_pred, average='macro')\n",
    "                f1macro_lst.append(f1_macro)\n",
    "                print(\"Val Acc:\",f1_macro , \"Best GS Acc:\",gd_search.best_score_, \"Best Params:\",gd_search.best_params_)\n",
    "\n",
    "              # Training final model\n",
    "            f1macro_avg = np.mean(f1macro_lst)\n",
    "            print(\"Average f1 macro score: \", f1macro_avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if option == 'log':\n",
    "#                 inner_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "#             if option == 'svm' or option == 'mlp':\n",
    "#                 inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "#             outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "#             pipeline = create_pipeline_cv(X_train, y_train, option, num_feat)\n",
    "#             if option == 'log' or option == 'svm' or option=='mlp':\n",
    "#                 t0 = time()\n",
    "#                 print(\"\\tStart grid search (inner cv)...\")\n",
    "#                 params = get_params(option)\n",
    "#                 clf = GridSearchCV(estimator=pipeline, param_grid=params, scoring='f1_macro', n_jobs=-1, cv=inner_cv)\n",
    "#                 clf.fit(X_train, y_train)\n",
    "#                 print(\"\\tGrid search done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "#                 best_model = clf.best_estimator_\n",
    "#                 print(\"\\tBest model: \", best_model)\n",
    "#                 t1 = time()\n",
    "#                 print(\"\\tStart cross validation (outer)...\")\n",
    "#                 nested_score = cross_val_score(clf, X=X_train, y=y_train, scoring='f1_macro', n_jobs=-1, cv=outer_cv)\n",
    "#                 print(\"\\tCross_val_score calculated in %0.3fs\" % (time() - t1))\n",
    "#                 score = nested_score.mean()\n",
    "#                 print(\"Score: \", score)\n",
    "#             else:\n",
    "#                 best_model = pipeline\n",
    "#                 t0 = time()\n",
    "#                 print(\"\\tStart cross validation...\")\n",
    "#                 nested_score = cross_val_score(pipeline, X=X_train, y=y_train, scoring='f1_macro', n_jobs=-1, cv=outer_cv)\n",
    "#                 print(\"\\tCross_val_score calculated in %0.3fs\" % (time() - t0))\n",
    "#                 score = nested_score.mean()\n",
    "#                 print(\"Score: \", score)\n",
    "            \n",
    "#             print(\"Computing final model...\")\n",
    "#             model = best_model.fit(X_train, y_train)\n",
    "#             names = get_names(x, model)\n",
    "#             print(\"Names of the top\", len(names), \"features: \\n\", names, \"\\n\")\n",
    "#             y_pred_prob = model.predict_proba(X_test)[:,1]\n",
    "#             y_pred = model.predict(X_test)\n",
    "#             print(\"AUC\", roc_auc_score(y_test, y_pred_prob))\n",
    "#             report = scores(y_test, y_pred, \"report\")\n",
    "#             print(\"Classification report: \\n\", report) \n",
    "#             cnfmatrix = create_cnfmatrix(model, X_test, y_test, y_pred, plotting=True, detailed=False) \n",
    "#             rocplot = roc_aucscore(model, X_test, y_test, classes, plotting=True, detailed=False)\n",
    "#             plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodological replication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e818b56253d4447a981aac786dc0195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:  mcc \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c36a8138270446d2a84f261a6a62c415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trait to predict:  openness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7671149dbf945bea359667ef0b92547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 5.597s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.3831417624521073 Best GS Acc: 0.3829883396341315 Best Params: {}\n",
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 3.138s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.38269230769230766 Best GS Acc: 0.3831004427227449 Best Params: {}\n",
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 3.079s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.38269230769230766 Best GS Acc: 0.3831004427227449 Best Params: {}\n",
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 3.035s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.38269230769230766 Best GS Acc: 0.3831004427227449 Best Params: {}\n",
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.612s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.38387715930902105 Best GS Acc: 0.38280414130234275 Best Params: {}\n",
      "Average f1 macro score:  0.3830191689676103\n",
      "\n",
      "Trait to predict:  conscientiousness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e5350456dc04e87a4696f3b63c6cfd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.661s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.39245283018867927 Best GS Acc: 0.39233278864349774 Best Params: {}\n",
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.632s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.39204545454545453 Best GS Acc: 0.3924349881796691 Best Params: {}\n",
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.761s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.39204545454545453 Best GS Acc: 0.3924349881796691 Best Params: {}\n",
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.652s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.39204545454545453 Best GS Acc: 0.3924349881796691 Best Params: {}\n",
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.748s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.3931947069943289 Best GS Acc: 0.39214704267643674 Best Params: {}\n",
      "Average f1 macro score:  0.3923567801638744\n",
      "\n",
      "Trait to predict:  extraversion \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1afe7d7e2069429cae99c38d7c618b17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.611s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.3598409542743539 Best GS Acc: 0.3605572139303483 Best Params: {}\n",
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.630s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.36055776892430275 Best GS Acc: 0.36037766280815375 Best Params: {}\n",
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.648s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.36055776892430275 Best GS Acc: 0.36037766280815375 Best Params: {}\n",
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.641s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.36055776892430275 Best GS Acc: 0.36037766280815375 Best Params: {}\n",
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.627s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.36055776892430275 Best GS Acc: 0.36037766280815375 Best Params: {}\n",
      "Average f1 macro score:  0.36041440599431296\n",
      "\n",
      "Trait to predict:  agreeableness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ce16946af2b4850937681b6bcedfdc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.618s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.41666666666666663 Best GS Acc: 0.4163634649690621 Best Params: {}\n",
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.871s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.4163636363636364 Best GS Acc: 0.4164388785817358 Best Params: {}\n",
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.604s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.4163636363636364 Best GS Acc: 0.4164388785817358 Best Params: {}\n",
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.632s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.4163636363636364 Best GS Acc: 0.4164388785817358 Best Params: {}\n",
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.608s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.4163636363636364 Best GS Acc: 0.4164388785817358 Best Params: {}\n",
      "Average f1 macro score:  0.4164242424242425\n",
      "\n",
      "Trait to predict:  neuroticism \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83fef3f644e54fae83c82174cd38a315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.637s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.33608247422680415 Best GS Acc: 0.3360913630825668 Best Params: {}\n",
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.621s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.33540372670807456 Best GS Acc: 0.33625962332507525 Best Params: {}\n",
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.656s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.33540372670807456 Best GS Acc: 0.33625962332507525 Best Params: {}\n",
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.666s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.3367768595041322 Best GS Acc: 0.3359173126614987 Best Params: {}\n",
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.824s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.3367768595041322 Best GS Acc: 0.3359173126614987 Best Params: {}\n",
      "Average f1 macro score:  0.3360887293302436\n",
      "Classifier:  log \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "952bac251a264078b6fe73f1908e985c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trait to predict:  openness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd7085efb64044189bae2ac48fcd9f91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 230.346s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced',\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5827242662685701 Best GS Acc: 0.4992020845897178 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 234.333s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced',\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.537833946568549 Best GS Acc: 0.5377906602456449 Best Params: {'classification__C': 0.1, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 233.882s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5216673378977044 Best GS Acc: 0.5719979996597322 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 235.058s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.543997077684877 Best GS Acc: 0.5433688122951021 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 232.059s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5322215025906736 Best GS Acc: 0.5418202500667647 Best Params: {'classification__C': 0.1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "Average f1 macro score:  0.5436888262020748\n",
      "\n",
      "Trait to predict:  conscientiousness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eb0b73251984f86bc8a7a554dd2a22b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 236.565s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced',\n",
      "                                    solver='saga'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5980186855670102 Best GS Acc: 0.5658298907163929 Best Params: {'classification__C': 1, 'classification__max_iter': 100, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 234.095s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5178981708954555 Best GS Acc: 0.5433507269353494 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 233.684s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=100, class_weight='balanced',\n",
      "                                    max_iter=200))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5808557653676174 Best GS Acc: 0.5372678430681639 Best Params: {'classification__C': 100, 'classification__max_iter': 200, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 236.503s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.6232593548114236 Best GS Acc: 0.5351061473584406 Best Params: {'classification__C': 1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 234.494s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced',\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5152244897959184 Best GS Acc: 0.5479335796034799 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "Average f1 macro score:  0.5670512932874849\n",
      "\n",
      "Trait to predict:  extraversion \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a44213c3fd546d98dbceacd039a7a3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 233.249s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced',\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5397450482774715 Best GS Acc: 0.5740825665174177 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 232.201s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5523366796894318 Best GS Acc: 0.5787477935897274 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 234.340s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5501401432575521 Best GS Acc: 0.5646882351340808 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 237.252s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    max_iter=200, solver='saga'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.6138846240355184 Best GS Acc: 0.5745017632051045 Best Params: {'classification__C': 0.001, 'classification__max_iter': 200, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 237.232s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5988126855178878 Best GS Acc: 0.5736852184339194 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "Average f1 macro score:  0.5709838361555724\n",
      "\n",
      "Trait to predict:  agreeableness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7be04236412645169aea5945dea10710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 233.488s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5084983498349835 Best GS Acc: 0.5338507496025126 Best Params: {'classification__C': 0.1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 235.260s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.6074004975124379 Best GS Acc: 0.5178109918713596 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 232.749s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5541666666666667 Best GS Acc: 0.5231322714221102 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 234.077s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5139807200043571 Best GS Acc: 0.544830674573662 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 232.020s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=100, class_weight='balanced',\n",
      "                                    max_iter=200, solver='saga'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5229334289960539 Best GS Acc: 0.5328110185949075 Best Params: {'classification__C': 100, 'classification__max_iter': 200, 'classification__solver': 'saga'}\n",
      "Average f1 macro score:  0.5413959326028998\n",
      "\n",
      "Trait to predict:  neuroticism \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdade26cb01a49b8be7e0ca5471b0b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 236.964s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5866335916913603 Best GS Acc: 0.5703980338469818 Best Params: {'classification__C': 0.1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 230.664s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced',\n",
      "                                    solver='saga'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.532160901671201 Best GS Acc: 0.5757660848918474 Best Params: {'classification__C': 1, 'classification__max_iter': 100, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 233.183s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=10, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5762211695270638 Best GS Acc: 0.5798813330929906 Best Params: {'classification__C': 10, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 232.197s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=10, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5695880295375049 Best GS Acc: 0.590073402763868 Best Params: {'classification__C': 10, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 236.340s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced',\n",
      "                                    solver='saga'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.581640989729225 Best GS Acc: 0.5816016544875616 Best Params: {'classification__C': 1, 'classification__max_iter': 100, 'classification__solver': 'saga'}\n",
      "Average f1 macro score:  0.569248936431271\n",
      "Classifier:  mlp \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71af94fdf7cb47f2aa0d71e23ee3dce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trait to predict:  openness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a5d8c04443d4bfd854c389e13483fd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 12.353s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier())])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5552036656446886 Best GS Acc: 0.5161185355716432 Best Params: {'classification__hidden_layer_sizes': (100,)}\n",
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 12.141s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier(hidden_layer_sizes=(50,)))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5312869704236611 Best GS Acc: 0.5163846200495461 Best Params: {'classification__hidden_layer_sizes': (50,)}\n",
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 13.045s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier(hidden_layer_sizes=(200,)))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5350137982807659 Best GS Acc: 0.5455538292955218 Best Params: {'classification__hidden_layer_sizes': (200,)}\n",
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 13.089s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier(hidden_layer_sizes=(200,)))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5520005876365468 Best GS Acc: 0.5296261740356882 Best Params: {'classification__hidden_layer_sizes': (200,)}\n",
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 11.835s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier(hidden_layer_sizes=(50,)))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5059179449073828 Best GS Acc: 0.5335919547036866 Best Params: {'classification__hidden_layer_sizes': (50,)}\n",
      "Average f1 macro score:  0.535884593378609\n",
      "\n",
      "Trait to predict:  conscientiousness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7b0ad1a7c9244a7b8d8427506cf1287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 12.334s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier())])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5760368663594471 Best GS Acc: 0.5694637156868737 Best Params: {'classification__hidden_layer_sizes': (100,)}\n",
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 12.943s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier(hidden_layer_sizes=(200,)))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5569383448354531 Best GS Acc: 0.5534627051400767 Best Params: {'classification__hidden_layer_sizes': (200,)}\n",
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 12.879s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier(hidden_layer_sizes=(200,)))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5178070849843279 Best GS Acc: 0.5384067725307901 Best Params: {'classification__hidden_layer_sizes': (200,)}\n",
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 13.138s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier(hidden_layer_sizes=(200,)))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5567930780559647 Best GS Acc: 0.5683635815698299 Best Params: {'classification__hidden_layer_sizes': (200,)}\n",
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 12.064s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier())])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.48590647021140293 Best GS Acc: 0.5471995297702916 Best Params: {'classification__hidden_layer_sizes': (100,)}\n",
      "Average f1 macro score:  0.5386963688893192\n",
      "\n",
      "Trait to predict:  extraversion \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "362a95e097cc4281905dbbe4ab2a43dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 12.299s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier())])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5842723004694836 Best GS Acc: 0.5607802212584285 Best Params: {'classification__hidden_layer_sizes': (100,)}\n",
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 11.716s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier(hidden_layer_sizes=(50,)))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5485232067510548 Best GS Acc: 0.5515981039448825 Best Params: {'classification__hidden_layer_sizes': (50,)}\n",
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 11.932s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier(hidden_layer_sizes=(50,)))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5276812972323708 Best GS Acc: 0.5600240016335587 Best Params: {'classification__hidden_layer_sizes': (50,)}\n",
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 11.983s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier(hidden_layer_sizes=(50,)))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.6056987515102699 Best GS Acc: 0.5500929806198513 Best Params: {'classification__hidden_layer_sizes': (50,)}\n",
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 12.280s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier(hidden_layer_sizes=(50,)))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.558450357230845 Best GS Acc: 0.5404483836898273 Best Params: {'classification__hidden_layer_sizes': (50,)}\n",
      "Average f1 macro score:  0.5649251826388049\n",
      "\n",
      "Trait to predict:  agreeableness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a99b73f6b4404140bd8a09d913fad6e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 15.428s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier(hidden_layer_sizes=(500,)))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5008932324506096 Best GS Acc: 0.5273987143392158 Best Params: {'classification__hidden_layer_sizes': (500,)}\n",
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 12.247s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier())])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5346359911755436 Best GS Acc: 0.5043822685027834 Best Params: {'classification__hidden_layer_sizes': (100,)}\n",
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 15.709s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier(hidden_layer_sizes=(500,)))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.504378859977726 Best GS Acc: 0.5174344225187645 Best Params: {'classification__hidden_layer_sizes': (500,)}\n",
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 12.078s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier())])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.49544715447154475 Best GS Acc: 0.5224649178555484 Best Params: {'classification__hidden_layer_sizes': (100,)}\n",
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 12.701s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier())])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.534267173156062 Best GS Acc: 0.5316158078040762 Best Params: {'classification__hidden_layer_sizes': (100,)}\n",
      "Average f1 macro score:  0.5139244822462972\n",
      "\n",
      "Trait to predict:  neuroticism \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ec6198e0bb44e579df92f65842f03c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 12.326s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier())])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.48124137797972194 Best GS Acc: 0.5729262590324573 Best Params: {'classification__hidden_layer_sizes': (100,)}\n",
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 11.734s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier(hidden_layer_sizes=(50,)))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.507209483093665 Best GS Acc: 0.5727014955000816 Best Params: {'classification__hidden_layer_sizes': (50,)}\n",
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 12.397s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier())])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5327057453416149 Best GS Acc: 0.5564998360723395 Best Params: {'classification__hidden_layer_sizes': (100,)}\n",
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 11.944s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier(hidden_layer_sizes=(50,)))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5975684422286364 Best GS Acc: 0.5402397929139051 Best Params: {'classification__hidden_layer_sizes': (50,)}\n",
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 12.326s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier(hidden_layer_sizes=(50,)))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5200209725027186 Best GS Acc: 0.5605980258239583 Best Params: {'classification__hidden_layer_sizes': (50,)}\n",
      "Average f1 macro score:  0.5277492042292713\n",
      "Classifier:  svm \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99bd5a28394e4deb9443f01360e09af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trait to predict:  openness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f9b8244f4504cf4a43f806ace8b8a58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.27498456 0.27498456 0.27498456 0.48191527 0.27498456 0.27498456\n",
      " 0.29761309 0.39093403 0.27498456 0.27498456 0.27498456 0.27498456\n",
      " 0.27498456 0.27498456 0.27498456 0.27498456        nan        nan\n",
      "        nan        nan 0.27498456 0.27498456 0.27498456 0.48191527\n",
      " 0.27498456 0.27498456 0.29761309 0.39093403 0.27498456 0.27498456\n",
      " 0.27498456 0.27498456 0.27498456 0.27498456 0.27498456 0.27498456\n",
      "        nan        nan        nan        nan 0.27498456 0.27457324\n",
      " 0.28517742 0.49736022 0.28014781 0.28531428 0.33263841 0.41545054\n",
      " 0.27498456 0.27498456 0.27498456 0.27498456 0.27498456 0.27498456\n",
      " 0.27498456 0.31897624        nan        nan        nan        nan\n",
      " 0.27498456 0.27457324 0.28517742 0.49736022 0.28014781 0.28531428\n",
      " 0.33263841 0.41545054 0.27498456 0.27498456 0.27498456 0.27498456\n",
      " 0.27498456 0.27498456 0.27498456 0.31897624        nan        nan\n",
      "        nan        nan 0.34552563 0.33308862 0.38326898 0.50541326\n",
      " 0.28592875 0.2940153  0.33036755 0.45668377 0.27498456 0.27498456\n",
      " 0.29217777 0.53160325 0.27498456 0.27778801 0.28337462 0.47919467\n",
      "        nan        nan        nan        nan 0.34552563 0.33308862\n",
      " 0.38326898 0.50541326 0.28592875 0.2940153  0.33036755 0.45668377\n",
      " 0.27498456 0.27498456 0.29217777 0.53160325 0.27498456 0.27778801\n",
      " 0.28337462 0.47919467        nan        nan        nan        nan\n",
      " 0.41618889 0.37351189 0.37812181 0.38368355 0.31553567 0.3374779\n",
      " 0.35197986 0.45324552 0.45347407 0.40386679 0.37669876 0.50878482\n",
      " 0.41634291 0.40952191 0.46545882 0.49361512        nan        nan\n",
      "        nan        nan 0.41618889 0.37351189 0.37812181 0.38368355\n",
      " 0.31553567 0.3374779  0.35197986 0.45324552 0.45347407 0.40386679\n",
      " 0.37669876 0.50878482 0.41634291 0.40952191 0.46545882 0.49361512\n",
      "        nan        nan        nan        nan 0.45002758 0.39620518\n",
      " 0.40834753 0.38093665 0.32425733 0.35357405 0.37866862 0.43854883\n",
      " 0.49974136 0.51065703 0.50543256 0.51739112 0.40301311 0.43745888\n",
      " 0.46111814 0.45974741        nan        nan        nan        nan\n",
      " 0.45002758 0.39620518 0.40834753 0.38093665 0.32425733 0.35357405\n",
      " 0.37866862 0.43854883 0.49974136 0.51065703 0.50543256 0.51739112\n",
      " 0.40301311 0.43745888 0.46111814 0.45974741        nan        nan\n",
      "        nan        nan 0.43074587 0.39379252 0.38895115 0.39118356\n",
      " 0.33027817 0.3509978  0.40765452 0.44123689 0.49625749 0.50950807\n",
      " 0.50456258 0.51624515 0.43712542 0.45126876 0.46482469 0.46524846\n",
      "        nan        nan        nan        nan 0.43074587 0.39379252\n",
      " 0.38895115 0.39118356 0.33027817 0.3509978  0.40765452 0.44123689\n",
      " 0.49625749 0.50950807 0.50456258 0.51624515 0.43712542 0.45126876\n",
      " 0.46482469 0.46524846        nan        nan        nan        nan\n",
      " 0.44846383 0.40968172 0.37870338 0.38345391 0.35158411 0.35489051\n",
      " 0.39522531 0.43380681 0.49625749 0.50950807 0.51395298 0.50590862\n",
      " 0.43460557 0.4422449  0.46888013 0.47259557        nan        nan\n",
      "        nan        nan 0.44846383 0.40968172 0.37870338 0.38345391\n",
      " 0.35158411 0.35489051 0.39522531 0.43380681 0.49625749 0.50950807\n",
      " 0.51395298 0.50590862 0.43460557 0.4422449  0.46888013 0.47259557\n",
      "        nan        nan        nan        nan 0.44846383 0.40968172\n",
      " 0.37870338 0.3826834  0.35330295 0.3520498  0.38306689 0.42181623\n",
      " 0.49625749 0.50950807 0.49840156 0.50186366 0.43642083 0.42677188\n",
      " 0.46740042 0.46802881        nan        nan        nan        nan\n",
      " 0.44846383 0.40968172 0.37870338 0.3826834  0.35330295 0.3520498\n",
      " 0.38306689 0.42181623 0.49625749 0.50950807 0.49840156 0.50186366\n",
      " 0.43642083 0.42677188 0.46740042 0.46802881        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 344.888s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=0.1, class_weight='balanced', max_iter=1000,\n",
      "                     probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.2747747747747748 Best GS Acc: 0.5316032482846069 Best Params: {'classification__C': 0.1, 'classification__gamma': 'scale', 'classification__kernel': 'rbf', 'classification__max_iter': 1000}\n",
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.27482931 0.27482931 0.27482931 0.54505306 0.27482931 0.27482931\n",
      " 0.34158033 0.36964486 0.3179967  0.29606035 0.27482931 0.27482931\n",
      " 0.27482931 0.27482931 0.27482931 0.27482931        nan        nan\n",
      "        nan        nan 0.27482931 0.27482931 0.27482931 0.54505306\n",
      " 0.27482931 0.27482931 0.34158033 0.36964486 0.3179967  0.29606035\n",
      " 0.27482931 0.27482931 0.27482931 0.27482931 0.27482931 0.27482931\n",
      "        nan        nan        nan        nan 0.27482931 0.27482931\n",
      " 0.30778761 0.54823677 0.27720456 0.2759729  0.36622465 0.41673099\n",
      " 0.29606035 0.29606035 0.27482931 0.27482931 0.27482931 0.27482931\n",
      " 0.27482931 0.27858759        nan        nan        nan        nan\n",
      " 0.27482931 0.27482931 0.30778761 0.54823677 0.27720456 0.2759729\n",
      " 0.36622465 0.41673099 0.29606035 0.29606035 0.27482931 0.27482931\n",
      " 0.27482931 0.27482931 0.27482931 0.27858759        nan        nan\n",
      "        nan        nan 0.31413545 0.30133499 0.43437511 0.54344452\n",
      " 0.28672986 0.29300457 0.39162351 0.44419349 0.33999361 0.29606035\n",
      " 0.31884595 0.52771362 0.27482931 0.27901579 0.28134002 0.53928769\n",
      "        nan        nan        nan        nan 0.31413545 0.30133499\n",
      " 0.43437511 0.54344452 0.28672986 0.29300457 0.39162351 0.44419349\n",
      " 0.33999361 0.29606035 0.31884595 0.52771362 0.27482931 0.27901579\n",
      " 0.28134002 0.53928769        nan        nan        nan        nan\n",
      " 0.40343824 0.39317829 0.39821237 0.38930863 0.30616925 0.3351399\n",
      " 0.34919871 0.49253117 0.42580531 0.44965578 0.455266   0.53078915\n",
      " 0.4246279  0.39577126 0.50575466 0.53115381        nan        nan\n",
      "        nan        nan 0.40343824 0.39317829 0.39821237 0.38930863\n",
      " 0.30616925 0.3351399  0.34919871 0.49253117 0.42580531 0.44965578\n",
      " 0.455266   0.53078915 0.4246279  0.39577126 0.50575466 0.53115381\n",
      "        nan        nan        nan        nan 0.46308395 0.40703521\n",
      " 0.36242974 0.40604096 0.34449927 0.36463512 0.4026134  0.5137551\n",
      " 0.48976739 0.48146883 0.48489311 0.51803166 0.4491917  0.46038875\n",
      " 0.51629459 0.52036678        nan        nan        nan        nan\n",
      " 0.46308395 0.40703521 0.36242974 0.40604096 0.34449927 0.36463512\n",
      " 0.4026134  0.5137551  0.48976739 0.48146883 0.48489311 0.51803166\n",
      " 0.4491917  0.46038875 0.51629459 0.52036678        nan        nan\n",
      "        nan        nan 0.42798402 0.44506555 0.39370157 0.38647314\n",
      " 0.31152769 0.3535074  0.42641169 0.44973848 0.48364969 0.47074068\n",
      " 0.48873108 0.51476987 0.44946399 0.44438507 0.52249049 0.51606254\n",
      "        nan        nan        nan        nan 0.42798402 0.44506555\n",
      " 0.39370157 0.38647314 0.31152769 0.3535074  0.42641169 0.44973848\n",
      " 0.48364969 0.47074068 0.48873108 0.51476987 0.44946399 0.44438507\n",
      " 0.52249049 0.51606254        nan        nan        nan        nan\n",
      " 0.4424908  0.45034708 0.39459902 0.41888808 0.36734023 0.3521886\n",
      " 0.41407291 0.46711709 0.471882   0.49362451 0.51650939 0.51988509\n",
      " 0.43112696 0.45087372 0.51817797 0.52311922        nan        nan\n",
      "        nan        nan 0.4424908  0.45034708 0.39459902 0.41888808\n",
      " 0.36734023 0.3521886  0.41407291 0.46711709 0.471882   0.49362451\n",
      " 0.51650939 0.51988509 0.43112696 0.45087372 0.51817797 0.52311922\n",
      "        nan        nan        nan        nan 0.45779389 0.46006537\n",
      " 0.40109446 0.42273033 0.37854126 0.34725881 0.39402414 0.44954755\n",
      " 0.483659   0.482308   0.49567206 0.49430667 0.43180629 0.465554\n",
      " 0.51865018 0.52180901        nan        nan        nan        nan\n",
      " 0.45779389 0.46006537 0.40109446 0.42273033 0.37854126 0.34725881\n",
      " 0.39402414 0.44954755 0.483659   0.482308   0.49567206 0.49430667\n",
      " 0.43180629 0.465554   0.51865018 0.52180901        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 347.311s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=0.01, class_weight='balanced', kernel='linear',\n",
      "                     max_iter=1000, probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.49795513935166746 Best GS Acc: 0.5482367734660896 Best Params: {'classification__C': 0.01, 'classification__gamma': 'scale', 'classification__kernel': 'linear', 'classification__max_iter': 1000}\n",
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.27482931 0.27482931 0.27482931 0.55020317 0.27482931 0.27482931\n",
      " 0.3179967  0.40065022 0.27482931 0.27482931 0.27482931 0.27482931\n",
      " 0.27482931 0.27482931 0.27482931 0.27482931        nan        nan\n",
      "        nan        nan 0.27482931 0.27482931 0.27482931 0.55020317\n",
      " 0.27482931 0.27482931 0.3179967  0.40065022 0.27482931 0.27482931\n",
      " 0.27482931 0.27482931 0.27482931 0.27482931 0.27482931 0.27482931\n",
      "        nan        nan        nan        nan 0.27482931 0.27482931\n",
      " 0.29337907 0.56549321 0.27539807 0.27776137 0.32471743 0.41947354\n",
      " 0.29676566 0.29606035 0.27482931 0.27482931 0.27482931 0.27482931\n",
      " 0.27482931 0.30151935        nan        nan        nan        nan\n",
      " 0.27482931 0.27482931 0.29337907 0.56549321 0.27539807 0.27776137\n",
      " 0.32471743 0.41947354 0.29676566 0.29606035 0.27482931 0.27482931\n",
      " 0.27482931 0.27482931 0.27482931 0.30151935        nan        nan\n",
      "        nan        nan 0.3291209  0.29445759 0.36571781 0.54058887\n",
      " 0.28573957 0.29671928 0.35585674 0.46027193 0.35475038 0.29606035\n",
      " 0.27482931 0.53955988 0.27857938 0.2802623  0.29495256 0.55349523\n",
      "        nan        nan        nan        nan 0.3291209  0.29445759\n",
      " 0.36571781 0.54058887 0.28573957 0.29671928 0.35585674 0.46027193\n",
      " 0.35475038 0.29606035 0.27482931 0.53955988 0.27857938 0.2802623\n",
      " 0.29495256 0.55349523        nan        nan        nan        nan\n",
      " 0.45270334 0.416327   0.40280632 0.41182729 0.31905979 0.3362956\n",
      " 0.35233936 0.50211882 0.46371224 0.46941735 0.44955708 0.54285992\n",
      " 0.45300239 0.42042905 0.5011152  0.52598107        nan        nan\n",
      "        nan        nan 0.45270334 0.416327   0.40280632 0.41182729\n",
      " 0.31905979 0.3362956  0.35233936 0.50211882 0.46371224 0.46941735\n",
      " 0.44955708 0.54285992 0.45300239 0.42042905 0.5011152  0.52598107\n",
      "        nan        nan        nan        nan 0.43390455 0.43056315\n",
      " 0.40437954 0.42641142 0.32687423 0.35415201 0.36626002 0.47375912\n",
      " 0.50903368 0.51239658 0.52475295 0.51798519 0.48265631 0.47341371\n",
      " 0.50909472 0.51492336        nan        nan        nan        nan\n",
      " 0.43390455 0.43056315 0.40437954 0.42641142 0.32687423 0.35415201\n",
      " 0.36626002 0.47375912 0.50903368 0.51239658 0.52475295 0.51798519\n",
      " 0.48265631 0.47341371 0.50909472 0.51492336        nan        nan\n",
      "        nan        nan 0.40296494 0.43874403 0.45988247 0.40040764\n",
      " 0.31392416 0.34169417 0.38797207 0.43880732 0.4896683  0.47676164\n",
      " 0.51184806 0.51664597 0.49611368 0.52048951 0.51339017 0.51726475\n",
      "        nan        nan        nan        nan 0.40296494 0.43874403\n",
      " 0.45988247 0.40040764 0.31392416 0.34169417 0.38797207 0.43880732\n",
      " 0.4896683  0.47676164 0.51184806 0.51664597 0.49611368 0.52048951\n",
      " 0.51339017 0.51726475        nan        nan        nan        nan\n",
      " 0.426015   0.44297855 0.45222167 0.40748836 0.33706789 0.37896527\n",
      " 0.3709254  0.41887626 0.4896683  0.47676164 0.51880495 0.51505657\n",
      " 0.4950698  0.49443344 0.50413467 0.50577272        nan        nan\n",
      "        nan        nan 0.426015   0.44297855 0.45222167 0.40748836\n",
      " 0.33706789 0.37896527 0.3709254  0.41887626 0.4896683  0.47676164\n",
      " 0.51880495 0.51505657 0.4950698  0.49443344 0.50413467 0.50577272\n",
      "        nan        nan        nan        nan 0.44772454 0.45710311\n",
      " 0.46657243 0.40744106 0.36443944 0.35799457 0.40159788 0.40760037\n",
      " 0.4896683  0.47676164 0.51257532 0.50943206 0.49288789 0.48637421\n",
      " 0.51134579 0.50548604        nan        nan        nan        nan\n",
      " 0.44772454 0.45710311 0.46657243 0.40744106 0.36443944 0.35799457\n",
      " 0.40159788 0.40760037 0.4896683  0.47676164 0.51257532 0.50943206\n",
      " 0.49288789 0.48637421 0.51134579 0.50548604        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 346.880s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=0.01, class_weight='balanced', kernel='linear',\n",
      "                     max_iter=1000, probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5368601855032634 Best GS Acc: 0.5654932114861868 Best Params: {'classification__C': 0.01, 'classification__gamma': 'scale', 'classification__kernel': 'linear', 'classification__max_iter': 1000}\n",
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.27482931 0.27482931 0.27482931 0.51334336 0.27482931 0.27482931\n",
      " 0.27582395 0.39774164 0.31870201 0.29676566 0.29606035 0.27482931\n",
      " 0.27482931 0.27482931 0.27482931 0.27482931        nan        nan\n",
      "        nan        nan 0.27482931 0.27482931 0.27482931 0.51334336\n",
      " 0.27482931 0.27482931 0.27582395 0.39774164 0.31870201 0.29676566\n",
      " 0.29606035 0.27482931 0.27482931 0.27482931 0.27482931 0.27482931\n",
      "        nan        nan        nan        nan 0.27580708 0.27482931\n",
      " 0.28218286 0.52570501 0.27400666 0.27331084 0.30528262 0.40547368\n",
      " 0.31870201 0.29676566 0.27482931 0.27482931 0.27482931 0.27482931\n",
      " 0.27482931 0.28881951        nan        nan        nan        nan\n",
      " 0.27580708 0.27482931 0.28218286 0.52570501 0.27400666 0.27331084\n",
      " 0.30528262 0.40547368 0.31870201 0.29676566 0.27482931 0.27482931\n",
      " 0.27482931 0.27482931 0.27482931 0.28881951        nan        nan\n",
      "        nan        nan 0.31811116 0.30070992 0.37556036 0.50793416\n",
      " 0.28091573 0.28994984 0.32758144 0.42791906 0.32755185 0.27482931\n",
      " 0.28340843 0.53074991 0.272352   0.27611898 0.2862116  0.52675038\n",
      "        nan        nan        nan        nan 0.31811116 0.30070992\n",
      " 0.37556036 0.50793416 0.28091573 0.28994984 0.32758144 0.42791906\n",
      " 0.32755185 0.27482931 0.28340843 0.53074991 0.272352   0.27611898\n",
      " 0.2862116  0.52675038        nan        nan        nan        nan\n",
      " 0.45838123 0.43009696 0.43610105 0.40780737 0.31038836 0.33041264\n",
      " 0.34530975 0.45342472 0.47661651 0.42797941 0.4152882  0.52925011\n",
      " 0.4481486  0.45859398 0.53013365 0.53550554        nan        nan\n",
      "        nan        nan 0.45838123 0.43009696 0.43610105 0.40780737\n",
      " 0.31038836 0.33041264 0.34530975 0.45342472 0.47661651 0.42797941\n",
      " 0.4152882  0.52925011 0.4481486  0.45859398 0.53013365 0.53550554\n",
      "        nan        nan        nan        nan 0.44535258 0.38563927\n",
      " 0.41334158 0.37919544 0.33401379 0.34996076 0.36991332 0.45369528\n",
      " 0.51763617 0.50327105 0.52482496 0.52611049 0.49373839 0.49983265\n",
      " 0.5283198  0.52855937        nan        nan        nan        nan\n",
      " 0.44535258 0.38563927 0.41334158 0.37919544 0.33401379 0.34996076\n",
      " 0.36991332 0.45369528 0.51763617 0.50327105 0.52482496 0.52611049\n",
      " 0.49373839 0.49983265 0.5283198  0.52855937        nan        nan\n",
      "        nan        nan 0.43275287 0.3911077  0.45829187 0.38018191\n",
      " 0.335397   0.36055338 0.41058083 0.45178426 0.50973309 0.47257303\n",
      " 0.50146433 0.49175156 0.48228262 0.50734486 0.52651292 0.53013538\n",
      "        nan        nan        nan        nan 0.43275287 0.3911077\n",
      " 0.45829187 0.38018191 0.335397   0.36055338 0.41058083 0.45178426\n",
      " 0.50973309 0.47257303 0.50146433 0.49175156 0.48228262 0.50734486\n",
      " 0.52651292 0.53013538        nan        nan        nan        nan\n",
      " 0.43606738 0.39582566 0.46308084 0.38135766 0.34638192 0.35885507\n",
      " 0.38914782 0.42732034 0.50973309 0.47257303 0.48813534 0.507349\n",
      " 0.50818787 0.5159018  0.52926056 0.53207769        nan        nan\n",
      "        nan        nan 0.43606738 0.39582566 0.46308084 0.38135766\n",
      " 0.34638192 0.35885507 0.38914782 0.42732034 0.50973309 0.47257303\n",
      " 0.48813534 0.507349   0.50818787 0.5159018  0.52926056 0.53207769\n",
      "        nan        nan        nan        nan 0.43606738 0.39582566\n",
      " 0.46308084 0.38569378 0.34638192 0.35885507 0.39779198 0.43621358\n",
      " 0.50973309 0.47257303 0.48813534 0.507349   0.5093523  0.50193283\n",
      " 0.52828803 0.53082503        nan        nan        nan        nan\n",
      " 0.43606738 0.39582566 0.46308084 0.38569378 0.34638192 0.35885507\n",
      " 0.39779198 0.43621358 0.50973309 0.47257303 0.48813534 0.507349\n",
      " 0.5093523  0.50193283 0.52828803 0.53082503        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 348.791s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=1, class_weight='balanced', kernel='sigmoid',\n",
      "                     max_iter=1000, probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5206093189964158 Best GS Acc: 0.535505535438984 Best Params: {'classification__C': 1, 'classification__gamma': 'scale', 'classification__kernel': 'sigmoid', 'classification__max_iter': 1000}\n",
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.27523832 0.27523832 0.27523832 0.53512507 0.27663581 0.27663581\n",
      " 0.27663581 0.38766499 0.27523832 0.27523832 0.27523832 0.27523832\n",
      " 0.27523832 0.27523832 0.27523832 0.27523832        nan        nan\n",
      "        nan        nan 0.27523832 0.27523832 0.27523832 0.53512507\n",
      " 0.27663581 0.27663581 0.27663581 0.38766499 0.27523832 0.27523832\n",
      " 0.27523832 0.27523832 0.27523832 0.27523832 0.27523832 0.27523832\n",
      "        nan        nan        nan        nan 0.27523832 0.27801883\n",
      " 0.29656477 0.54080981 0.27623296 0.2831108  0.29049956 0.40155925\n",
      " 0.27523832 0.27523832 0.27523832 0.27523832 0.27523832 0.27523832\n",
      " 0.27523832 0.28448535        nan        nan        nan        nan\n",
      " 0.27523832 0.27801883 0.29656477 0.54080981 0.27623296 0.2831108\n",
      " 0.29049956 0.40155925 0.27523832 0.27523832 0.27523832 0.27523832\n",
      " 0.27523832 0.27523832 0.27523832 0.28448535        nan        nan\n",
      "        nan        nan 0.30858334 0.31656692 0.36761729 0.52854744\n",
      " 0.29188381 0.29052052 0.31537748 0.44061414 0.29646936 0.29646936\n",
      " 0.27523832 0.52793333 0.27441799 0.2771819  0.28411966 0.53148208\n",
      "        nan        nan        nan        nan 0.30858334 0.31656692\n",
      " 0.36761729 0.52854744 0.29188381 0.29052052 0.31537748 0.44061414\n",
      " 0.29646936 0.29646936 0.27523832 0.52793333 0.27441799 0.2771819\n",
      " 0.28411966 0.53148208        nan        nan        nan        nan\n",
      " 0.40646953 0.40445641 0.38180437 0.39260812 0.31570381 0.33859842\n",
      " 0.35276793 0.50120311 0.43109864 0.44472063 0.38061538 0.5464044\n",
      " 0.36519616 0.4185542  0.49536455 0.50861617        nan        nan\n",
      "        nan        nan 0.40646953 0.40445641 0.38180437 0.39260812\n",
      " 0.31570381 0.33859842 0.35276793 0.50120311 0.43109864 0.44472063\n",
      " 0.38061538 0.5464044  0.36519616 0.4185542  0.49536455 0.50861617\n",
      "        nan        nan        nan        nan 0.41320802 0.44015043\n",
      " 0.36974074 0.39184176 0.32830084 0.36409023 0.3933721  0.47462896\n",
      " 0.51096812 0.50316037 0.5049451  0.53298895 0.44078466 0.46044112\n",
      " 0.49821348 0.49589413        nan        nan        nan        nan\n",
      " 0.41320802 0.44015043 0.36974074 0.39184176 0.32830084 0.36409023\n",
      " 0.3933721  0.47462896 0.51096812 0.50316037 0.5049451  0.53298895\n",
      " 0.44078466 0.46044112 0.49821348 0.49589413        nan        nan\n",
      "        nan        nan 0.43335686 0.43923957 0.44333778 0.41175603\n",
      " 0.34090279 0.37299438 0.41603145 0.44143893 0.50264657 0.49134484\n",
      " 0.49807922 0.49715993 0.46422058 0.47911283 0.5037635  0.50653031\n",
      "        nan        nan        nan        nan 0.43335686 0.43923957\n",
      " 0.44333778 0.41175603 0.34090279 0.37299438 0.41603145 0.44143893\n",
      " 0.50264657 0.49134484 0.49807922 0.49715993 0.46422058 0.47911283\n",
      " 0.5037635  0.50653031        nan        nan        nan        nan\n",
      " 0.42617863 0.43563721 0.43618432 0.4408457  0.35839866 0.37961407\n",
      " 0.40677381 0.44756911 0.50264657 0.49134484 0.51372886 0.50609212\n",
      " 0.46783662 0.46647916 0.50486489 0.50599052        nan        nan\n",
      "        nan        nan 0.42617863 0.43563721 0.43618432 0.4408457\n",
      " 0.35839866 0.37961407 0.40677381 0.44756911 0.50264657 0.49134484\n",
      " 0.51372886 0.50609212 0.46783662 0.46647916 0.50486489 0.50599052\n",
      "        nan        nan        nan        nan 0.42617863 0.43563721\n",
      " 0.44076595 0.42240334 0.35886531 0.37214664 0.38611569 0.42195053\n",
      " 0.50264657 0.49134484 0.51486035 0.50937134 0.46969395 0.47228888\n",
      " 0.51324833 0.50750135        nan        nan        nan        nan\n",
      " 0.42617863 0.43563721 0.44076595 0.42240334 0.35886531 0.37214664\n",
      " 0.38611569 0.42195053 0.50264657 0.49134484 0.51486035 0.50937134\n",
      " 0.46969395 0.47228888 0.51324833 0.50750135        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 343.495s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=1, class_weight='balanced', max_iter=1000,\n",
      "                     probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5260196344480805 Best GS Acc: 0.5464043955571454 Best Params: {'classification__C': 1, 'classification__gamma': 'scale', 'classification__kernel': 'rbf', 'classification__max_iter': 1000}\n",
      "Average f1 macro score:  0.47124381061484044\n",
      "\n",
      "Trait to predict:  conscientiousness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27afc07fdae24abbb83d09ce03191c74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.26164497 0.26164497 0.26164497 0.55354277 0.26121852 0.26256685\n",
      " 0.34919355 0.34273185 0.34160461 0.35855217 0.26164497 0.26164497\n",
      " 0.26164497 0.26164497 0.26164497 0.26164497        nan        nan\n",
      "        nan        nan 0.26164497 0.26164497 0.26164497 0.55354277\n",
      " 0.26121852 0.26256685 0.34919355 0.34273185 0.34160461 0.35855217\n",
      " 0.26164497 0.26164497 0.26164497 0.26164497 0.26164497 0.26164497\n",
      "        nan        nan        nan        nan 0.26779165 0.26348239\n",
      " 0.29632153 0.56317222 0.26878677 0.3150776  0.35512049 0.39907118\n",
      " 0.30567997 0.38474032 0.26164497 0.26164497 0.26164497 0.26164497\n",
      " 0.26164497 0.2718447         nan        nan        nan        nan\n",
      " 0.26779165 0.26348239 0.29632153 0.56317222 0.26878677 0.3150776\n",
      " 0.35512049 0.39907118 0.30567997 0.38474032 0.26164497 0.26164497\n",
      " 0.26164497 0.26164497 0.26164497 0.2718447         nan        nan\n",
      "        nan        nan 0.31273328 0.31639948 0.42713068 0.55435434\n",
      " 0.29317927 0.31687386 0.4058997  0.44736408 0.35760777 0.37669671\n",
      " 0.29634982 0.54559865 0.26299329 0.2732281  0.28619646 0.54915248\n",
      "        nan        nan        nan        nan 0.31273328 0.31639948\n",
      " 0.42713068 0.55435434 0.29317927 0.31687386 0.4058997  0.44736408\n",
      " 0.35760777 0.37669671 0.29634982 0.54559865 0.26299329 0.2732281\n",
      " 0.28619646 0.54915248        nan        nan        nan        nan\n",
      " 0.40969206 0.38187508 0.38957477 0.39276773 0.31869763 0.33935963\n",
      " 0.3624464  0.51174397 0.46883461 0.44661257 0.53951909 0.56984257\n",
      " 0.40847708 0.41899325 0.50607511 0.55322385        nan        nan\n",
      "        nan        nan 0.40969206 0.38187508 0.38957477 0.39276773\n",
      " 0.31869763 0.33935963 0.3624464  0.51174397 0.46883461 0.44661257\n",
      " 0.53951909 0.56984257 0.40847708 0.41899325 0.50607511 0.55322385\n",
      "        nan        nan        nan        nan 0.44219352 0.41021686\n",
      " 0.39128601 0.39205904 0.33212483 0.35708558 0.40092137 0.53158923\n",
      " 0.50309854 0.53118634 0.5287163  0.5288758  0.44777817 0.4978483\n",
      " 0.54519284 0.5446247         nan        nan        nan        nan\n",
      " 0.44219352 0.41021686 0.39128601 0.39205904 0.33212483 0.35708558\n",
      " 0.40092137 0.53158923 0.50309854 0.53118634 0.5287163  0.5288758\n",
      " 0.44777817 0.4978483  0.54519284 0.5446247         nan        nan\n",
      "        nan        nan 0.42738005 0.42877988 0.40738951 0.4067493\n",
      " 0.33993275 0.36979312 0.41078883 0.46076855 0.5198328  0.49219147\n",
      " 0.50933962 0.52110694 0.47125616 0.49923351 0.53808417 0.54413512\n",
      "        nan        nan        nan        nan 0.42738005 0.42877988\n",
      " 0.40738951 0.4067493  0.33993275 0.36979312 0.41078883 0.46076855\n",
      " 0.5198328  0.49219147 0.50933962 0.52110694 0.47125616 0.49923351\n",
      " 0.53808417 0.54413512        nan        nan        nan        nan\n",
      " 0.42738005 0.42197497 0.40194445 0.39901988 0.33756949 0.37774418\n",
      " 0.39139901 0.43956634 0.53718355 0.49752719 0.52331664 0.52284758\n",
      " 0.48577638 0.50099658 0.54565513 0.54698582        nan        nan\n",
      "        nan        nan 0.42738005 0.42197497 0.40194445 0.39901988\n",
      " 0.33756949 0.37774418 0.39139901 0.43956634 0.53718355 0.49752719\n",
      " 0.52331664 0.52284758 0.48577638 0.50099658 0.54565513 0.54698582\n",
      "        nan        nan        nan        nan 0.42738005 0.42003127\n",
      " 0.39773068 0.40110895 0.33756949 0.36628546 0.39547241 0.42002692\n",
      " 0.51902151 0.48256604 0.50848463 0.5318749  0.47338588 0.49709093\n",
      " 0.54610164 0.5471981         nan        nan        nan        nan\n",
      " 0.42738005 0.42003127 0.39773068 0.40110895 0.33756949 0.36628546\n",
      " 0.39547241 0.42002692 0.51902151 0.48256604 0.50848463 0.5318749\n",
      " 0.47338588 0.49709093 0.54610164 0.5471981         nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 345.086s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=1, class_weight='balanced', max_iter=1000,\n",
      "                     probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5953106305110648 Best GS Acc: 0.5698425699459257 Best Params: {'classification__C': 1, 'classification__gamma': 'scale', 'classification__kernel': 'rbf', 'classification__max_iter': 1000}\n",
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.26149425 0.26149425 0.26149425 0.5403433  0.26552583 0.26467207\n",
      " 0.34542521 0.29405921 0.39243499 0.36624684 0.26149425 0.26149425\n",
      " 0.26149425 0.26149425 0.26149425 0.26149425        nan        nan\n",
      "        nan        nan 0.26149425 0.26149425 0.26149425 0.5403433\n",
      " 0.26552583 0.26467207 0.34542521 0.29405921 0.39243499 0.36624684\n",
      " 0.26149425 0.26149425 0.26149425 0.26149425 0.26149425 0.26149425\n",
      "        nan        nan        nan        nan 0.2610686  0.26156316\n",
      " 0.27828288 0.54343435 0.26647954 0.33003234 0.38079921 0.41701422\n",
      " 0.36624684 0.34005869 0.31387055 0.26149425 0.26149425 0.26149425\n",
      " 0.26149425 0.28815827        nan        nan        nan        nan\n",
      " 0.2610686  0.26156316 0.27828288 0.54343435 0.26647954 0.33003234\n",
      " 0.38079921 0.41701422 0.36624684 0.34005869 0.31387055 0.26149425\n",
      " 0.26149425 0.26149425 0.26149425 0.28815827        nan        nan\n",
      "        nan        nan 0.32186373 0.31864397 0.40261353 0.54069022\n",
      " 0.28239148 0.31281695 0.3732083  0.45160573 0.37356387 0.37715491\n",
      " 0.32851458 0.52937429 0.26241692 0.26777638 0.27089033 0.55543775\n",
      "        nan        nan        nan        nan 0.32186373 0.31864397\n",
      " 0.40261353 0.54069022 0.28239148 0.31281695 0.3732083  0.45160573\n",
      " 0.37356387 0.37715491 0.32851458 0.52937429 0.26241692 0.26777638\n",
      " 0.27089033 0.55543775        nan        nan        nan        nan\n",
      " 0.42457514 0.41470194 0.37910874 0.42568232 0.30705447 0.32149025\n",
      " 0.34282446 0.48292105 0.43133198 0.50401267 0.53004823 0.54577588\n",
      " 0.43876085 0.413932   0.51078882 0.55196063        nan        nan\n",
      "        nan        nan 0.42457514 0.41470194 0.37910874 0.42568232\n",
      " 0.30705447 0.32149025 0.34282446 0.48292105 0.43133198 0.50401267\n",
      " 0.53004823 0.54577588 0.43876085 0.413932   0.51078882 0.55196063\n",
      "        nan        nan        nan        nan 0.41368237 0.3858336\n",
      " 0.36734545 0.38591704 0.32408419 0.35122723 0.39695568 0.51238841\n",
      " 0.49551161 0.52112283 0.53261371 0.54593706 0.45987474 0.4764105\n",
      " 0.55058418 0.53851622        nan        nan        nan        nan\n",
      " 0.41368237 0.3858336  0.36734545 0.38591704 0.32408419 0.35122723\n",
      " 0.39695568 0.51238841 0.49551161 0.52112283 0.53261371 0.54593706\n",
      " 0.45987474 0.4764105  0.55058418 0.53851622        nan        nan\n",
      "        nan        nan 0.39607067 0.39053022 0.39319975 0.37548271\n",
      " 0.33785501 0.36419514 0.42203887 0.48339894 0.48385569 0.50652647\n",
      " 0.50996214 0.53393976 0.46019461 0.48752399 0.54439596 0.54169895\n",
      "        nan        nan        nan        nan 0.39607067 0.39053022\n",
      " 0.39319975 0.37548271 0.33785501 0.36419514 0.42203887 0.48339894\n",
      " 0.48385569 0.50652647 0.50996214 0.53393976 0.46019461 0.48752399\n",
      " 0.54439596 0.54169895        nan        nan        nan        nan\n",
      " 0.40498362 0.41051147 0.38512119 0.4468356  0.33605435 0.35134368\n",
      " 0.39597324 0.42675869 0.49466124 0.51064104 0.5213476  0.52002583\n",
      " 0.46154465 0.51641991 0.54781883 0.54542147        nan        nan\n",
      "        nan        nan 0.40498362 0.41051147 0.38512119 0.4468356\n",
      " 0.33605435 0.35134368 0.39597324 0.42675869 0.49466124 0.51064104\n",
      " 0.5213476  0.52002583 0.46154465 0.51641991 0.54781883 0.54542147\n",
      "        nan        nan        nan        nan 0.41800659 0.41748862\n",
      " 0.41055295 0.42281854 0.32975353 0.34335407 0.38536618 0.40218374\n",
      " 0.46064817 0.47908869 0.48435404 0.4974437  0.44483558 0.49338823\n",
      " 0.54767321 0.5426454         nan        nan        nan        nan\n",
      " 0.41800659 0.41748862 0.41055295 0.42281854 0.32975353 0.34335407\n",
      " 0.38536618 0.40218374 0.46064817 0.47908869 0.48435404 0.4974437\n",
      " 0.44483558 0.49338823 0.54767321 0.5426454         nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 346.379s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=0.1, class_weight='balanced', kernel='sigmoid',\n",
      "                     max_iter=1000, probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.4081289081289081 Best GS Acc: 0.555437753914761 Best Params: {'classification__C': 0.1, 'classification__gamma': 'scale', 'classification__kernel': 'sigmoid', 'classification__max_iter': 1000}\n",
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.26149425 0.26149425 0.26149425 0.49839116 0.26284257 0.26284257\n",
      " 0.2641909  0.26642199 0.2876824  0.26149425 0.26149425 0.26149425\n",
      " 0.26149425 0.26149425 0.26149425 0.26149425        nan        nan\n",
      "        nan        nan 0.26149425 0.26149425 0.26149425 0.49839116\n",
      " 0.26284257 0.26284257 0.2641909  0.26642199 0.2876824  0.26149425\n",
      " 0.26149425 0.26149425 0.26149425 0.26149425 0.26149425 0.26149425\n",
      "        nan        nan        nan        nan 0.26638261 0.262409\n",
      " 0.26732643 0.53673788 0.26732139 0.26952696 0.30320095 0.36692044\n",
      " 0.2876824  0.26149425 0.26149425 0.26149425 0.26149425 0.26149425\n",
      " 0.26149425 0.2663519         nan        nan        nan        nan\n",
      " 0.26638261 0.262409   0.26732643 0.53673788 0.26732139 0.26952696\n",
      " 0.30320095 0.36692044 0.2876824  0.26149425 0.26149425 0.26149425\n",
      " 0.26149425 0.26149425 0.26149425 0.2663519         nan        nan\n",
      "        nan        nan 0.31899231 0.35490857 0.36626151 0.53091971\n",
      " 0.29635029 0.3092734  0.31335035 0.44672148 0.31387055 0.30873989\n",
      " 0.26149425 0.52858639 0.26284257 0.27031119 0.31515337 0.51133714\n",
      "        nan        nan        nan        nan 0.31899231 0.35490857\n",
      " 0.36626151 0.53091971 0.29635029 0.3092734  0.31335035 0.44672148\n",
      " 0.31387055 0.30873989 0.26149425 0.52858639 0.26284257 0.27031119\n",
      " 0.31515337 0.51133714        nan        nan        nan        nan\n",
      " 0.43336656 0.41486764 0.37497785 0.39466724 0.31880174 0.32883719\n",
      " 0.33634657 0.44732401 0.42987904 0.42790302 0.39675473 0.54406591\n",
      " 0.42240744 0.44344404 0.48344533 0.50319304        nan        nan\n",
      "        nan        nan 0.43336656 0.41486764 0.37497785 0.39466724\n",
      " 0.31880174 0.32883719 0.33634657 0.44732401 0.42987904 0.42790302\n",
      " 0.39675473 0.54406591 0.42240744 0.44344404 0.48344533 0.50319304\n",
      "        nan        nan        nan        nan 0.43286946 0.3827938\n",
      " 0.41729668 0.41408343 0.34030432 0.34761744 0.37924065 0.42208111\n",
      " 0.51013039 0.51603785 0.52873648 0.53549066 0.41532096 0.46058363\n",
      " 0.5028212  0.5096251         nan        nan        nan        nan\n",
      " 0.43286946 0.3827938  0.41729668 0.41408343 0.34030432 0.34761744\n",
      " 0.37924065 0.42208111 0.51013039 0.51603785 0.52873648 0.53549066\n",
      " 0.41532096 0.46058363 0.5028212  0.5096251         nan        nan\n",
      "        nan        nan 0.37329382 0.44616825 0.43000446 0.41106589\n",
      " 0.34263042 0.3587824  0.39174741 0.41432097 0.52368748 0.52624114\n",
      " 0.51917527 0.52603371 0.43015668 0.46847576 0.50155698 0.50236835\n",
      "        nan        nan        nan        nan 0.37329382 0.44616825\n",
      " 0.43000446 0.41106589 0.34263042 0.3587824  0.39174741 0.41432097\n",
      " 0.52368748 0.52624114 0.51917527 0.52603371 0.43015668 0.46847576\n",
      " 0.50155698 0.50236835        nan        nan        nan        nan\n",
      " 0.42051454 0.46873537 0.43525238 0.41049487 0.33836667 0.33600324\n",
      " 0.40485963 0.42691816 0.52857702 0.5251118  0.51700257 0.52490348\n",
      " 0.43454552 0.46365319 0.50066859 0.49698531        nan        nan\n",
      "        nan        nan 0.42051454 0.46873537 0.43525238 0.41049487\n",
      " 0.33836667 0.33600324 0.40485963 0.42691816 0.52857702 0.5251118\n",
      " 0.51700257 0.52490348 0.43454552 0.46365319 0.50066859 0.49698531\n",
      "        nan        nan        nan        nan 0.41011395 0.46239022\n",
      " 0.44880118 0.41770178 0.34232658 0.32774816 0.39619306 0.430911\n",
      " 0.52701021 0.52578329 0.51270182 0.5265778  0.45446975 0.47655315\n",
      " 0.50081618 0.4991904         nan        nan        nan        nan\n",
      " 0.41011395 0.46239022 0.44880118 0.41770178 0.34232658 0.32774816\n",
      " 0.39619306 0.430911   0.52701021 0.52578329 0.51270182 0.5265778\n",
      " 0.45446975 0.47655315 0.50081618 0.4991904         nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 346.260s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=1, class_weight='balanced', max_iter=1000,\n",
      "                     probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.55511998099311 Best GS Acc: 0.5440659146627036 Best Params: {'classification__C': 1, 'classification__gamma': 'scale', 'classification__kernel': 'rbf', 'classification__max_iter': 1000}\n",
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.26149425 0.26149425 0.26284257 0.51678627 0.26375732 0.26776239\n",
      " 0.34097344 0.3291641  0.31387055 0.36624684 0.32006852 0.26149425\n",
      " 0.26149425 0.26149425 0.26149425 0.26149425        nan        nan\n",
      "        nan        nan 0.26149425 0.26149425 0.26284257 0.51678627\n",
      " 0.26375732 0.26776239 0.34097344 0.3291641  0.31387055 0.36624684\n",
      " 0.32006852 0.26149425 0.26149425 0.26149425 0.26149425 0.26149425\n",
      "        nan        nan        nan        nan 0.26332375 0.2673156\n",
      " 0.26944966 0.554909   0.27263171 0.27645263 0.36439963 0.4162776\n",
      " 0.34005869 0.31387055 0.3242721  0.26149425 0.26149425 0.26149425\n",
      " 0.26149425 0.26241692        nan        nan        nan        nan\n",
      " 0.26332375 0.2673156  0.26944966 0.554909   0.27263171 0.27645263\n",
      " 0.36439963 0.4162776  0.34005869 0.31387055 0.3242721  0.26149425\n",
      " 0.26149425 0.26149425 0.26149425 0.26241692        nan        nan\n",
      "        nan        nan 0.2966652  0.29851149 0.35761903 0.54169274\n",
      " 0.28253193 0.30497892 0.33519024 0.4319622  0.31387055 0.34005869\n",
      " 0.33781008 0.54488555 0.2663519  0.27045102 0.28255318 0.54741188\n",
      "        nan        nan        nan        nan 0.2966652  0.29851149\n",
      " 0.35761903 0.54169274 0.28253193 0.30497892 0.33519024 0.4319622\n",
      " 0.31387055 0.34005869 0.33781008 0.54488555 0.2663519  0.27045102\n",
      " 0.28255318 0.54741188        nan        nan        nan        nan\n",
      " 0.39025245 0.43723222 0.36982808 0.38387263 0.31563819 0.333904\n",
      " 0.34749035 0.46030647 0.42388475 0.4553527  0.4731616  0.57273615\n",
      " 0.44026553 0.41162898 0.48877813 0.52623112        nan        nan\n",
      "        nan        nan 0.39025245 0.43723222 0.36982808 0.38387263\n",
      " 0.31563819 0.333904   0.34749035 0.46030647 0.42388475 0.4553527\n",
      " 0.4731616  0.57273615 0.44026553 0.41162898 0.48877813 0.52623112\n",
      "        nan        nan        nan        nan 0.44882427 0.41386983\n",
      " 0.39137996 0.40288397 0.3324016  0.33928288 0.35354962 0.46544257\n",
      " 0.4577282  0.48470893 0.52583991 0.55774071 0.44281142 0.45766653\n",
      " 0.51532545 0.5218768         nan        nan        nan        nan\n",
      " 0.44882427 0.41386983 0.39137996 0.40288397 0.3324016  0.33928288\n",
      " 0.35354962 0.46544257 0.4577282  0.48470893 0.52583991 0.55774071\n",
      " 0.44281142 0.45766653 0.51532545 0.5218768         nan        nan\n",
      "        nan        nan 0.4332551  0.43274289 0.38824322 0.42424191\n",
      " 0.32700358 0.35689027 0.38658208 0.43242848 0.4798152  0.48372958\n",
      " 0.50533283 0.52023822 0.45941282 0.47928125 0.52500075 0.51777664\n",
      "        nan        nan        nan        nan 0.4332551  0.43274289\n",
      " 0.38824322 0.42424191 0.32700358 0.35689027 0.38658208 0.43242848\n",
      " 0.4798152  0.48372958 0.50533283 0.52023822 0.45941282 0.47928125\n",
      " 0.52500075 0.51777664        nan        nan        nan        nan\n",
      " 0.42727346 0.40764679 0.38906577 0.41231309 0.36983977 0.35709352\n",
      " 0.43435694 0.39872945 0.49060329 0.48412608 0.50858635 0.50137489\n",
      " 0.45876308 0.44462397 0.50621953 0.51292567        nan        nan\n",
      "        nan        nan 0.42727346 0.40764679 0.38906577 0.41231309\n",
      " 0.36983977 0.35709352 0.43435694 0.39872945 0.49060329 0.48412608\n",
      " 0.50858635 0.50137489 0.45876308 0.44462397 0.50621953 0.51292567\n",
      "        nan        nan        nan        nan 0.42727346 0.40922565\n",
      " 0.40825221 0.4239425  0.34696833 0.34490024 0.39279861 0.42428993\n",
      " 0.48503889 0.48591279 0.49333824 0.48521662 0.4444009  0.45031162\n",
      " 0.5130774  0.51273403        nan        nan        nan        nan\n",
      " 0.42727346 0.40922565 0.40825221 0.4239425  0.34696833 0.34490024\n",
      " 0.39279861 0.42428993 0.48503889 0.48591279 0.49333824 0.48521662\n",
      " 0.4444009  0.45031162 0.5130774  0.51273403        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 347.342s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=1, class_weight='balanced', max_iter=1000,\n",
      "                     probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5832612082395707 Best GS Acc: 0.5727361513018681 Best Params: {'classification__C': 1, 'classification__gamma': 'scale', 'classification__kernel': 'rbf', 'classification__max_iter': 1000}\n",
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.26191747 0.26191747 0.26191747 0.54733662 0.26326579 0.26462211\n",
      " 0.34932759 0.38467871 0.3601566  0.3135826  0.28739445 0.26191747\n",
      " 0.26191747 0.26191747 0.26191747 0.26191747        nan        nan\n",
      "        nan        nan 0.26191747 0.26191747 0.26191747 0.54733662\n",
      " 0.26326579 0.26462211 0.34932759 0.38467871 0.3601566  0.3135826\n",
      " 0.28739445 0.26191747 0.26191747 0.26191747 0.26191747 0.26191747\n",
      "        nan        nan        nan        nan 0.26462211 0.26462211\n",
      " 0.29520873 0.54705102 0.26510564 0.27835573 0.3965789  0.41737424\n",
      " 0.3601566  0.3135826  0.28739445 0.26191747 0.26191747 0.26191747\n",
      " 0.26191747 0.2789597         nan        nan        nan        nan\n",
      " 0.26462211 0.26462211 0.29520873 0.54705102 0.26510564 0.27835573\n",
      " 0.3965789  0.41737424 0.3601566  0.3135826  0.28739445 0.26191747\n",
      " 0.26191747 0.26191747 0.26191747 0.2789597         nan        nan\n",
      "        nan        nan 0.3000984  0.32410008 0.42224638 0.54245161\n",
      " 0.2817317  0.30241965 0.38620697 0.44471286 0.36194062 0.43922621\n",
      " 0.28739445 0.53345628 0.26460072 0.2668452  0.27483479 0.54354055\n",
      "        nan        nan        nan        nan 0.3000984  0.32410008\n",
      " 0.42224638 0.54245161 0.2817317  0.30241965 0.38620697 0.44471286\n",
      " 0.36194062 0.43922621 0.28739445 0.53345628 0.26460072 0.2668452\n",
      " 0.27483479 0.54354055        nan        nan        nan        nan\n",
      " 0.40036269 0.39225341 0.38494245 0.39207849 0.30826417 0.33036794\n",
      " 0.36088853 0.50333306 0.451904   0.49154276 0.54116749 0.53968027\n",
      " 0.40081553 0.38297829 0.47609194 0.51795934        nan        nan\n",
      "        nan        nan 0.40036269 0.39225341 0.38494245 0.39207849\n",
      " 0.30826417 0.33036794 0.36088853 0.50333306 0.451904   0.49154276\n",
      " 0.54116749 0.53968027 0.40081553 0.38297829 0.47609194 0.51795934\n",
      "        nan        nan        nan        nan 0.38793374 0.41301387\n",
      " 0.38285589 0.37015242 0.33439642 0.34671734 0.37618709 0.51770923\n",
      " 0.48503651 0.49599552 0.53494549 0.54995454 0.47164112 0.46431025\n",
      " 0.50515883 0.5103403         nan        nan        nan        nan\n",
      " 0.38793374 0.41301387 0.38285589 0.37015242 0.33439642 0.34671734\n",
      " 0.37618709 0.51770923 0.48503651 0.49599552 0.53494549 0.54995454\n",
      " 0.47164112 0.46431025 0.50515883 0.5103403         nan        nan\n",
      "        nan        nan 0.40899654 0.38222855 0.39261494 0.38250319\n",
      " 0.33677899 0.34479951 0.39136519 0.44546926 0.50136031 0.490642\n",
      " 0.50259904 0.51258898 0.44408791 0.45755396 0.515447   0.52003255\n",
      "        nan        nan        nan        nan 0.40899654 0.38222855\n",
      " 0.39261494 0.38250319 0.33677899 0.34479951 0.39136519 0.44546926\n",
      " 0.50136031 0.490642   0.50259904 0.51258898 0.44408791 0.45755396\n",
      " 0.515447   0.52003255        nan        nan        nan        nan\n",
      " 0.40777087 0.40321254 0.37131311 0.4134297  0.34501922 0.35314865\n",
      " 0.39951259 0.44416726 0.50394114 0.50579435 0.5168607  0.51376747\n",
      " 0.46499352 0.50560973 0.51717718 0.52095554        nan        nan\n",
      "        nan        nan 0.40777087 0.40321254 0.37131311 0.4134297\n",
      " 0.34501922 0.35314865 0.39951259 0.44416726 0.50394114 0.50579435\n",
      " 0.5168607  0.51376747 0.46499352 0.50560973 0.51717718 0.52095554\n",
      "        nan        nan        nan        nan 0.39535487 0.40457619\n",
      " 0.37980506 0.35798567 0.35414301 0.36074521 0.38980476 0.42978685\n",
      " 0.48738599 0.50845958 0.54069855 0.51884245 0.4527156  0.47964954\n",
      " 0.50512061 0.5212134         nan        nan        nan        nan\n",
      " 0.39535487 0.40457619 0.37980506 0.35798567 0.35414301 0.36074521\n",
      " 0.38980476 0.42978685 0.48738599 0.50845958 0.54069855 0.51884245\n",
      " 0.4527156  0.47964954 0.50512061 0.5212134         nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 344.111s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=10, class_weight='balanced', max_iter=1000,\n",
      "                     probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5209331552902364 Best GS Acc: 0.549954536361018 Best Params: {'classification__C': 10, 'classification__gamma': 'scale', 'classification__kernel': 'rbf', 'classification__max_iter': 1000}\n",
      "Average f1 macro score:  0.5325507766325781\n",
      "\n",
      "Trait to predict:  extraversion \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4c2abad72ef41ef91431f1433c3638d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.30368799 0.30368799 0.30368799 0.58083204 0.30368799 0.30368799\n",
      " 0.32890696 0.35390198 0.34668313 0.30368799 0.30368799 0.31512269\n",
      " 0.30368799 0.30368799 0.30368799 0.30368799        nan        nan\n",
      "        nan        nan 0.30368799 0.30368799 0.30368799 0.58083204\n",
      " 0.30368799 0.30368799 0.32890696 0.35390198 0.34668313 0.30368799\n",
      " 0.30368799 0.31512269 0.30368799 0.30368799 0.30368799 0.30368799\n",
      "        nan        nan        nan        nan 0.30330947 0.30368799\n",
      " 0.35652408 0.57670571 0.30863268 0.3101675  0.35876727 0.43758087\n",
      " 0.33524843 0.30368799 0.30368799 0.31572235 0.30368799 0.30368799\n",
      " 0.30368799 0.40467979        nan        nan        nan        nan\n",
      " 0.30330947 0.30368799 0.35652408 0.57670571 0.30863268 0.3101675\n",
      " 0.35876727 0.43758087 0.33524843 0.30368799 0.30368799 0.31572235\n",
      " 0.30368799 0.30368799 0.30368799 0.40467979        nan        nan\n",
      "        nan        nan 0.34766402 0.35607894 0.43573449 0.56101335\n",
      " 0.3253392  0.33656468 0.39077293 0.46447372 0.38510683 0.34453562\n",
      " 0.30522281 0.57190821 0.32655761 0.30284799 0.31107393 0.57181278\n",
      "        nan        nan        nan        nan 0.34766402 0.35607894\n",
      " 0.43573449 0.56101335 0.3253392  0.33656468 0.39077293 0.46447372\n",
      " 0.38510683 0.34453562 0.30522281 0.57190821 0.32655761 0.30284799\n",
      " 0.31107393 0.57181278        nan        nan        nan        nan\n",
      " 0.44634691 0.4264568  0.42975504 0.45677024 0.36005691 0.37497724\n",
      " 0.38539247 0.52496985 0.42737731 0.42308    0.41491242 0.57155398\n",
      " 0.49473657 0.50130532 0.53731692 0.54498433        nan        nan\n",
      "        nan        nan 0.44634691 0.4264568  0.42975504 0.45677024\n",
      " 0.36005691 0.37497724 0.38539247 0.52496985 0.42737731 0.42308\n",
      " 0.41491242 0.57155398 0.49473657 0.50130532 0.53731692 0.54498433\n",
      "        nan        nan        nan        nan 0.43765955 0.44463119\n",
      " 0.40624641 0.40568871 0.35909052 0.38763006 0.39063122 0.48836702\n",
      " 0.50672709 0.50227064 0.54051598 0.56560818 0.4864216  0.48410621\n",
      " 0.52787097 0.52938393        nan        nan        nan        nan\n",
      " 0.43765955 0.44463119 0.40624641 0.40568871 0.35909052 0.38763006\n",
      " 0.39063122 0.48836702 0.50672709 0.50227064 0.54051598 0.56560818\n",
      " 0.4864216  0.48410621 0.52787097 0.52938393        nan        nan\n",
      "        nan        nan 0.45232367 0.47326792 0.45277378 0.44338679\n",
      " 0.36587669 0.37729472 0.41063194 0.44019961 0.47158442 0.51088109\n",
      " 0.50315217 0.52029952 0.5253826  0.50251044 0.54013404 0.54021494\n",
      "        nan        nan        nan        nan 0.45232367 0.47326792\n",
      " 0.45277378 0.44338679 0.36587669 0.37729472 0.41063194 0.44019961\n",
      " 0.47158442 0.51088109 0.50315217 0.52029952 0.5253826  0.50251044\n",
      " 0.54013404 0.54021494        nan        nan        nan        nan\n",
      " 0.44798473 0.46546712 0.46162401 0.4168765  0.35679742 0.37793736\n",
      " 0.40048234 0.45208535 0.47158442 0.52157521 0.50495714 0.51900835\n",
      " 0.54859047 0.50804815 0.54548575 0.54164545        nan        nan\n",
      "        nan        nan 0.44798473 0.46546712 0.46162401 0.4168765\n",
      " 0.35679742 0.37793736 0.40048234 0.45208535 0.47158442 0.52157521\n",
      " 0.50495714 0.51900835 0.54859047 0.50804815 0.54548575 0.54164545\n",
      "        nan        nan        nan        nan 0.44798473 0.46546712\n",
      " 0.46162401 0.43541918 0.35510231 0.37339164 0.38076529 0.41993769\n",
      " 0.47158442 0.50876065 0.48826561 0.53055747 0.53928449 0.50466641\n",
      " 0.54121339 0.54147574        nan        nan        nan        nan\n",
      " 0.44798473 0.46546712 0.46162401 0.43541918 0.35510231 0.37339164\n",
      " 0.38076529 0.41993769 0.47158442 0.50876065 0.48826561 0.53055747\n",
      " 0.53928449 0.50466641 0.54121339 0.54147574        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 344.859s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=0.001, class_weight='balanced', kernel='linear',\n",
      "                     max_iter=1000, probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.35821305841924395 Best GS Acc: 0.5808320422488507 Best Params: {'classification__C': 0.001, 'classification__gamma': 'scale', 'classification__kernel': 'linear', 'classification__max_iter': 1000}\n",
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.30389951 0.30389951 0.30389951 0.58006777 0.30389951 0.30389951\n",
      " 0.3279153  0.38550409 0.3267689  0.3267689  0.30389951 0.35639\n",
      " 0.30389951 0.30389951 0.30389951 0.30389951        nan        nan\n",
      "        nan        nan 0.30389951 0.30389951 0.30389951 0.58006777\n",
      " 0.30389951 0.30389951 0.3279153  0.38550409 0.3267689  0.3267689\n",
      " 0.30389951 0.35639    0.30389951 0.30389951 0.30389951 0.30389951\n",
      "        nan        nan        nan        nan 0.30389951 0.30389951\n",
      " 0.3406978  0.5734761  0.30544435 0.30963301 0.34960592 0.42676929\n",
      " 0.3267689  0.3267689  0.30389951 0.39531518 0.30389951 0.30389951\n",
      " 0.30389951 0.38457407        nan        nan        nan        nan\n",
      " 0.30389951 0.30389951 0.3406978  0.5734761  0.30544435 0.30963301\n",
      " 0.34960592 0.42676929 0.3267689  0.3267689  0.30389951 0.39531518\n",
      " 0.30389951 0.30389951 0.30389951 0.38457407        nan        nan\n",
      "        nan        nan 0.36492327 0.35561575 0.38246844 0.54587208\n",
      " 0.32292538 0.33370521 0.3624214  0.46798037 0.3278545  0.38308118\n",
      " 0.35205669 0.56792526 0.38829515 0.30445859 0.312093   0.55940402\n",
      "        nan        nan        nan        nan 0.36492327 0.35561575\n",
      " 0.38246844 0.54587208 0.32292538 0.33370521 0.3624214  0.46798037\n",
      " 0.3278545  0.38308118 0.35205669 0.56792526 0.38829515 0.30445859\n",
      " 0.312093   0.55940402        nan        nan        nan        nan\n",
      " 0.41065248 0.42235843 0.38064739 0.41452476 0.35621189 0.37311956\n",
      " 0.37981845 0.52316903 0.43705129 0.44757051 0.44572528 0.56853357\n",
      " 0.53356061 0.50142021 0.52394713 0.53864773        nan        nan\n",
      "        nan        nan 0.41065248 0.42235843 0.38064739 0.41452476\n",
      " 0.35621189 0.37311956 0.37981845 0.52316903 0.43705129 0.44757051\n",
      " 0.44572528 0.56853357 0.53356061 0.50142021 0.52394713 0.53864773\n",
      "        nan        nan        nan        nan 0.40045123 0.44723083\n",
      " 0.3952627  0.38067341 0.3593198  0.37903697 0.39348263 0.44886749\n",
      " 0.49295693 0.48603952 0.53771409 0.54254293 0.53476076 0.5151644\n",
      " 0.53557697 0.53716744        nan        nan        nan        nan\n",
      " 0.40045123 0.44723083 0.3952627  0.38067341 0.3593198  0.37903697\n",
      " 0.39348263 0.44886749 0.49295693 0.48603952 0.53771409 0.54254293\n",
      " 0.53476076 0.5151644  0.53557697 0.53716744        nan        nan\n",
      "        nan        nan 0.39912841 0.41875416 0.38523747 0.40150265\n",
      " 0.37246115 0.38454281 0.41836936 0.42670954 0.45705944 0.4900186\n",
      " 0.4830114  0.52765401 0.5191889  0.5153872  0.53250639 0.5383739\n",
      "        nan        nan        nan        nan 0.39912841 0.41875416\n",
      " 0.38523747 0.40150265 0.37246115 0.38454281 0.41836936 0.42670954\n",
      " 0.45705944 0.4900186  0.4830114  0.52765401 0.5191889  0.5153872\n",
      " 0.53250639 0.5383739         nan        nan        nan        nan\n",
      " 0.39912841 0.41875416 0.38523747 0.41103635 0.36013105 0.37430934\n",
      " 0.37602293 0.39501711 0.45705944 0.48684743 0.4765836  0.48807287\n",
      " 0.53372755 0.50096672 0.53592989 0.53695267        nan        nan\n",
      "        nan        nan 0.39912841 0.41875416 0.38523747 0.41103635\n",
      " 0.36013105 0.37430934 0.37602293 0.39501711 0.45705944 0.48684743\n",
      " 0.4765836  0.48807287 0.53372755 0.50096672 0.53592989 0.53695267\n",
      "        nan        nan        nan        nan 0.39912841 0.41875416\n",
      " 0.38523747 0.41103635 0.36063343 0.37610614 0.38407235 0.40479425\n",
      " 0.45705944 0.48684743 0.46846633 0.48486663 0.53747645 0.50876566\n",
      " 0.5376622  0.5369323         nan        nan        nan        nan\n",
      " 0.39912841 0.41875416 0.38523747 0.41103635 0.36063343 0.37610614\n",
      " 0.38407235 0.40479425 0.45705944 0.48684743 0.46846633 0.48486663\n",
      " 0.53747645 0.50876566 0.5376622  0.5369323         nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 342.117s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=0.001, class_weight='balanced', kernel='linear',\n",
      "                     max_iter=1000, probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.3681674208144797 Best GS Acc: 0.5800677704665587 Best Params: {'classification__C': 0.001, 'classification__gamma': 'scale', 'classification__kernel': 'linear', 'classification__max_iter': 1000}\n",
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.30389951 0.30389951 0.30389951 0.57647688 0.30389951 0.30389951\n",
      " 0.30768826 0.35597662 0.33109836 0.34183491 0.30389951 0.34845774\n",
      " 0.30389951 0.30389951 0.30389951 0.30389951        nan        nan\n",
      "        nan        nan 0.30389951 0.30389951 0.30389951 0.57647688\n",
      " 0.30389951 0.30389951 0.30768826 0.35597662 0.33109836 0.34183491\n",
      " 0.30389951 0.34845774 0.30389951 0.30389951 0.30389951 0.30389951\n",
      "        nan        nan        nan        nan 0.30848623 0.31002106\n",
      " 0.34854944 0.55835943 0.31268454 0.31681071 0.321869   0.45741519\n",
      " 0.31680717 0.31533421 0.30389951 0.34514279 0.30389951 0.30389951\n",
      " 0.30389951 0.38332669        nan        nan        nan        nan\n",
      " 0.30848623 0.31002106 0.34854944 0.55835943 0.31268454 0.31681071\n",
      " 0.321869   0.45741519 0.31680717 0.31533421 0.30389951 0.34514279\n",
      " 0.30389951 0.30389951 0.30389951 0.38332669        nan        nan\n",
      "        nan        nan 0.33251034 0.35655352 0.42926992 0.55134885\n",
      " 0.33269247 0.33948344 0.35542805 0.4641246  0.32782224 0.34711025\n",
      " 0.34882573 0.55205409 0.36215077 0.30385023 0.31042932 0.55644455\n",
      "        nan        nan        nan        nan 0.33251034 0.35655352\n",
      " 0.42926992 0.55134885 0.33269247 0.33948344 0.35542805 0.4641246\n",
      " 0.32782224 0.34711025 0.34882573 0.55205409 0.36215077 0.30385023\n",
      " 0.31042932 0.55644455        nan        nan        nan        nan\n",
      " 0.40783323 0.42335597 0.40098149 0.40743955 0.35044565 0.36480153\n",
      " 0.37794989 0.49605374 0.44689596 0.45839801 0.43530632 0.56255289\n",
      " 0.49404764 0.49588156 0.52248411 0.54277348        nan        nan\n",
      "        nan        nan 0.40783323 0.42335597 0.40098149 0.40743955\n",
      " 0.35044565 0.36480153 0.37794989 0.49605374 0.44689596 0.45839801\n",
      " 0.43530632 0.56255289 0.49404764 0.49588156 0.52248411 0.54277348\n",
      "        nan        nan        nan        nan 0.417285   0.41426386\n",
      " 0.44977253 0.38964614 0.36691711 0.38801145 0.38989832 0.46893895\n",
      " 0.4888786  0.50125753 0.53324256 0.55277599 0.53216642 0.51553724\n",
      " 0.53532289 0.5374798         nan        nan        nan        nan\n",
      " 0.417285   0.41426386 0.44977253 0.38964614 0.36691711 0.38801145\n",
      " 0.38989832 0.46893895 0.4888786  0.50125753 0.53324256 0.55277599\n",
      " 0.53216642 0.51553724 0.53532289 0.5374798         nan        nan\n",
      "        nan        nan 0.4454149  0.42074402 0.42786762 0.39648771\n",
      " 0.37852389 0.38586446 0.40393596 0.43176941 0.45896558 0.48353731\n",
      " 0.4936382  0.49379078 0.5224178  0.50243561 0.53696498 0.53286175\n",
      "        nan        nan        nan        nan 0.4454149  0.42074402\n",
      " 0.42786762 0.39648771 0.37852389 0.38586446 0.40393596 0.43176941\n",
      " 0.45896558 0.48353731 0.4936382  0.49379078 0.5224178  0.50243561\n",
      " 0.53696498 0.53286175        nan        nan        nan        nan\n",
      " 0.449658   0.47190768 0.47048189 0.40450125 0.3785403  0.39443587\n",
      " 0.41134106 0.432226   0.48186061 0.50259134 0.49108541 0.51380669\n",
      " 0.53653937 0.52609839 0.54797962 0.54613196        nan        nan\n",
      "        nan        nan 0.449658   0.47190768 0.47048189 0.40450125\n",
      " 0.3785403  0.39443587 0.41134106 0.432226   0.48186061 0.50259134\n",
      " 0.49108541 0.51380669 0.53653937 0.52609839 0.54797962 0.54613196\n",
      "        nan        nan        nan        nan 0.449658   0.47190768\n",
      " 0.48758237 0.45185429 0.38357142 0.38819851 0.41097082 0.42037868\n",
      " 0.48186061 0.50259134 0.49108541 0.51380669 0.53208073 0.52831734\n",
      " 0.54549414 0.54208043        nan        nan        nan        nan\n",
      " 0.449658   0.47190768 0.48758237 0.45185429 0.38357142 0.38819851\n",
      " 0.41097082 0.42037868 0.48186061 0.50259134 0.49108541 0.51380669\n",
      " 0.53208073 0.52831734 0.54549414 0.54208043        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 345.101s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=0.001, class_weight='balanced', kernel='linear',\n",
      "                     max_iter=1000, probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.3421518397764322 Best GS Acc: 0.5764768794706159 Best Params: {'classification__C': 0.001, 'classification__gamma': 'scale', 'classification__kernel': 'linear', 'classification__max_iter': 1000}\n",
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.30389951 0.30389951 0.30389951 0.56878633 0.30389951 0.30389951\n",
      " 0.31802737 0.39645713 0.31533421 0.31463888 0.30389951 0.35181721\n",
      " 0.30389951 0.30389951 0.30389951 0.30389951        nan        nan\n",
      "        nan        nan 0.30389951 0.30389951 0.30389951 0.56878633\n",
      " 0.30389951 0.30389951 0.31802737 0.39645713 0.31533421 0.31463888\n",
      " 0.30389951 0.35181721 0.30389951 0.30389951 0.30389951 0.30389951\n",
      "        nan        nan        nan        nan 0.30389951 0.30389951\n",
      " 0.33750045 0.57057814 0.30698204 0.30698204 0.32026612 0.42525803\n",
      " 0.31533421 0.31463888 0.30389951 0.34052738 0.30389951 0.30389951\n",
      " 0.30389951 0.33103533        nan        nan        nan        nan\n",
      " 0.30389951 0.30389951 0.33750045 0.57057814 0.30698204 0.30698204\n",
      " 0.32026612 0.42525803 0.31533421 0.31463888 0.30389951 0.34052738\n",
      " 0.30389951 0.30389951 0.30389951 0.33103533        nan        nan\n",
      "        nan        nan 0.33144642 0.3288793  0.40663844 0.56942232\n",
      " 0.31310977 0.31733659 0.36471307 0.45018153 0.3494407  0.34282917\n",
      " 0.30389951 0.57499704 0.30687947 0.30508245 0.30638677 0.56020912\n",
      "        nan        nan        nan        nan 0.33144642 0.3288793\n",
      " 0.40663844 0.56942232 0.31310977 0.31733659 0.36471307 0.45018153\n",
      " 0.3494407  0.34282917 0.30389951 0.57499704 0.30687947 0.30508245\n",
      " 0.30638677 0.56020912        nan        nan        nan        nan\n",
      " 0.43306399 0.42518355 0.4007633  0.43577355 0.33876823 0.35022965\n",
      " 0.36822334 0.49201437 0.46208053 0.45719237 0.41699245 0.57615109\n",
      " 0.43975947 0.43925691 0.50799577 0.53286227        nan        nan\n",
      "        nan        nan 0.43306399 0.42518355 0.4007633  0.43577355\n",
      " 0.33876823 0.35022965 0.36822334 0.49201437 0.46208053 0.45719237\n",
      " 0.41699245 0.57615109 0.43975947 0.43925691 0.50799577 0.53286227\n",
      "        nan        nan        nan        nan 0.4399965  0.42714444\n",
      " 0.38226419 0.39862341 0.35793733 0.37324979 0.38257937 0.47328363\n",
      " 0.49718326 0.52848249 0.51845376 0.55077879 0.44271562 0.49133905\n",
      " 0.53638244 0.53110915        nan        nan        nan        nan\n",
      " 0.4399965  0.42714444 0.38226419 0.39862341 0.35793733 0.37324979\n",
      " 0.38257937 0.47328363 0.49718326 0.52848249 0.51845376 0.55077879\n",
      " 0.44271562 0.49133905 0.53638244 0.53110915        nan        nan\n",
      "        nan        nan 0.4399965  0.41829729 0.40372079 0.41122156\n",
      " 0.34507813 0.36732749 0.41377795 0.43128301 0.47359349 0.46436618\n",
      " 0.51793301 0.50945546 0.5069218  0.49730131 0.52189293 0.52496947\n",
      "        nan        nan        nan        nan 0.4399965  0.41829729\n",
      " 0.40372079 0.41122156 0.34507813 0.36732749 0.41377795 0.43128301\n",
      " 0.47359349 0.46436618 0.51793301 0.50945546 0.5069218  0.49730131\n",
      " 0.52189293 0.52496947        nan        nan        nan        nan\n",
      " 0.4399965  0.40162455 0.43025731 0.40727363 0.34442653 0.37811577\n",
      " 0.41735161 0.44251484 0.47359349 0.47638363 0.49442332 0.49988713\n",
      " 0.50946458 0.4927528  0.53572571 0.53103855        nan        nan\n",
      "        nan        nan 0.4399965  0.40162455 0.43025731 0.40727363\n",
      " 0.34442653 0.37811577 0.41735161 0.44251484 0.47359349 0.47638363\n",
      " 0.49442332 0.49988713 0.50946458 0.4927528  0.53572571 0.53103855\n",
      "        nan        nan        nan        nan 0.4399965  0.40533225\n",
      " 0.42297914 0.43093543 0.36500101 0.38983257 0.41082741 0.44566926\n",
      " 0.47359349 0.46850344 0.50969625 0.50886214 0.52695686 0.4895492\n",
      " 0.5227146  0.52879863        nan        nan        nan        nan\n",
      " 0.4399965  0.40533225 0.42297914 0.43093543 0.36500101 0.38983257\n",
      " 0.41082741 0.44566926 0.47359349 0.46850344 0.50969625 0.50886214\n",
      " 0.52695686 0.4895492  0.5227146  0.52879863        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 350.608s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=1, class_weight='balanced', max_iter=1000,\n",
      "                     probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.6289380877742947 Best GS Acc: 0.5761510944225849 Best Params: {'classification__C': 1, 'classification__gamma': 'scale', 'classification__kernel': 'rbf', 'classification__max_iter': 1000}\n",
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.30389951 0.30389951 0.30389951 0.56938252 0.30389951 0.30389951\n",
      " 0.33750827 0.37564896 0.30389951 0.31533421 0.30389951 0.31533421\n",
      " 0.30389951 0.30389951 0.30389951 0.30389951        nan        nan\n",
      "        nan        nan 0.30389951 0.30389951 0.30389951 0.56938252\n",
      " 0.30389951 0.30389951 0.33750827 0.37564896 0.30389951 0.31533421\n",
      " 0.30389951 0.31533421 0.30389951 0.30389951 0.30389951 0.30389951\n",
      "        nan        nan        nan        nan 0.30389951 0.30389951\n",
      " 0.32541298 0.56960784 0.30389951 0.30389951 0.33969766 0.42506393\n",
      " 0.30389951 0.31533421 0.30389951 0.34263679 0.30389951 0.30389951\n",
      " 0.30389951 0.42787777        nan        nan        nan        nan\n",
      " 0.30389951 0.30389951 0.32541298 0.56960784 0.30389951 0.30389951\n",
      " 0.33969766 0.42506393 0.30389951 0.31533421 0.30389951 0.34263679\n",
      " 0.30389951 0.30389951 0.30389951 0.42787777        nan        nan\n",
      "        nan        nan 0.34176112 0.33711183 0.4200832  0.54913657\n",
      " 0.30347652 0.314544   0.38238972 0.45840182 0.3267689  0.34581367\n",
      " 0.31011866 0.56817234 0.39332477 0.29986181 0.30609014 0.57452655\n",
      "        nan        nan        nan        nan 0.34176112 0.33711183\n",
      " 0.4200832  0.54913657 0.30347652 0.314544   0.38238972 0.45840182\n",
      " 0.3267689  0.34581367 0.31011866 0.56817234 0.39332477 0.29986181\n",
      " 0.30609014 0.57452655        nan        nan        nan        nan\n",
      " 0.44455619 0.41816592 0.42717105 0.3825608  0.3431854  0.3551852\n",
      " 0.37689684 0.50086016 0.44157687 0.46370072 0.43273225 0.56818431\n",
      " 0.49666594 0.50485149 0.53012592 0.53113462        nan        nan\n",
      "        nan        nan 0.44455619 0.41816592 0.42717105 0.3825608\n",
      " 0.3431854  0.3551852  0.37689684 0.50086016 0.44157687 0.46370072\n",
      " 0.43273225 0.56818431 0.49666594 0.50485149 0.53012592 0.53113462\n",
      "        nan        nan        nan        nan 0.49978301 0.40097844\n",
      " 0.45683646 0.42459494 0.34247958 0.35655214 0.39225367 0.4460581\n",
      " 0.45612925 0.48814895 0.51165377 0.53799366 0.52292755 0.5043926\n",
      " 0.52854864 0.53033416        nan        nan        nan        nan\n",
      " 0.49978301 0.40097844 0.45683646 0.42459494 0.34247958 0.35655214\n",
      " 0.39225367 0.4460581  0.45612925 0.48814895 0.51165377 0.53799366\n",
      " 0.52292755 0.5043926  0.52854864 0.53033416        nan        nan\n",
      "        nan        nan 0.47065781 0.41974454 0.41559079 0.44290664\n",
      " 0.36604717 0.35741371 0.38669198 0.40361244 0.45078878 0.47675324\n",
      " 0.47679833 0.49588315 0.51755586 0.50070052 0.52622306 0.53043491\n",
      "        nan        nan        nan        nan 0.47065781 0.41974454\n",
      " 0.41559079 0.44290664 0.36604717 0.35741371 0.38669198 0.40361244\n",
      " 0.45078878 0.47675324 0.47679833 0.49588315 0.51755586 0.50070052\n",
      " 0.52622306 0.53043491        nan        nan        nan        nan\n",
      " 0.47065781 0.41974454 0.42924484 0.45095214 0.343319   0.35601984\n",
      " 0.39113961 0.41448071 0.44512013 0.47064762 0.50609124 0.48419478\n",
      " 0.53091354 0.49899842 0.52525409 0.53191434        nan        nan\n",
      "        nan        nan 0.47065781 0.41974454 0.42924484 0.45095214\n",
      " 0.343319   0.35601984 0.39113961 0.41448071 0.44512013 0.47064762\n",
      " 0.50609124 0.48419478 0.53091354 0.49899842 0.52525409 0.53191434\n",
      "        nan        nan        nan        nan 0.47065781 0.41974454\n",
      " 0.42924484 0.45095214 0.34289952 0.35709206 0.37068028 0.39294259\n",
      " 0.41353647 0.44743459 0.49087958 0.46229768 0.51676363 0.50050778\n",
      " 0.52891824 0.53111608        nan        nan        nan        nan\n",
      " 0.47065781 0.41974454 0.42924484 0.45095214 0.34289952 0.35709206\n",
      " 0.37068028 0.39294259 0.41353647 0.44743459 0.49087958 0.46229768\n",
      " 0.51676363 0.50050778 0.52891824 0.53111608        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 349.247s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=0.1, class_weight='balanced', kernel='sigmoid',\n",
      "                     max_iter=1000, probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5389363354037267 Best GS Acc: 0.574526548009607 Best Params: {'classification__C': 0.1, 'classification__gamma': 'scale', 'classification__kernel': 'sigmoid', 'classification__max_iter': 1000}\n",
      "Average f1 macro score:  0.44728134843763545\n",
      "\n",
      "Trait to predict:  agreeableness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33091c060dbe4688a3e3add3d576ddc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.2227583  0.2227583  0.2227583  0.56008705 0.2227583  0.2227583\n",
      " 0.2227583  0.35089447 0.2227583  0.2227583  0.33816478 0.40131431\n",
      " 0.41636346 0.41636346 0.41636346 0.41636346        nan        nan\n",
      "        nan        nan 0.2227583  0.2227583  0.2227583  0.56008705\n",
      " 0.2227583  0.2227583  0.2227583  0.35089447 0.2227583  0.2227583\n",
      " 0.33816478 0.40131431 0.41636346 0.41636346 0.41636346 0.41636346\n",
      "        nan        nan        nan        nan 0.22398075 0.25868567\n",
      " 0.3563503  0.54801928 0.2227583  0.2227583  0.2227583  0.40341602\n",
      " 0.2227583  0.2227583  0.29969595 0.37596114 0.41636346 0.41636346\n",
      " 0.41636346 0.50845991        nan        nan        nan        nan\n",
      " 0.22398075 0.25868567 0.3563503  0.54801928 0.2227583  0.2227583\n",
      " 0.2227583  0.40341602 0.2227583  0.2227583  0.29969595 0.37596114\n",
      " 0.41636346 0.41636346 0.41636346 0.50845991        nan        nan\n",
      "        nan        nan 0.39410687 0.44866634 0.48617714 0.55182049\n",
      " 0.22398075 0.2227583  0.22519227 0.44330939 0.2227583  0.2227583\n",
      " 0.32239711 0.5452777  0.4437441  0.41591228 0.41624905 0.54835351\n",
      "        nan        nan        nan        nan 0.39410687 0.44866634\n",
      " 0.48617714 0.55182049 0.22398075 0.2227583  0.22519227 0.44330939\n",
      " 0.2227583  0.2227583  0.32239711 0.5452777  0.4437441  0.41591228\n",
      " 0.41624905 0.54835351        nan        nan        nan        nan\n",
      " 0.47392499 0.47947933 0.49022167 0.47611291 0.34632502 0.28403853\n",
      " 0.41524121 0.49004    0.2227583  0.2227583  0.34473131 0.54457987\n",
      " 0.52069472 0.51243705 0.50131043 0.51459659        nan        nan\n",
      "        nan        nan 0.47392499 0.47947933 0.49022167 0.47611291\n",
      " 0.34632502 0.28403853 0.41524121 0.49004    0.2227583  0.2227583\n",
      " 0.34473131 0.54457987 0.52069472 0.51243705 0.50131043 0.51459659\n",
      "        nan        nan        nan        nan 0.46420521 0.47458677\n",
      " 0.47932123 0.45971332 0.44812368 0.47541122 0.48938218 0.50667553\n",
      " 0.35413074 0.41238728 0.51294416 0.53650724 0.5036363  0.50874754\n",
      " 0.49798685 0.50239804        nan        nan        nan        nan\n",
      " 0.46420521 0.47458677 0.47932123 0.45971332 0.44812368 0.47541122\n",
      " 0.48938218 0.50667553 0.35413074 0.41238728 0.51294416 0.53650724\n",
      " 0.5036363  0.50874754 0.49798685 0.50239804        nan        nan\n",
      "        nan        nan 0.47760372 0.48811365 0.49118622 0.46235661\n",
      " 0.45979359 0.47901381 0.48897827 0.50201959 0.41450388 0.43033814\n",
      " 0.49249965 0.5086403  0.51629635 0.50165289 0.49958314 0.50051094\n",
      "        nan        nan        nan        nan 0.47760372 0.48811365\n",
      " 0.49118622 0.46235661 0.45979359 0.47901381 0.48897827 0.50201959\n",
      " 0.41450388 0.43033814 0.49249965 0.5086403  0.51629635 0.50165289\n",
      " 0.49958314 0.50051094        nan        nan        nan        nan\n",
      " 0.45906919 0.4803641  0.46547001 0.45293966 0.45599734 0.47661914\n",
      " 0.50352831 0.49710238 0.40989116 0.44355052 0.49668063 0.52544433\n",
      " 0.51324426 0.50326013 0.49928222 0.4982196         nan        nan\n",
      "        nan        nan 0.45906919 0.4803641  0.46547001 0.45293966\n",
      " 0.45599734 0.47661914 0.50352831 0.49710238 0.40989116 0.44355052\n",
      " 0.49668063 0.52544433 0.51324426 0.50326013 0.49928222 0.4982196\n",
      "        nan        nan        nan        nan 0.45906919 0.47576004\n",
      " 0.46086595 0.44877604 0.45398087 0.46000301 0.49423218 0.48653988\n",
      " 0.39533328 0.4529252  0.53821588 0.49793299 0.51433217 0.49793079\n",
      " 0.49890331 0.49667203        nan        nan        nan        nan\n",
      " 0.45906919 0.47576004 0.46086595 0.44877604 0.45398087 0.46000301\n",
      " 0.49423218 0.48653988 0.39533328 0.4529252  0.53821588 0.49793299\n",
      " 0.51433217 0.49793079 0.49890331 0.49667203        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 343.536s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=0.001, class_weight='balanced', kernel='linear',\n",
      "                     max_iter=1000, probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.283025773982004 Best GS Acc: 0.5600870459485006 Best Params: {'classification__C': 0.001, 'classification__gamma': 'scale', 'classification__kernel': 'linear', 'classification__max_iter': 1000}\n",
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.22262382 0.22262382 0.30327586 0.51652608 0.22262382 0.22262382\n",
      " 0.22262382 0.34502276 0.22262382 0.22262382 0.33876576 0.37723459\n",
      " 0.41643888 0.41643888 0.41643888 0.41643888        nan        nan\n",
      "        nan        nan 0.22262382 0.22262382 0.30327586 0.51652608\n",
      " 0.22262382 0.22262382 0.22262382 0.34502276 0.22262382 0.22262382\n",
      " 0.33876576 0.37723459 0.41643888 0.41643888 0.41643888 0.41643888\n",
      "        nan        nan        nan        nan 0.22262382 0.27042613\n",
      " 0.41392787 0.50440564 0.22262382 0.22262382 0.22262382 0.423884\n",
      " 0.22262382 0.22262382 0.42349105 0.4334627  0.41643888 0.41643888\n",
      " 0.41643888 0.45730405        nan        nan        nan        nan\n",
      " 0.22262382 0.27042613 0.41392787 0.50440564 0.22262382 0.22262382\n",
      " 0.22262382 0.423884   0.22262382 0.22262382 0.42349105 0.4334627\n",
      " 0.41643888 0.41643888 0.41643888 0.45730405        nan        nan\n",
      "        nan        nan 0.4606832  0.46444745 0.4772901  0.50710291\n",
      " 0.22383938 0.22383938 0.22505493 0.47530747 0.22262382 0.22262382\n",
      " 0.44355394 0.50732324 0.45164136 0.41484103 0.41484103 0.506091\n",
      "        nan        nan        nan        nan 0.4606832  0.46444745\n",
      " 0.4772901  0.50710291 0.22383938 0.22383938 0.22505493 0.47530747\n",
      " 0.22262382 0.22262382 0.44355394 0.50732324 0.45164136 0.41484103\n",
      " 0.41484103 0.506091          nan        nan        nan        nan\n",
      " 0.50608683 0.47868076 0.49534161 0.48221848 0.29361022 0.27299865\n",
      " 0.38962876 0.481456   0.22262382 0.22262382 0.40241403 0.51372132\n",
      " 0.48169971 0.49924574 0.50440154 0.49737429        nan        nan\n",
      "        nan        nan 0.50608683 0.47868076 0.49534161 0.48221848\n",
      " 0.29361022 0.27299865 0.38962876 0.481456   0.22262382 0.22262382\n",
      " 0.40241403 0.51372132 0.48169971 0.49924574 0.50440154 0.49737429\n",
      "        nan        nan        nan        nan 0.49492326 0.49962991\n",
      " 0.48058584 0.47044374 0.45740892 0.47119487 0.47082171 0.50707266\n",
      " 0.35414415 0.44517577 0.49627356 0.51742829 0.49135688 0.49316149\n",
      " 0.48112916 0.4896647         nan        nan        nan        nan\n",
      " 0.49492326 0.49962991 0.48058584 0.47044374 0.45740892 0.47119487\n",
      " 0.47082171 0.50707266 0.35414415 0.44517577 0.49627356 0.51742829\n",
      " 0.49135688 0.49316149 0.48112916 0.4896647         nan        nan\n",
      "        nan        nan 0.46336584 0.48489283 0.48056893 0.53821471\n",
      " 0.45836619 0.49220395 0.47990251 0.52028666 0.44869357 0.46346357\n",
      " 0.50846008 0.51104258 0.48917604 0.4917203  0.48431693 0.49107966\n",
      "        nan        nan        nan        nan 0.46336584 0.48489283\n",
      " 0.48056893 0.53821471 0.45836619 0.49220395 0.47990251 0.52028666\n",
      " 0.44869357 0.46346357 0.50846008 0.51104258 0.48917604 0.4917203\n",
      " 0.48431693 0.49107966        nan        nan        nan        nan\n",
      " 0.48918784 0.50972    0.49105155 0.49137205 0.42240055 0.47311352\n",
      " 0.49579648 0.51302753 0.46139194 0.47125095 0.46994172 0.50592042\n",
      " 0.48182547 0.48162149 0.48413484 0.48732243        nan        nan\n",
      "        nan        nan 0.48918784 0.50972    0.49105155 0.49137205\n",
      " 0.42240055 0.47311352 0.49579648 0.51302753 0.46139194 0.47125095\n",
      " 0.46994172 0.50592042 0.48182547 0.48162149 0.48413484 0.48732243\n",
      "        nan        nan        nan        nan 0.51561039 0.51638602\n",
      " 0.49335513 0.48621206 0.4220168  0.46757112 0.48230853 0.51225996\n",
      " 0.4338245  0.46157552 0.47484387 0.5053305  0.49048645 0.49144903\n",
      " 0.48058759 0.48413833        nan        nan        nan        nan\n",
      " 0.51561039 0.51638602 0.49335513 0.48621206 0.4220168  0.46757112\n",
      " 0.48230853 0.51225996 0.4338245  0.46157552 0.47484387 0.5053305\n",
      " 0.49048645 0.49144903 0.48058759 0.48413833        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 346.247s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=100, class_weight='balanced', kernel='linear',\n",
      "                     max_iter=1000, probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5198591678939617 Best GS Acc: 0.5382147088498743 Best Params: {'classification__C': 100, 'classification__gamma': 'scale', 'classification__kernel': 'linear', 'classification__max_iter': 1000}\n",
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.22262382 0.26334576 0.30215152 0.52168892 0.22262382 0.22262382\n",
      " 0.22262382 0.38097564 0.22262382 0.22262382 0.41643888 0.44082724\n",
      " 0.41643888 0.41643888 0.41643888 0.42625401        nan        nan\n",
      "        nan        nan 0.22262382 0.26334576 0.30215152 0.52168892\n",
      " 0.22262382 0.22262382 0.22262382 0.38097564 0.22262382 0.22262382\n",
      " 0.41643888 0.44082724 0.41643888 0.41643888 0.41643888 0.42625401\n",
      "        nan        nan        nan        nan 0.22579601 0.2961656\n",
      " 0.41621653 0.51934292 0.22384627 0.22384627 0.22384627 0.41025989\n",
      " 0.22262382 0.22262382 0.41643888 0.43442038 0.41643888 0.41643888\n",
      " 0.41643888 0.45805399        nan        nan        nan        nan\n",
      " 0.22579601 0.2961656  0.41621653 0.51934292 0.22384627 0.22384627\n",
      " 0.22384627 0.41025989 0.22262382 0.22262382 0.41643888 0.43442038\n",
      " 0.41643888 0.41643888 0.41643888 0.45805399        nan        nan\n",
      "        nan        nan 0.3674265  0.4576699  0.5012624  0.51631987\n",
      " 0.22262382 0.22262382 0.22262382 0.42712729 0.22262382 0.22262382\n",
      " 0.50594462 0.51395001 0.41674973 0.41762758 0.4176288  0.52023922\n",
      "        nan        nan        nan        nan 0.3674265  0.4576699\n",
      " 0.5012624  0.51631987 0.22262382 0.22262382 0.22262382 0.42712729\n",
      " 0.22262382 0.22262382 0.50594462 0.51395001 0.41674973 0.41762758\n",
      " 0.4176288  0.52023922        nan        nan        nan        nan\n",
      " 0.47318921 0.47959512 0.48915874 0.50077577 0.32560941 0.28988138\n",
      " 0.42192734 0.49582559 0.22262382 0.2436484  0.39467486 0.52527862\n",
      " 0.50116434 0.52015562 0.52805307 0.51869808        nan        nan\n",
      "        nan        nan 0.47318921 0.47959512 0.48915874 0.50077577\n",
      " 0.32560941 0.28988138 0.42192734 0.49582559 0.22262382 0.2436484\n",
      " 0.39467486 0.52527862 0.50116434 0.52015562 0.52805307 0.51869808\n",
      "        nan        nan        nan        nan 0.49942866 0.50194271\n",
      " 0.48583512 0.47188987 0.46368621 0.49109976 0.4983269  0.51603277\n",
      " 0.3525246  0.43173872 0.5121894  0.53643006 0.51248744 0.52197671\n",
      " 0.50432889 0.50992167        nan        nan        nan        nan\n",
      " 0.49942866 0.50194271 0.48583512 0.47188987 0.46368621 0.49109976\n",
      " 0.4983269  0.51603277 0.3525246  0.43173872 0.5121894  0.53643006\n",
      " 0.51248744 0.52197671 0.50432889 0.50992167        nan        nan\n",
      "        nan        nan 0.4892375  0.51745898 0.47849396 0.49236924\n",
      " 0.4778986  0.48577007 0.50402414 0.49779891 0.44384435 0.45551314\n",
      " 0.49321247 0.49442696 0.48808554 0.51303914 0.50412722 0.50883599\n",
      "        nan        nan        nan        nan 0.4892375  0.51745898\n",
      " 0.47849396 0.49236924 0.4778986  0.48577007 0.50402414 0.49779891\n",
      " 0.44384435 0.45551314 0.49321247 0.49442696 0.48808554 0.51303914\n",
      " 0.50412722 0.50883599        nan        nan        nan        nan\n",
      " 0.48135862 0.49632612 0.46977021 0.47136401 0.47885981 0.47858197\n",
      " 0.50802243 0.50891643 0.44384435 0.4662111  0.48347817 0.50593146\n",
      " 0.47148004 0.49888823 0.50979314 0.51000007        nan        nan\n",
      "        nan        nan 0.48135862 0.49632612 0.46977021 0.47136401\n",
      " 0.47885981 0.47858197 0.50802243 0.50891643 0.44384435 0.4662111\n",
      " 0.48347817 0.50593146 0.47148004 0.49888823 0.50979314 0.51000007\n",
      "        nan        nan        nan        nan 0.48135862 0.49632612\n",
      " 0.46977021 0.47310371 0.47885981 0.47354922 0.50252066 0.5026904\n",
      " 0.44384435 0.4579743  0.49250332 0.51181205 0.47237981 0.50886259\n",
      " 0.50517527 0.50528464        nan        nan        nan        nan\n",
      " 0.48135862 0.49632612 0.46977021 0.47310371 0.47885981 0.47354922\n",
      " 0.50252066 0.5026904  0.44384435 0.4579743  0.49250332 0.51181205\n",
      " 0.47237981 0.50886259 0.50517527 0.50528464        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 342.476s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=10, class_weight='balanced', max_iter=1000,\n",
      "                     probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.53992628992629 Best GS Acc: 0.5364300552443025 Best Params: {'classification__C': 10, 'classification__gamma': 'scale', 'classification__kernel': 'rbf', 'classification__max_iter': 1000}\n",
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.22262382 0.22262382 0.22641908 0.53563466 0.22262382 0.22262382\n",
      " 0.22262382 0.30726025 0.22262382 0.22262382 0.27435888 0.40089478\n",
      " 0.41643888 0.41643888 0.41643888 0.41643888        nan        nan\n",
      "        nan        nan 0.22262382 0.22262382 0.22641908 0.53563466\n",
      " 0.22262382 0.22262382 0.22262382 0.30726025 0.22262382 0.22262382\n",
      " 0.27435888 0.40089478 0.41643888 0.41643888 0.41643888 0.41643888\n",
      "        nan        nan        nan        nan 0.22215039 0.22215325\n",
      " 0.34591768 0.52176322 0.22262382 0.22262382 0.22262382 0.42488096\n",
      " 0.22262382 0.22262382 0.3194047  0.35625175 0.41643888 0.41643888\n",
      " 0.41643888 0.54825347        nan        nan        nan        nan\n",
      " 0.22215039 0.22215325 0.34591768 0.52176322 0.22262382 0.22262382\n",
      " 0.22262382 0.42488096 0.22262382 0.22262382 0.3194047  0.35625175\n",
      " 0.41643888 0.41643888 0.41643888 0.54825347        nan        nan\n",
      "        nan        nan 0.4077123  0.47379919 0.47679123 0.52303562\n",
      " 0.22262382 0.22262382 0.22262382 0.46204792 0.22262382 0.22262382\n",
      " 0.24126779 0.53514513 0.46588487 0.41853292 0.42767438 0.53572231\n",
      "        nan        nan        nan        nan 0.4077123  0.47379919\n",
      " 0.47679123 0.52303562 0.22262382 0.22262382 0.22262382 0.46204792\n",
      " 0.22262382 0.22262382 0.24126779 0.53514513 0.46588487 0.41853292\n",
      " 0.42767438 0.53572231        nan        nan        nan        nan\n",
      " 0.49263563 0.484835   0.49156344 0.50577246 0.28166986 0.28211458\n",
      " 0.31823944 0.48544554 0.22262382 0.22262382 0.30854297 0.54014221\n",
      " 0.50671385 0.50592244 0.51801388 0.5149652         nan        nan\n",
      "        nan        nan 0.49263563 0.484835   0.49156344 0.50577246\n",
      " 0.28166986 0.28211458 0.31823944 0.48544554 0.22262382 0.22262382\n",
      " 0.30854297 0.54014221 0.50671385 0.50592244 0.51801388 0.5149652\n",
      "        nan        nan        nan        nan 0.48716141 0.47616042\n",
      " 0.49220336 0.48028386 0.47973241 0.50927561 0.5002055  0.53210875\n",
      " 0.37100776 0.44210445 0.50381192 0.53921979 0.50047113 0.50200955\n",
      " 0.49985402 0.50538288        nan        nan        nan        nan\n",
      " 0.48716141 0.47616042 0.49220336 0.48028386 0.47973241 0.50927561\n",
      " 0.5002055  0.53210875 0.37100776 0.44210445 0.50381192 0.53921979\n",
      " 0.50047113 0.50200955 0.49985402 0.50538288        nan        nan\n",
      "        nan        nan 0.49122918 0.47988276 0.48971234 0.47440201\n",
      " 0.50001042 0.50873346 0.50515526 0.51024609 0.44018639 0.47032283\n",
      " 0.487017   0.52155244 0.49669853 0.48848883 0.50765272 0.49801479\n",
      "        nan        nan        nan        nan 0.49122918 0.47988276\n",
      " 0.48971234 0.47440201 0.50001042 0.50873346 0.50515526 0.51024609\n",
      " 0.44018639 0.47032283 0.487017   0.52155244 0.49669853 0.48848883\n",
      " 0.50765272 0.49801479        nan        nan        nan        nan\n",
      " 0.4678248  0.46704066 0.48145821 0.47295159 0.48243668 0.48341629\n",
      " 0.51670227 0.51112415 0.45827074 0.45564804 0.50339289 0.51161511\n",
      " 0.51557704 0.49976789 0.50312009 0.50158204        nan        nan\n",
      "        nan        nan 0.4678248  0.46704066 0.48145821 0.47295159\n",
      " 0.48243668 0.48341629 0.51670227 0.51112415 0.45827074 0.45564804\n",
      " 0.50339289 0.51161511 0.51557704 0.49976789 0.50312009 0.50158204\n",
      "        nan        nan        nan        nan 0.47765025 0.47686611\n",
      " 0.49319515 0.47307552 0.48635408 0.48876564 0.49798792 0.50383883\n",
      " 0.43729103 0.46812312 0.52052819 0.51979963 0.49290564 0.50286535\n",
      " 0.49828051 0.49835811        nan        nan        nan        nan\n",
      " 0.47765025 0.47686611 0.49319515 0.47307552 0.48635408 0.48876564\n",
      " 0.49798792 0.50383883 0.43729103 0.46812312 0.52052819 0.51979963\n",
      " 0.49290564 0.50286535 0.49828051 0.49835811        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 343.974s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=0.01, class_weight='balanced', kernel='sigmoid',\n",
      "                     max_iter=1000, probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.4163636363636364 Best GS Acc: 0.5482534744995174 Best Params: {'classification__C': 0.01, 'classification__gamma': 'scale', 'classification__kernel': 'sigmoid', 'classification__max_iter': 1000}\n",
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.22262382 0.22262382 0.39467404 0.51814012 0.22262382 0.22262382\n",
      " 0.22262382 0.38253028 0.22262382 0.22262382 0.41643888 0.41643888\n",
      " 0.41643888 0.41643888 0.41643888 0.41643888        nan        nan\n",
      "        nan        nan 0.22262382 0.22262382 0.39467404 0.51814012\n",
      " 0.22262382 0.22262382 0.22262382 0.38253028 0.22262382 0.22262382\n",
      " 0.41643888 0.41643888 0.41643888 0.41643888 0.41643888 0.41643888\n",
      "        nan        nan        nan        nan 0.22262382 0.25825759\n",
      " 0.48958501 0.51646424 0.22262382 0.22262382 0.22262382 0.42522587\n",
      " 0.22262382 0.22262382 0.37723459 0.38100493 0.41643888 0.41643888\n",
      " 0.41643888 0.47874355        nan        nan        nan        nan\n",
      " 0.22262382 0.25825759 0.48958501 0.51646424 0.22262382 0.22262382\n",
      " 0.22262382 0.42522587 0.22262382 0.22262382 0.37723459 0.38100493\n",
      " 0.41643888 0.41643888 0.41643888 0.47874355        nan        nan\n",
      "        nan        nan 0.43760944 0.48772155 0.51824306 0.53061296\n",
      " 0.22384627 0.22384627 0.22384627 0.45845305 0.22262382 0.22262382\n",
      " 0.43649435 0.50683391 0.45431941 0.42220536 0.42325647 0.51857546\n",
      "        nan        nan        nan        nan 0.43760944 0.48772155\n",
      " 0.51824306 0.53061296 0.22384627 0.22384627 0.22384627 0.45845305\n",
      " 0.22262382 0.22262382 0.43649435 0.50683391 0.45431941 0.42220536\n",
      " 0.42325647 0.51857546        nan        nan        nan        nan\n",
      " 0.5008897  0.51471391 0.49632608 0.4908627  0.36894224 0.29207193\n",
      " 0.5046739  0.5091193  0.22262382 0.22262382 0.37498351 0.53930118\n",
      " 0.51221231 0.51661004 0.51203897 0.50454366        nan        nan\n",
      "        nan        nan 0.5008897  0.51471391 0.49632608 0.4908627\n",
      " 0.36894224 0.29207193 0.5046739  0.5091193  0.22262382 0.22262382\n",
      " 0.37498351 0.53930118 0.51221231 0.51661004 0.51203897 0.50454366\n",
      "        nan        nan        nan        nan 0.50194965 0.50285837\n",
      " 0.47439299 0.4908111  0.46091677 0.48440682 0.47733784 0.50063831\n",
      " 0.35646776 0.43098887 0.51951624 0.54830098 0.48827097 0.51990193\n",
      " 0.50527574 0.50826956        nan        nan        nan        nan\n",
      " 0.50194965 0.50285837 0.47439299 0.4908111  0.46091677 0.48440682\n",
      " 0.47733784 0.50063831 0.35646776 0.43098887 0.51951624 0.54830098\n",
      " 0.48827097 0.51990193 0.50527574 0.50826956        nan        nan\n",
      "        nan        nan 0.48965342 0.48742556 0.4740685  0.47129239\n",
      " 0.46223479 0.48110461 0.48543078 0.50004528 0.43454689 0.46993992\n",
      " 0.50012414 0.50354584 0.48841409 0.51512357 0.50217419 0.50075201\n",
      "        nan        nan        nan        nan 0.48965342 0.48742556\n",
      " 0.4740685  0.47129239 0.46223479 0.48110461 0.48543078 0.50004528\n",
      " 0.43454689 0.46993992 0.50012414 0.50354584 0.48841409 0.51512357\n",
      " 0.50217419 0.50075201        nan        nan        nan        nan\n",
      " 0.51005246 0.49570031 0.47519003 0.48139625 0.46597827 0.47919619\n",
      " 0.50027111 0.47919624 0.43454689 0.46620794 0.48071107 0.49715942\n",
      " 0.50356745 0.53129253 0.50522726 0.50411823        nan        nan\n",
      "        nan        nan 0.51005246 0.49570031 0.47519003 0.48139625\n",
      " 0.46597827 0.47919619 0.50027111 0.47919624 0.43454689 0.46620794\n",
      " 0.48071107 0.49715942 0.50356745 0.53129253 0.50522726 0.50411823\n",
      "        nan        nan        nan        nan 0.51005246 0.50332963\n",
      " 0.4654305  0.47242124 0.46707834 0.48703741 0.48502953 0.49327884\n",
      " 0.43454689 0.46620794 0.48710946 0.49948442 0.5086102  0.52268852\n",
      " 0.51088692 0.51115755        nan        nan        nan        nan\n",
      " 0.51005246 0.50332963 0.4654305  0.47242124 0.46707834 0.48703741\n",
      " 0.48502953 0.49327884 0.43454689 0.46620794 0.48710946 0.49948442\n",
      " 0.5086102  0.52268852 0.51088692 0.51115755        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 343.023s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=10, class_weight='balanced', max_iter=1000,\n",
      "                     probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5545740684333436 Best GS Acc: 0.5483009849909999 Best Params: {'classification__C': 10, 'classification__gamma': 'scale', 'classification__kernel': 'rbf', 'classification__max_iter': 1000}\n",
      "Average f1 macro score:  0.4627497873198472\n",
      "\n",
      "Trait to predict:  neuroticism \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e19908ac09ef496f856459fa1bbc9582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.33328941 0.41192232 0.38354871 0.5498727  0.33055192 0.33055192\n",
      " 0.33055192 0.33624116 0.33055192 0.33055192 0.33505373 0.36080333\n",
      " 0.33609136 0.33609136 0.33609136 0.33609136        nan        nan\n",
      "        nan        nan 0.33328941 0.41192232 0.38354871 0.5498727\n",
      " 0.33055192 0.33055192 0.33055192 0.33624116 0.33055192 0.33055192\n",
      " 0.33505373 0.36080333 0.33609136 0.33609136 0.33609136 0.33609136\n",
      "        nan        nan        nan        nan 0.36845825 0.44762632\n",
      " 0.52055507 0.55554729 0.33055192 0.33055192 0.33055192 0.37400614\n",
      " 0.33055192 0.33055192 0.3771377  0.36064045 0.33609136 0.33609136\n",
      " 0.33609136 0.34630711        nan        nan        nan        nan\n",
      " 0.36845825 0.44762632 0.52055507 0.55554729 0.33055192 0.33055192\n",
      " 0.33055192 0.37400614 0.33055192 0.33055192 0.3771377  0.36064045\n",
      " 0.33609136 0.33609136 0.33609136 0.34630711        nan        nan\n",
      "        nan        nan 0.49397301 0.42466139 0.47334361 0.55592469\n",
      " 0.35009993 0.38403384 0.34701199 0.43093753 0.33055192 0.33055192\n",
      " 0.42973224 0.56817045 0.3579574  0.35276108 0.36284297 0.54114374\n",
      "        nan        nan        nan        nan 0.49397301 0.42466139\n",
      " 0.47334361 0.55592469 0.35009993 0.38403384 0.34701199 0.43093753\n",
      " 0.33055192 0.33055192 0.42973224 0.56817045 0.3579574  0.35276108\n",
      " 0.36284297 0.54114374        nan        nan        nan        nan\n",
      " 0.46757469 0.47048675 0.42778914 0.46657078 0.40938933 0.44396233\n",
      " 0.45473425 0.49084869 0.33647329 0.3753582  0.53775868 0.58111588\n",
      " 0.48740046 0.50675862 0.52043216 0.53314537        nan        nan\n",
      "        nan        nan 0.46757469 0.47048675 0.42778914 0.46657078\n",
      " 0.40938933 0.44396233 0.45473425 0.49084869 0.33647329 0.3753582\n",
      " 0.53775868 0.58111588 0.48740046 0.50675862 0.52043216 0.53314537\n",
      "        nan        nan        nan        nan 0.49125664 0.4934123\n",
      " 0.44550258 0.43066939 0.39228945 0.44104777 0.4631521  0.49670928\n",
      " 0.5228785  0.52892362 0.54830965 0.56936205 0.5171691  0.52299206\n",
      " 0.50824565 0.50425487        nan        nan        nan        nan\n",
      " 0.49125664 0.4934123  0.44550258 0.43066939 0.39228945 0.44104777\n",
      " 0.4631521  0.49670928 0.5228785  0.52892362 0.54830965 0.56936205\n",
      " 0.5171691  0.52299206 0.50824565 0.50425487        nan        nan\n",
      "        nan        nan 0.49125664 0.48533745 0.4685129  0.46949404\n",
      " 0.39224558 0.43300818 0.46484158 0.51593174 0.53286681 0.53532108\n",
      " 0.53584028 0.53677007 0.52176146 0.52141201 0.51462718 0.52302541\n",
      "        nan        nan        nan        nan 0.49125664 0.48533745\n",
      " 0.4685129  0.46949404 0.39224558 0.43300818 0.46484158 0.51593174\n",
      " 0.53286681 0.53532108 0.53584028 0.53677007 0.52176146 0.52141201\n",
      " 0.51462718 0.52302541        nan        nan        nan        nan\n",
      " 0.49125664 0.48475812 0.46973807 0.45334239 0.38411444 0.44475319\n",
      " 0.46555674 0.49831276 0.53286681 0.5272888  0.53847559 0.52618833\n",
      " 0.51448844 0.51314562 0.52089409 0.52394382        nan        nan\n",
      "        nan        nan 0.49125664 0.48475812 0.46973807 0.45334239\n",
      " 0.38411444 0.44475319 0.46555674 0.49831276 0.53286681 0.5272888\n",
      " 0.53847559 0.52618833 0.51448844 0.51314562 0.52089409 0.52394382\n",
      "        nan        nan        nan        nan 0.49125664 0.48475812\n",
      " 0.46973807 0.45334239 0.38411444 0.44493383 0.45861149 0.49107266\n",
      " 0.53286681 0.5272888  0.53847559 0.53547743 0.51228201 0.52012161\n",
      " 0.52559598 0.52792062        nan        nan        nan        nan\n",
      " 0.49125664 0.48475812 0.46973807 0.45334239 0.38411444 0.44493383\n",
      " 0.45861149 0.49107266 0.53286681 0.5272888  0.53847559 0.53547743\n",
      " 0.51228201 0.52012161 0.52559598 0.52792062        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 349.351s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=1, class_weight='balanced', max_iter=1000,\n",
      "                     probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5403017324536019 Best GS Acc: 0.5811158809201297 Best Params: {'classification__C': 1, 'classification__gamma': 'scale', 'classification__kernel': 'rbf', 'classification__max_iter': 1000}\n",
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.33037968 0.36386421 0.35719254 0.55572925 0.33037968 0.33037968\n",
      " 0.33037968 0.33267861 0.33037968 0.33037968 0.33141731 0.35941893\n",
      " 0.33625962 0.33625962 0.33625962 0.33625962        nan        nan\n",
      "        nan        nan 0.33037968 0.36386421 0.35719254 0.55572925\n",
      " 0.33037968 0.33037968 0.33037968 0.33267861 0.33037968 0.33037968\n",
      " 0.33141731 0.35941893 0.33625962 0.33625962 0.33625962 0.33625962\n",
      "        nan        nan        nan        nan 0.39325461 0.46678269\n",
      " 0.50136629 0.5640524  0.33037968 0.33037968 0.33037968 0.39292815\n",
      " 0.33037968 0.33037968 0.36259893 0.47215082 0.33625962 0.33625962\n",
      " 0.33625962 0.41140663        nan        nan        nan        nan\n",
      " 0.39325461 0.46678269 0.50136629 0.5640524  0.33037968 0.33037968\n",
      " 0.33037968 0.39292815 0.33037968 0.33037968 0.36259893 0.47215082\n",
      " 0.33625962 0.33625962 0.33625962 0.41140663        nan        nan\n",
      "        nan        nan 0.43904428 0.47149779 0.4739604  0.56589897\n",
      " 0.33003019 0.33003019 0.3296807  0.47260927 0.33037968 0.33037968\n",
      " 0.39808829 0.55424595 0.34214863 0.33798557 0.34371175 0.55796637\n",
      "        nan        nan        nan        nan 0.43904428 0.47149779\n",
      " 0.4739604  0.56589897 0.33003019 0.33003019 0.3296807  0.47260927\n",
      " 0.33037968 0.33037968 0.39808829 0.55424595 0.34214863 0.33798557\n",
      " 0.34371175 0.55796637        nan        nan        nan        nan\n",
      " 0.43064019 0.42543093 0.42170517 0.43936941 0.41670426 0.46639943\n",
      " 0.46048383 0.53022219 0.33037968 0.33037968 0.42868879 0.56486684\n",
      " 0.50623203 0.5036851  0.51356603 0.53337804        nan        nan\n",
      "        nan        nan 0.43064019 0.42543093 0.42170517 0.43936941\n",
      " 0.41670426 0.46639943 0.46048383 0.53022219 0.33037968 0.33037968\n",
      " 0.42868879 0.56486684 0.50623203 0.5036851  0.51356603 0.53337804\n",
      "        nan        nan        nan        nan 0.4561395  0.44357676\n",
      " 0.4166621  0.41496563 0.39228509 0.42506098 0.45991066 0.50756276\n",
      " 0.47546668 0.48346838 0.52785846 0.56138374 0.5312325  0.51790404\n",
      " 0.52282473 0.5237443         nan        nan        nan        nan\n",
      " 0.4561395  0.44357676 0.4166621  0.41496563 0.39228509 0.42506098\n",
      " 0.45991066 0.50756276 0.47546668 0.48346838 0.52785846 0.56138374\n",
      " 0.5312325  0.51790404 0.52282473 0.5237443         nan        nan\n",
      "        nan        nan 0.45044632 0.4533187  0.43799594 0.42228996\n",
      " 0.39240154 0.40727309 0.47133712 0.47915916 0.4782244  0.47200159\n",
      " 0.50954793 0.50621169 0.52207462 0.52017803 0.52046284 0.51853051\n",
      "        nan        nan        nan        nan 0.45044632 0.4533187\n",
      " 0.43799594 0.42228996 0.39240154 0.40727309 0.47133712 0.47915916\n",
      " 0.4782244  0.47200159 0.50954793 0.50621169 0.52207462 0.52017803\n",
      " 0.52046284 0.51853051        nan        nan        nan        nan\n",
      " 0.45162661 0.44367881 0.43973848 0.42503528 0.40143913 0.41570791\n",
      " 0.45546194 0.48013546 0.48933928 0.4919887  0.50379324 0.5015422\n",
      " 0.51349459 0.52479603 0.51747479 0.52011278        nan        nan\n",
      "        nan        nan 0.45162661 0.44367881 0.43973848 0.42503528\n",
      " 0.40143913 0.41570791 0.45546194 0.48013546 0.48933928 0.4919887\n",
      " 0.50379324 0.5015422  0.51349459 0.52479603 0.51747479 0.52011278\n",
      "        nan        nan        nan        nan 0.45941877 0.44246388\n",
      " 0.46872498 0.41763402 0.4050229  0.40472743 0.4511307  0.46984212\n",
      " 0.49070828 0.4698572  0.49377397 0.5190877  0.51715955 0.52095313\n",
      " 0.52296289 0.52741704        nan        nan        nan        nan\n",
      " 0.45941877 0.44246388 0.46872498 0.41763402 0.4050229  0.40472743\n",
      " 0.4511307  0.46984212 0.49070828 0.4698572  0.49377397 0.5190877\n",
      " 0.51715955 0.52095313 0.52296289 0.52741704        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 342.813s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=0.1, class_weight='balanced', kernel='linear',\n",
      "                     max_iter=1000, probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.4802461139896373 Best GS Acc: 0.5658989717395284 Best Params: {'classification__C': 0.1, 'classification__gamma': 'scale', 'classification__kernel': 'linear', 'classification__max_iter': 1000}\n",
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.33037968 0.36460869 0.36783596 0.55469992 0.33037968 0.33037968\n",
      " 0.33037968 0.33300839 0.33037968 0.33037968 0.33625962 0.33453019\n",
      " 0.33625962 0.33625962 0.33625962 0.33625962        nan        nan\n",
      "        nan        nan 0.33037968 0.36460869 0.36783596 0.55469992\n",
      " 0.33037968 0.33037968 0.33037968 0.33300839 0.33037968 0.33037968\n",
      " 0.33625962 0.33453019 0.33625962 0.33625962 0.33625962 0.33625962\n",
      "        nan        nan        nan        nan 0.39784713 0.40908117\n",
      " 0.48801941 0.55765011 0.33037968 0.33037968 0.33037968 0.35752439\n",
      " 0.33037968 0.33037968 0.33625962 0.39265985 0.33625962 0.33625962\n",
      " 0.33625962 0.37634225        nan        nan        nan        nan\n",
      " 0.39784713 0.40908117 0.48801941 0.55765011 0.33037968 0.33037968\n",
      " 0.33037968 0.35752439 0.33037968 0.33037968 0.33625962 0.39265985\n",
      " 0.33625962 0.33625962 0.33625962 0.37634225        nan        nan\n",
      "        nan        nan 0.45838089 0.44932779 0.47417877 0.55723858\n",
      " 0.32967887 0.33003019 0.33003019 0.42217962 0.33037968 0.33037968\n",
      " 0.48848773 0.56019807 0.34897067 0.33557323 0.33936709 0.55821328\n",
      "        nan        nan        nan        nan 0.45838089 0.44932779\n",
      " 0.47417877 0.55723858 0.32967887 0.33003019 0.33003019 0.42217962\n",
      " 0.33037968 0.33037968 0.48848773 0.56019807 0.34897067 0.33557323\n",
      " 0.33936709 0.55821328        nan        nan        nan        nan\n",
      " 0.48410908 0.4395819  0.42797321 0.44465629 0.40593121 0.43981999\n",
      " 0.44622006 0.46874192 0.33037968 0.38649253 0.53355758 0.56304084\n",
      " 0.50556432 0.47273572 0.53800847 0.55530433        nan        nan\n",
      "        nan        nan 0.48410908 0.4395819  0.42797321 0.44465629\n",
      " 0.40593121 0.43981999 0.44622006 0.46874192 0.33037968 0.38649253\n",
      " 0.53355758 0.56304084 0.50556432 0.47273572 0.53800847 0.55530433\n",
      "        nan        nan        nan        nan 0.45217428 0.45428372\n",
      " 0.45002916 0.4321854  0.40242144 0.42557808 0.45529968 0.51146063\n",
      " 0.49587619 0.52938341 0.55603561 0.56580578 0.52819927 0.53589434\n",
      " 0.54914816 0.54382545        nan        nan        nan        nan\n",
      " 0.45217428 0.45428372 0.45002916 0.4321854  0.40242144 0.42557808\n",
      " 0.45529968 0.51146063 0.49587619 0.52938341 0.55603561 0.56580578\n",
      " 0.52819927 0.53589434 0.54914816 0.54382545        nan        nan\n",
      "        nan        nan 0.46626216 0.46844865 0.43768942 0.44961446\n",
      " 0.39087668 0.43024661 0.49832028 0.51653963 0.49977762 0.50482648\n",
      " 0.52659816 0.53563401 0.51221533 0.53469594 0.53050731 0.5280007\n",
      "        nan        nan        nan        nan 0.46626216 0.46844865\n",
      " 0.43768942 0.44961446 0.39087668 0.43024661 0.49832028 0.51653963\n",
      " 0.49977762 0.50482648 0.52659816 0.53563401 0.51221533 0.53469594\n",
      " 0.53050731 0.5280007         nan        nan        nan        nan\n",
      " 0.48521676 0.45618661 0.44769494 0.44674474 0.38261124 0.41738163\n",
      " 0.47224571 0.51858252 0.49754587 0.50881493 0.53927962 0.53522014\n",
      " 0.51082362 0.54308815 0.53687349 0.53594006        nan        nan\n",
      "        nan        nan 0.48521676 0.45618661 0.44769494 0.44674474\n",
      " 0.38261124 0.41738163 0.47224571 0.51858252 0.49754587 0.50881493\n",
      " 0.53927962 0.53522014 0.51082362 0.54308815 0.53687349 0.53594006\n",
      "        nan        nan        nan        nan 0.46561893 0.46432816\n",
      " 0.46764492 0.46763974 0.36992409 0.40262649 0.44992143 0.50567804\n",
      " 0.50501372 0.48934181 0.51280688 0.53046044 0.53661036 0.5479174\n",
      " 0.53483922 0.5460343         nan        nan        nan        nan\n",
      " 0.46561893 0.46432816 0.46764492 0.46763974 0.36992409 0.40262649\n",
      " 0.44992143 0.50567804 0.50501372 0.48934181 0.51280688 0.53046044\n",
      " 0.53661036 0.5479174  0.53483922 0.5460343         nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 345.309s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=10, class_weight='balanced', max_iter=1000,\n",
      "                     probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5699891279024618 Best GS Acc: 0.5658057842475704 Best Params: {'classification__C': 10, 'classification__gamma': 'scale', 'classification__kernel': 'rbf', 'classification__max_iter': 1000}\n",
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.3516354  0.33246034 0.33687938 0.55644393 0.33072917 0.33072917\n",
      " 0.33072917 0.33107322 0.33072917 0.3317668  0.33487968 0.33591731\n",
      " 0.33591731 0.33591731 0.33591731 0.33591731        nan        nan\n",
      "        nan        nan 0.3516354  0.33246034 0.33687938 0.55644393\n",
      " 0.33072917 0.33072917 0.33072917 0.33107322 0.33072917 0.3317668\n",
      " 0.33487968 0.33591731 0.33591731 0.33591731 0.33591731 0.33591731\n",
      "        nan        nan        nan        nan 0.39393763 0.50582608\n",
      " 0.53527649 0.56610279 0.33072917 0.33072917 0.33072917 0.34992131\n",
      " 0.33072917 0.33314671 0.33487968 0.38776935 0.33591731 0.33591731\n",
      " 0.33591731 0.39357626        nan        nan        nan        nan\n",
      " 0.39393763 0.50582608 0.53527649 0.56610279 0.33072917 0.33072917\n",
      " 0.33072917 0.34992131 0.33072917 0.33314671 0.33487968 0.38776935\n",
      " 0.33591731 0.33591731 0.33591731 0.39357626        nan        nan\n",
      "        nan        nan 0.45826265 0.43704133 0.47240647 0.56332859\n",
      " 0.33072917 0.33072917 0.33072917 0.45894125 0.33072917 0.33072917\n",
      " 0.50946834 0.55412873 0.34382886 0.33591731 0.33939041 0.56042857\n",
      "        nan        nan        nan        nan 0.45826265 0.43704133\n",
      " 0.47240647 0.56332859 0.33072917 0.33072917 0.33072917 0.45894125\n",
      " 0.33072917 0.33072917 0.50946834 0.55412873 0.34382886 0.33591731\n",
      " 0.33939041 0.56042857        nan        nan        nan        nan\n",
      " 0.46934852 0.42054752 0.43759687 0.42726391 0.40735453 0.45440056\n",
      " 0.45996201 0.50259686 0.33660325 0.33037968 0.49056142 0.54839432\n",
      " 0.50517654 0.51296058 0.54848098 0.5684824         nan        nan\n",
      "        nan        nan 0.46934852 0.42054752 0.43759687 0.42726391\n",
      " 0.40735453 0.45440056 0.45996201 0.50259686 0.33660325 0.33037968\n",
      " 0.49056142 0.54839432 0.50517654 0.51296058 0.54848098 0.5684824\n",
      "        nan        nan        nan        nan 0.45064435 0.44231496\n",
      " 0.42791073 0.43126969 0.4037798  0.44390325 0.45185073 0.50163309\n",
      " 0.49288382 0.48597579 0.53501034 0.53362934 0.52310603 0.54084585\n",
      " 0.54953527 0.54519069        nan        nan        nan        nan\n",
      " 0.45064435 0.44231496 0.42791073 0.43126969 0.4037798  0.44390325\n",
      " 0.45185073 0.50163309 0.49288382 0.48597579 0.53501034 0.53362934\n",
      " 0.52310603 0.54084585 0.54953527 0.54519069        nan        nan\n",
      "        nan        nan 0.45064435 0.49534183 0.45230058 0.44753697\n",
      " 0.40936573 0.43665332 0.48674105 0.51548363 0.48054157 0.50388386\n",
      " 0.51152142 0.52433342 0.53038263 0.55318408 0.54493541 0.54674172\n",
      "        nan        nan        nan        nan 0.45064435 0.49534183\n",
      " 0.45230058 0.44753697 0.40936573 0.43665332 0.48674105 0.51548363\n",
      " 0.48054157 0.50388386 0.51152142 0.52433342 0.53038263 0.55318408\n",
      " 0.54493541 0.54674172        nan        nan        nan        nan\n",
      " 0.45064435 0.49534183 0.45230058 0.46141729 0.40652869 0.4370355\n",
      " 0.45586892 0.49732159 0.48054157 0.50388386 0.5115413  0.52018535\n",
      " 0.51841295 0.55937321 0.55238634 0.54791451        nan        nan\n",
      "        nan        nan 0.45064435 0.49534183 0.45230058 0.46141729\n",
      " 0.40652869 0.4370355  0.45586892 0.49732159 0.48054157 0.50388386\n",
      " 0.5115413  0.52018535 0.51841295 0.55937321 0.55238634 0.54791451\n",
      "        nan        nan        nan        nan 0.45064435 0.49534183\n",
      " 0.45230058 0.46141729 0.40652869 0.4370355  0.47873996 0.49188659\n",
      " 0.48054157 0.50388386 0.51310057 0.51319016 0.52070892 0.55536184\n",
      " 0.54902368 0.54806681        nan        nan        nan        nan\n",
      " 0.45064435 0.49534183 0.45230058 0.46141729 0.40652869 0.4370355\n",
      " 0.47873996 0.49188659 0.48054157 0.50388386 0.51310057 0.51319016\n",
      " 0.52070892 0.55536184 0.54902368 0.54806681        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 344.435s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=1, class_weight='balanced', kernel='sigmoid',\n",
      "                     max_iter=1000, probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5856536972155634 Best GS Acc: 0.5684823961551178 Best Params: {'classification__C': 1, 'classification__gamma': 'scale', 'classification__kernel': 'sigmoid', 'classification__max_iter': 1000}\n",
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.3320791  0.37931844 0.35718906 0.58887762 0.33072917 0.33072917\n",
      " 0.33072917 0.333417   0.33072917 0.33072917 0.37456486 0.34443483\n",
      " 0.33591731 0.33591731 0.33591731 0.33591731        nan        nan\n",
      "        nan        nan 0.3320791  0.37931844 0.35718906 0.58887762\n",
      " 0.33072917 0.33072917 0.33072917 0.333417   0.33072917 0.33072917\n",
      " 0.37456486 0.34443483 0.33591731 0.33591731 0.33591731 0.33591731\n",
      "        nan        nan        nan        nan 0.39613466 0.50259057\n",
      " 0.54297341 0.58250613 0.33072917 0.33072917 0.33072917 0.39691089\n",
      " 0.33072917 0.33072917 0.33072917 0.33557323 0.33591731 0.33591731\n",
      " 0.33591731 0.36492807        nan        nan        nan        nan\n",
      " 0.39613466 0.50259057 0.54297341 0.58250613 0.33072917 0.33072917\n",
      " 0.33072917 0.39691089 0.33072917 0.33072917 0.33072917 0.33557323\n",
      " 0.33591731 0.33591731 0.33591731 0.36492807        nan        nan\n",
      "        nan        nan 0.46938129 0.43131341 0.47335312 0.57949432\n",
      " 0.3575319  0.33303361 0.3296807  0.45910236 0.33072917 0.33072917\n",
      " 0.3745006  0.57247806 0.34059529 0.34239203 0.34206381 0.58593442\n",
      "        nan        nan        nan        nan 0.46938129 0.43131341\n",
      " 0.47335312 0.57949432 0.3575319  0.33303361 0.3296807  0.45910236\n",
      " 0.33072917 0.33072917 0.3745006  0.57247806 0.34059529 0.34239203\n",
      " 0.34206381 0.58593442        nan        nan        nan        nan\n",
      " 0.47389195 0.48266843 0.44261915 0.44233836 0.42148261 0.44008748\n",
      " 0.46404988 0.524177   0.33072917 0.33072917 0.44705703 0.54872936\n",
      " 0.54324954 0.51244411 0.53597694 0.54780294        nan        nan\n",
      "        nan        nan 0.47389195 0.48266843 0.44261915 0.44233836\n",
      " 0.42148261 0.44008748 0.46404988 0.524177   0.33072917 0.33072917\n",
      " 0.44705703 0.54872936 0.54324954 0.51244411 0.53597694 0.54780294\n",
      "        nan        nan        nan        nan 0.48126361 0.49270785\n",
      " 0.4159164  0.42093381 0.39798958 0.42455755 0.44823685 0.49888919\n",
      " 0.49797406 0.50968278 0.52700792 0.53949004 0.54561367 0.53959982\n",
      " 0.55479802 0.55103694        nan        nan        nan        nan\n",
      " 0.48126361 0.49270785 0.4159164  0.42093381 0.39798958 0.42455755\n",
      " 0.44823685 0.49888919 0.49797406 0.50968278 0.52700792 0.53949004\n",
      " 0.54561367 0.53959982 0.55479802 0.55103694        nan        nan\n",
      "        nan        nan 0.46599563 0.44829678 0.42697988 0.41090202\n",
      " 0.38767774 0.41349147 0.4569947  0.48972871 0.48333897 0.50683206\n",
      " 0.5193925  0.5337086  0.53052059 0.55019234 0.55466729 0.54570675\n",
      "        nan        nan        nan        nan 0.46599563 0.44829678\n",
      " 0.42697988 0.41090202 0.38767774 0.41349147 0.4569947  0.48972871\n",
      " 0.48333897 0.50683206 0.5193925  0.5337086  0.53052059 0.55019234\n",
      " 0.55466729 0.54570675        nan        nan        nan        nan\n",
      " 0.47082356 0.46809894 0.46478219 0.41565025 0.39337114 0.41193044\n",
      " 0.45882916 0.48556455 0.48333897 0.50369624 0.51773286 0.52129188\n",
      " 0.53718194 0.53015023 0.54138155 0.53087346        nan        nan\n",
      "        nan        nan 0.47082356 0.46809894 0.46478219 0.41565025\n",
      " 0.39337114 0.41193044 0.45882916 0.48556455 0.48333897 0.50369624\n",
      " 0.51773286 0.52129188 0.53718194 0.53015023 0.54138155 0.53087346\n",
      "        nan        nan        nan        nan 0.4795559  0.47752565\n",
      " 0.45420546 0.44743852 0.39467273 0.40762551 0.4468011  0.49000441\n",
      " 0.48333897 0.5131037  0.51218186 0.51578468 0.55366926 0.53627454\n",
      " 0.5458183  0.54481706        nan        nan        nan        nan\n",
      " 0.4795559  0.47752565 0.45420546 0.44743852 0.39467273 0.40762551\n",
      " 0.4468011  0.49000441 0.48333897 0.5131037  0.51218186 0.51578468\n",
      " 0.55366926 0.53627454 0.5458183  0.54481706        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 347.918s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=0.001, class_weight='balanced', kernel='linear',\n",
      "                     max_iter=1000, probability=True))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.45675603455954394 Best GS Acc: 0.5888776195024077 Best Params: {'classification__C': 0.001, 'classification__gamma': 'scale', 'classification__kernel': 'linear', 'classification__max_iter': 1000}\n",
      "Average f1 macro score:  0.5265893412241617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    }
   ],
   "source": [
    "clf_lst = ['mcc', 'log', 'mlp', 'svm']\n",
    "classify_cv(df, 'binary', clf_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression with subsets of the features\n",
      "LR with word ngrams\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9132b24e75094b33be9d6264d4dc980d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:  log \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3138cbe735574190b5838c9eab372efb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trait to predict:  openness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ffc9708554547e1b623a0608dceb68f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 16.683s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.6080200501253132 Best GS Acc: 0.5139708362623485 Best Params: {'classification__C': 0.1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 12.976s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5288400507775309 Best GS Acc: 0.5483258130952888 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 13.876s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5163720369626357 Best GS Acc: 0.5394892767975861 Best Params: {'classification__C': 1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 13.745s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.4864821628539434 Best GS Acc: 0.5227199290447601 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 13.731s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5133713153331683 Best GS Acc: 0.5563486393281919 Best Params: {'classification__C': 1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "Average f1 macro score:  0.5306171232105183\n",
      "\n",
      "Trait to predict:  conscientiousness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74de6e37cecb4006bca44904ff34795f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 14.096s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=10, class_weight='balanced', max_iter=200,\n",
      "                                    solver='saga'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5866077656358987 Best GS Acc: 0.5421639347285986 Best Params: {'classification__C': 10, 'classification__max_iter': 200, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 13.774s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5620294102784376 Best GS Acc: 0.5507921034026084 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 17.790s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced',\n",
      "                                    solver='saga'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5570908654615261 Best GS Acc: 0.5594624113435078 Best Params: {'classification__C': 1, 'classification__max_iter': 100, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 16.248s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=10, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5944716761837385 Best GS Acc: 0.5367773179385658 Best Params: {'classification__C': 10, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 13.158s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5179397678382984 Best GS Acc: 0.5543344659282415 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "Average f1 macro score:  0.5636278970795799\n",
      "\n",
      "Trait to predict:  extraversion \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce3238ad92644b40b28c67da5a1db0e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 13.146s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5357880381842977 Best GS Acc: 0.5797161814074788 Best Params: {'classification__C': 1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 13.101s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5917329093799681 Best GS Acc: 0.569958100376134 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 13.234s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    solver='saga'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.545747328356024 Best GS Acc: 0.5796944698824866 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 13.173s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.6585106382978724 Best GS Acc: 0.5749345741501694 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 13.149s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5734618148173667 Best GS Acc: 0.5731083112572882 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "Average f1 macro score:  0.5810481458071057\n",
      "\n",
      "Trait to predict:  agreeableness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b768392f905644d7882eeeeb4c544278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 13.264s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5213017269468883 Best GS Acc: 0.5538443789909021 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 13.110s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5914018231091401 Best GS Acc: 0.5189534477475692 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 13.984s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5374827502232324 Best GS Acc: 0.5250955444035894 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 13.907s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5131792549555707 Best GS Acc: 0.558705294423669 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 13.973s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5153366773065816 Best GS Acc: 0.537900353784105 Best Params: {'classification__C': 0.1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "Average f1 macro score:  0.5357404465082827\n",
      "\n",
      "Trait to predict:  neuroticism \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1885b6585b004d469dfb4fad7cb18e26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 14.489s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5775745649573638 Best GS Acc: 0.5539248906710565 Best Params: {'classification__C': 0.1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 13.199s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5383987563155849 Best GS Acc: 0.6014496515437132 Best Params: {'classification__C': 1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 13.237s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5416112141906528 Best GS Acc: 0.5741911227759505 Best Params: {'classification__C': 1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 13.656s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.554084378430363 Best GS Acc: 0.5931539293324152 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 13.048s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.535537061673966 Best GS Acc: 0.5721416930973492 Best Params: {'classification__C': 1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "Average f1 macro score:  0.5494411951135861\n"
     ]
    }
   ],
   "source": [
    "small_clf_lst = ['log']\n",
    "print(\"Logistic regression with subsets of the features\")\n",
    "print(\"LR with word ngrams\")\n",
    "classify_cv(log_wordngrams_df, 'binary', small_clf_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR with char ngrams\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51182da0b694434f91d9358f4d191d52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:  log \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2033112c5fb047859c86f60a2483b4e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trait to predict:  openness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1633a7f3fe174bc1b8f8aad96ac983fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 14.256s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=100, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5402388369678088 Best GS Acc: 0.5392401366974038 Best Params: {'classification__C': 100, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 14.263s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.49323996113989643 Best GS Acc: 0.5296247848999082 Best Params: {'classification__C': 0.1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 14.612s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5434399896559613 Best GS Acc: 0.5484435931495957 Best Params: {'classification__C': 0.1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 15.005s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5558345718239123 Best GS Acc: 0.5155704729807918 Best Params: {'classification__C': 1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 15.285s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5215620031796503 Best GS Acc: 0.5639980625792947 Best Params: {'classification__C': 0.1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "Average f1 macro score:  0.5308630725534458\n",
      "\n",
      "Trait to predict:  conscientiousness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76d04c1ebfd449b58bb1b70308fbaef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 18.109s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.580149603443036 Best GS Acc: 0.5328250815924269 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 17.408s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=100, class_weight='balanced',\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5345952476842529 Best GS Acc: 0.5377589506504448 Best Params: {'classification__C': 100, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 17.547s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1000, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5322215025906736 Best GS Acc: 0.5538186786793513 Best Params: {'classification__C': 1000, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 18.573s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced',\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5378339465685491 Best GS Acc: 0.541312122367377 Best Params: {'classification__C': 0.1, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 16.831s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5107916632342038 Best GS Acc: 0.5493935929149606 Best Params: {'classification__C': 1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "Average f1 macro score:  0.5391183927041431\n",
      "\n",
      "Trait to predict:  extraversion \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3023685d00f940d3af6555fdd5871d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 13.994s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=10, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5330084696600534 Best GS Acc: 0.5857819135346445 Best Params: {'classification__C': 10, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 14.023s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5277189265536723 Best GS Acc: 0.5793512070883364 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 15.069s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced',\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5887714288508366 Best GS Acc: 0.5525977426654849 Best Params: {'classification__C': 0.1, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 14.631s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=10, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5876284646527561 Best GS Acc: 0.5736718507144205 Best Params: {'classification__C': 10, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 14.052s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5471615508099431 Best GS Acc: 0.5570782420232228 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "Average f1 macro score:  0.5568577681054523\n",
      "\n",
      "Trait to predict:  agreeableness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0936df01f582488787aa1037c45bade2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 13.531s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.506809620399884 Best GS Acc: 0.5309079454311204 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 13.796s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5499534445669275 Best GS Acc: 0.4996493666516967 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 13.298s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5350137982807659 Best GS Acc: 0.5262866484162045 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 14.261s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5042471042471042 Best GS Acc: 0.5372605293833789 Best Params: {'classification__C': 0.1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 14.518s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5229334289960539 Best GS Acc: 0.5348812076285981 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "Average f1 macro score:  0.5237914792981471\n",
      "\n",
      "Trait to predict:  neuroticism \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eb939c19755482c81b545fcfcf2ab89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 14.109s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.518600497048773 Best GS Acc: 0.5399961669056991 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 15.440s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5605941459152469 Best GS Acc: 0.5450187344340952 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 13.967s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced',\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5388289197794517 Best GS Acc: 0.5663034763333817 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 15.467s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=10, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5631464344039194 Best GS Acc: 0.5379382739249567 Best Params: {'classification__C': 10, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 14.620s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5599105449948951 Best GS Acc: 0.5718295270310927 Best Params: {'classification__C': 0.1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "Average f1 macro score:  0.5482161084284571\n"
     ]
    }
   ],
   "source": [
    "print(\"LR with char ngrams\")\n",
    "classify_cv(log_charngrams_df, 'binary', small_clf_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR with wordlists\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f884b3e4fcee405f909ab333bbbaac5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:  log \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0551b0865a564f35ad52a7e04c72cb65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trait to predict:  openness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ada88061cbfb4a71bab6a489d2355ae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 10.623s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=100, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5544750158127767 Best GS Acc: 0.5200156816215756 Best Params: {'classification__C': 100, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 9.867s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=100, class_weight='balanced',\n",
      "                                    max_iter=200))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5406995230524643 Best GS Acc: 0.5421995207684253 Best Params: {'classification__C': 100, 'classification__max_iter': 200, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 6.488s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.4997170850829387 Best GS Acc: 0.5563763681341308 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 10.059s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    solver='saga'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5348533211734305 Best GS Acc: 0.5276189045356701 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 5.906s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5242836255855821 Best GS Acc: 0.5488582778412391 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "Average f1 macro score:  0.5308057141414384\n",
      "\n",
      "Trait to predict:  conscientiousness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f08184b2dbe4470fa41f305f1b5afe94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 9.075s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced',\n",
      "                                    solver='saga'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5211919802800314 Best GS Acc: 0.553949653153396 Best Params: {'classification__C': 0.1, 'classification__max_iter': 100, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 7.038s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced',\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5475231574708015 Best GS Acc: 0.5614525010448131 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 7.507s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=100, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5669150221506242 Best GS Acc: 0.5499391136610392 Best Params: {'classification__C': 100, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 7.803s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=100, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.564874121749568 Best GS Acc: 0.5541187462510713 Best Params: {'classification__C': 100, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 12.374s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1000, class_weight='balanced',\n",
      "                                    max_iter=1000))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.540205969993204 Best GS Acc: 0.5355677165457141 Best Params: {'classification__C': 1000, 'classification__max_iter': 1000, 'classification__solver': 'lbfgs'}\n",
      "Average f1 macro score:  0.5481420503288458\n",
      "\n",
      "Trait to predict:  extraversion \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de27e4d5f9164a64b0cd4fae048cada7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 5.002s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5498602050326189 Best GS Acc: 0.5557718815101651 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 5.457s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced',\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5692975532754538 Best GS Acc: 0.5593360207434144 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 4.753s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5477103718199609 Best GS Acc: 0.558764265006598 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 4.422s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.6235045742434905 Best GS Acc: 0.5627658778633382 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 4.450s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5505918289423445 Best GS Acc: 0.5808036342778327 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "Average f1 macro score:  0.5681929066627738\n",
      "\n",
      "Trait to predict:  agreeableness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "632b91277d3748cdb009c2d1871782a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 7.168s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=10000, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5043339015445012 Best GS Acc: 0.549911210175348 Best Params: {'classification__C': 10000, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 11.666s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=10000, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5610816326530612 Best GS Acc: 0.5097067778384801 Best Params: {'classification__C': 10000, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 8.382s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=10, class_weight='balanced',\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5374827502232324 Best GS Acc: 0.5225389054650346 Best Params: {'classification__C': 10, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 6.938s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced',\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5309760374050263 Best GS Acc: 0.525680801047986 Best Params: {'classification__C': 0.1, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 4.718s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced',\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.4710112359550562 Best GS Acc: 0.531533390067257 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "Average f1 macro score:  0.5209771115561754\n",
      "\n",
      "Trait to predict:  neuroticism \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb9dbafdd17b4749afe751a545af82e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 5.649s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5620061933840766 Best GS Acc: 0.5691438212239133 Best Params: {'classification__C': 0.1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 10.947s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.46695864124998787 Best GS Acc: 0.5738772984684515 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 9.680s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced',\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5506649039583171 Best GS Acc: 0.5562562802560127 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 9.855s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5319426082899137 Best GS Acc: 0.541118152627462 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 5.761s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1000, class_weight='balanced',\n",
      "                                    max_iter=200))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.6230529595015576 Best GS Acc: 0.5675381844749867 Best Params: {'classification__C': 1000, 'classification__max_iter': 200, 'classification__solver': 'lbfgs'}\n",
      "Average f1 macro score:  0.5469250612767705\n"
     ]
    }
   ],
   "source": [
    "print(\"LR with wordlists\")\n",
    "classify_cv(log_wordlists_df, 'binary', small_clf_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR with posts features\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80477c280cae4ba6a346c751d737bc74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:  log \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10b28fb0a9e145b4bf4b04c93db42c8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trait to predict:  openness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4173fae0acc4d78a85beefc8f4da43b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 201.786s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=10, class_weight='balanced', max_iter=200,\n",
      "                                    solver='saga'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5816495676716993 Best GS Acc: 0.49481883873314636 Best Params: {'classification__C': 10, 'classification__max_iter': 200, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 205.263s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=100, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.48545732639951056 Best GS Acc: 0.5032966597973922 Best Params: {'classification__C': 100, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 204.230s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=100, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.511939182452642 Best GS Acc: 0.4991284869946333 Best Params: {'classification__C': 100, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 206.173s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=100, class_weight='balanced',\n",
      "                                    solver='saga'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.507587064676617 Best GS Acc: 0.5161943928438619 Best Params: {'classification__C': 100, 'classification__max_iter': 100, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 202.209s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=10, class_weight='balanced',\n",
      "                                    solver='saga'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5359581594875713 Best GS Acc: 0.5177552889040429 Best Params: {'classification__C': 10, 'classification__max_iter': 100, 'classification__solver': 'saga'}\n",
      "Average f1 macro score:  0.5245182601376082\n",
      "\n",
      "Trait to predict:  conscientiousness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74838a9b5ec94bbda2cd4e0afa20d189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 205.446s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=100, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5974370995468041 Best GS Acc: 0.5433195770992472 Best Params: {'classification__C': 100, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 204.448s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=10, class_weight='balanced',\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5254927385892116 Best GS Acc: 0.5417140838205505 Best Params: {'classification__C': 10, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 203.902s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=100, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.613826693296892 Best GS Acc: 0.5365918605202072 Best Params: {'classification__C': 100, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 205.512s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced', max_iter=200,\n",
      "                                    solver='saga'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.556585292344786 Best GS Acc: 0.5509414497851317 Best Params: {'classification__C': 1, 'classification__max_iter': 200, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 205.562s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced', max_iter=200,\n",
      "                                    solver='saga'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5735463925205796 Best GS Acc: 0.5511455963075073 Best Params: {'classification__C': 1, 'classification__max_iter': 200, 'classification__solver': 'saga'}\n",
      "Average f1 macro score:  0.5733776432596547\n",
      "\n",
      "Trait to predict:  extraversion \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd2758a8f98418c9c4a98d3a92c41de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 205.089s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=100, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5162871600253004 Best GS Acc: 0.48065932522227833 Best Params: {'classification__C': 100, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 203.289s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.44918550379793165 Best GS Acc: 0.5125829084647847 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 206.744s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=10000, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.4509091761177243 Best GS Acc: 0.47577341659682426 Best Params: {'classification__C': 10000, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 210.240s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.49065642528677544 Best GS Acc: 0.468767887964462 Best Params: {'classification__C': 0.1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 208.064s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.43370263213605253 Best GS Acc: 0.49844753397851127 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "Average f1 macro score:  0.4681481794727569\n",
      "\n",
      "Trait to predict:  agreeableness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "112d13d5f0db4f4ab583b2a62c8cb0f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 205.228s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=10, class_weight='balanced',\n",
      "                                    solver='saga'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.48299518318493656 Best GS Acc: 0.48179744230502475 Best Params: {'classification__C': 10, 'classification__max_iter': 100, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 209.700s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.498321083172147 Best GS Acc: 0.48353051515668116 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 205.584s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1000, class_weight='balanced'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.49123431233018505 Best GS Acc: 0.49892097705300953 Best Params: {'classification__C': 1000, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 207.038s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=10, class_weight='balanced',\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.48970883534136544 Best GS Acc: 0.5102441318849491 Best Params: {'classification__C': 10, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 205.167s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=10000, class_weight='balanced',\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.552469570938484 Best GS Acc: 0.49504458271888974 Best Params: {'classification__C': 10000, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "Average f1 macro score:  0.5029457969934236\n",
      "\n",
      "Trait to predict:  neuroticism \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dcd7d217e2149d9b27715fac8f4b361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 208.265s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1000, class_weight='balanced',\n",
      "                                    max_iter=500))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.4374563242487771 Best GS Acc: 0.48645742518671853 Best Params: {'classification__C': 1000, 'classification__max_iter': 500, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 202.440s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced', max_iter=500,\n",
      "                                    solver='saga'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.44527649769585254 Best GS Acc: 0.4961321598427654 Best Params: {'classification__C': 1, 'classification__max_iter': 500, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 205.136s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced',\n",
      "                                    solver='saga'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.48602215682880384 Best GS Acc: 0.47771107426637754 Best Params: {'classification__C': 1, 'classification__max_iter': 100, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 203.092s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.4897064486507302 Best GS Acc: 0.4620835118696583 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 206.449s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=10, class_weight='balanced',\n",
      "                                    max_iter=1000, solver='saga'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.4721308637701229 Best GS Acc: 0.49037936109891406 Best Params: {'classification__C': 10, 'classification__max_iter': 1000, 'classification__solver': 'saga'}\n",
      "Average f1 macro score:  0.46611845823885734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "print(\"LR with posts features\")\n",
    "classify_cv(log_posts_df, 'binary', small_clf_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR with posts features but without subreddit\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd955056874a494aa167ac1a2ff27762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:  log \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6832f530320045d8a5b86c1454f1d710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trait to predict:  openness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58d0ba1b25e04c999f5b3695e351461b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 14.048s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=100, class_weight='balanced',\n",
      "                                    solver='saga'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5123485554520038 Best GS Acc: 0.4813968813287709 Best Params: {'classification__C': 100, 'classification__max_iter': 100, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 10.421s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced', max_iter=500,\n",
      "                                    solver='saga'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.46627449073849 Best GS Acc: 0.4805581585221609 Best Params: {'classification__C': 1, 'classification__max_iter': 500, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 10.407s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=10, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.48849591916051305 Best GS Acc: 0.4858618386501764 Best Params: {'classification__C': 10, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 10.059s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.468881252386407 Best GS Acc: 0.48679145598309903 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 9.932s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced',\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.4653116281921579 Best GS Acc: 0.5044723494011946 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "Average f1 macro score:  0.4802623691859143\n",
      "\n",
      "Trait to predict:  conscientiousness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2de5ad5559d44fd1861552ec53aad22f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 10.513s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=100, class_weight='balanced',\n",
      "                                    max_iter=1000, solver='saga'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.47995797011207975 Best GS Acc: 0.47444273862745057 Best Params: {'classification__C': 100, 'classification__max_iter': 1000, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 9.822s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=100, class_weight='balanced',\n",
      "                                    max_iter=200, solver='saga'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5142174432497013 Best GS Acc: 0.4882318605486578 Best Params: {'classification__C': 100, 'classification__max_iter': 200, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 9.991s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    max_iter=500, solver='saga'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.46429512516469035 Best GS Acc: 0.49016279440350996 Best Params: {'classification__C': 0.001, 'classification__max_iter': 500, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 10.248s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.4697888333910291 Best GS Acc: 0.5118187165076227 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 10.557s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=100, class_weight='balanced',\n",
      "                                    max_iter=1000, solver='saga'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.47630338957288343 Best GS Acc: 0.5061951776528597 Best Params: {'classification__C': 100, 'classification__max_iter': 1000, 'classification__solver': 'saga'}\n",
      "Average f1 macro score:  0.4809125522980768\n",
      "\n",
      "Trait to predict:  extraversion \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3030f5b0b14248289a9f6a4765d1c6c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 10.246s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1000, class_weight='balanced',\n",
      "                                    max_iter=200, solver='saga'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.4999803435939773 Best GS Acc: 0.5354450157062127 Best Params: {'classification__C': 1000, 'classification__max_iter': 200, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 9.513s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5295767539815794 Best GS Acc: 0.5329923509688607 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 9.682s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1000, class_weight='balanced',\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.49459694690828016 Best GS Acc: 0.5272756375999531 Best Params: {'classification__C': 1000, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 9.619s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    max_iter=200, solver='saga'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.4835554862174206 Best GS Acc: 0.5181844460502205 Best Params: {'classification__C': 0.001, 'classification__max_iter': 200, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 10.992s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=100, class_weight='balanced',\n",
      "                                    max_iter=200))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5373198285936891 Best GS Acc: 0.5111347981923583 Best Params: {'classification__C': 100, 'classification__max_iter': 200, 'classification__solver': 'lbfgs'}\n",
      "Average f1 macro score:  0.5090058718589893\n",
      "\n",
      "Trait to predict:  agreeableness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee03cee856a340cfb353cca1c936acbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 9.818s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced',\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.4942815721649484 Best GS Acc: 0.47300672512892944 Best Params: {'classification__C': 1, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 10.555s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.4531625781625781 Best GS Acc: 0.4808116402616188 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 10.015s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=10, class_weight='balanced'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.4715368137099334 Best GS Acc: 0.476733906250295 Best Params: {'classification__C': 10, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 9.938s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced',\n",
      "                                    solver='saga'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5121580547112462 Best GS Acc: 0.4645829943295084 Best Params: {'classification__C': 1, 'classification__max_iter': 100, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 10.212s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced',\n",
      "                                    solver='saga'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.44154825474401904 Best GS Acc: 0.48391881613773746 Best Params: {'classification__C': 0.1, 'classification__max_iter': 100, 'classification__solver': 'saga'}\n",
      "Average f1 macro score:  0.4745374546985451\n",
      "\n",
      "Trait to predict:  neuroticism \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7946d6b238c340f0b05be2976fbf762c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 10.085s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced', max_iter=500,\n",
      "                                    solver='saga'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.47510971786833855 Best GS Acc: 0.47750225393713536 Best Params: {'classification__C': 1, 'classification__max_iter': 500, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 10.503s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=10000, class_weight='balanced',\n",
      "                                    max_iter=500, solver='saga'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.4734998107475955 Best GS Acc: 0.500111064486752 Best Params: {'classification__C': 10000, 'classification__max_iter': 500, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 10.087s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced',\n",
      "                                    solver='saga'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.4826200093211124 Best GS Acc: 0.4969158133929102 Best Params: {'classification__C': 1, 'classification__max_iter': 100, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 9.766s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    max_iter=500, solver='saga'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.4637529137529137 Best GS Acc: 0.5280253254800652 Best Params: {'classification__C': 0.001, 'classification__max_iter': 500, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 10.355s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=10, class_weight='balanced',\n",
      "                                    max_iter=1000, solver='saga'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5201327949056458 Best GS Acc: 0.48632133479752004 Best Params: {'classification__C': 10, 'classification__max_iter': 1000, 'classification__solver': 'saga'}\n",
      "Average f1 macro score:  0.48302304931912127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "print(\"LR with posts features but without subreddit\")\n",
    "classify_cv(log_postswithoutsubreddits_df, 'binary', small_clf_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif, SequentialFeatureSelector\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def get_classifier(classifier):\n",
    "    if classifier == 'log':\n",
    "        return LogisticRegression(class_weight='balanced')\n",
    "    \n",
    "def get_featureselection(fs, classifier):\n",
    "    if fs == 'anova':\n",
    "        return SelectKBest(f_classif, k=30)\n",
    "    if fs == 'mutual':\n",
    "        return mutual_info_classif()\n",
    "    if fs == 'sequential':\n",
    "        return SequentialFeatureSelector(get_classifier(classifier), n_features_to_select=30, n_jobs=-1)\n",
    "\n",
    "    \n",
    "def new_pipe(classifier, fs, dim):\n",
    "    if dim:\n",
    "        pipeline = Pipeline([\n",
    "              ('variance_threshold', VarianceThreshold()),\n",
    "              ('scaler', StandardScaler()),\n",
    "              ('pca', PCA(n_components=100)),\n",
    "              ('feature_selection',  get_featureselection(fs, classifier)),\n",
    "              ('classification', get_classifier(classifier))\n",
    "            ])\n",
    "    else:\n",
    "        pipeline = Pipeline([\n",
    "              ('variance_threshold', VarianceThreshold()),\n",
    "              ('scaler', StandardScaler()),\n",
    "              ('feature_selection',  get_featureselection(fs, classifier)),\n",
    "              ('classification', get_classifier(classifier))\n",
    "            ])\n",
    "    return pipeline\n",
    "\n",
    "def classify(df, classifier, classes, fs, dim):\n",
    "    for trait_name in traits:\n",
    "        print(\"Trait to predict: \", trait_name)\n",
    "        x,y = trait(df, classes,trait_name)\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=0)\n",
    "        clf = new_pipe(classifier, fs, dim)\n",
    "        clf.fit(x_train, y_train)\n",
    "        y_pred=clf.predict(x_test)\n",
    "        report = scores(y_test, y_pred, \"report\")\n",
    "        print(report)\n",
    "\n",
    "classify(log_charngrams_df, 'log', classes='binary', fs='mutual', dim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram of true traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_imbalance(df, traits):\n",
    "    length = len(df)\n",
    "    o = df['trait', 'big5_o']\n",
    "    c = df['trait', 'big5_c']\n",
    "    e = df['trait', 'big5_e']\n",
    "    a = df['trait', 'big5_a']\n",
    "    n = df['trait', 'big5_n']\n",
    "    binarylst = [o, c, e, a, n]\n",
    "    o5 = df['trait', 'big5_o_multi']\n",
    "    c5 = df['trait', 'big5_c_multi']\n",
    "    e5 = df['trait', 'big5_e_multi']\n",
    "    a5 = df['trait', 'big5_a_multi']\n",
    "    n5 = df['trait', 'big5_n_multi']\n",
    "    multilst = [o5, c5, e5, a5, n5]\n",
    "    \n",
    "    result = []\n",
    "    for trait in binarylst: \n",
    "        result.append(np.bincount(trait) / length)\n",
    "    result5 = []\n",
    "    for trait in multilst:\n",
    "        result5.append(np.bincount(trait) / len(trait))\n",
    "    \n",
    "    print(\"Distribution of the true trait values in the classes (in %):\\n\")\n",
    "    for i in range(len(traits)):\n",
    "        print(traits[i], \"\\n\\tBinary: \", result[i], \"\\n\\t5 classes: \", result5[i], \"\\n\")\n",
    "    \n",
    "#     result =np.bincount(o) / len(o)\n",
    "#     result5 =np.bincount(o5) / len(o)\n",
    "#     print(\"Openness\\n\\tBinary: \", result, \"\\n\\t5 classes: \", result5)\n",
    "\n",
    "    \n",
    "check_imbalance(df, traits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true histogram plots\n",
    "all_hist_true(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%javascript\n",
    "# IPython.OutputArea.auto_scroll_threshold = 1000;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check results on train set with k nearest neighbor algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify(df, 'knn', 'binary', trainscores=True, plotting=False, weighted=False, detailed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify(df, 'knn', 'multi', trainscores=True, plotting=False, weighted=False, detailed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify(df, 'log', 'binary', plotting=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify(df, 'log', 'binary', plotting=True, weighted=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression: multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify(df, 'multilog', 'multi', plotting=True, weighted=True, detailed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify(df, 'mlp', 'binary', plotting=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify(df, 'mlp', 'multi', plotting=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify(df, 'svm', 'binary', plotting=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify(df, 'svm', 'multi', plotting=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify(df, 'svmlinear', 'linear', plotting=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify(df, 'linear', 'linear', plotting=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results without predictor subreddit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  binary log (without subreddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify(smalldf, 'log', 'binary', plotting=True, weighted=True, detailed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multi log (without subreddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify(smalldf, 'multilog', 'multi', plotting=True, weighted=True, detailed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP (without subreddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify(smalldf, 'mlp', 'binary', plotting=True, weighted=False, detailed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression (without subreddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify(smalldf, 'lin', 'linear', plotting=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
