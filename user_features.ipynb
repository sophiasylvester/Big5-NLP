{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "random.seed(32)\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 422 entries, 0 to 421\n",
      "Data columns (total 26 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   index                  422 non-null    int64  \n",
      " 1   author                 422 non-null    object \n",
      " 2   complete_body          422 non-null    object \n",
      " 3   doc_body               422 non-null    object \n",
      " 4   probody                422 non-null    object \n",
      " 5   tokens                 422 non-null    object \n",
      " 6   senttokens             422 non-null    object \n",
      " 7   agreeableness          422 non-null    float64\n",
      " 8   openness               422 non-null    float64\n",
      " 9   conscientiousness      422 non-null    float64\n",
      " 10  extraversion           422 non-null    float64\n",
      " 11  neuroticism            422 non-null    float64\n",
      " 12  agree                  422 non-null    int64  \n",
      " 13  openn                  422 non-null    int64  \n",
      " 14  consc                  422 non-null    int64  \n",
      " 15  extra                  422 non-null    int64  \n",
      " 16  neuro                  422 non-null    int64  \n",
      " 17  all_utc                422 non-null    object \n",
      " 18  mean_controversiality  422 non-null    float64\n",
      " 19  mean_gilded            422 non-null    float64\n",
      " 20  num_subreddits         422 non-null    int64  \n",
      " 21  subreddit_dist         422 non-null    object \n",
      " 22  weekday_dist           422 non-null    object \n",
      " 23  month_dist             422 non-null    object \n",
      " 24  year_dist              422 non-null    object \n",
      " 25  all_lang               422 non-null    object \n",
      "dtypes: float64(7), int64(7), object(12)\n",
      "memory usage: 85.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# authors = pd.read_csv('/home/sophia/ma_py/author_profiles.csv')\n",
    "\n",
    "df = pd.read_pickle(\"preprocessed_author.pkl\")\n",
    "# df = pre_df.set_index(['index', 'author'])\n",
    "# df.head(10)\n",
    "df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>author</th>\n",
       "      <th>complete_body</th>\n",
       "      <th>doc_body</th>\n",
       "      <th>probody</th>\n",
       "      <th>tokens</th>\n",
       "      <th>senttokens</th>\n",
       "      <th>agreeableness</th>\n",
       "      <th>openness</th>\n",
       "      <th>conscientiousness</th>\n",
       "      <th>...</th>\n",
       "      <th>neuro</th>\n",
       "      <th>all_utc</th>\n",
       "      <th>mean_controversiality</th>\n",
       "      <th>mean_gilded</th>\n",
       "      <th>num_subreddits</th>\n",
       "      <th>subreddit_dist</th>\n",
       "      <th>weekday_dist</th>\n",
       "      <th>month_dist</th>\n",
       "      <th>year_dist</th>\n",
       "      <th>all_lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>424</td>\n",
       "      <td>xanthraxoid</td>\n",
       "      <td>I'd really like this video to include some inf...</td>\n",
       "      <td>[I'd really like this video to include some in...</td>\n",
       "      <td>[would really like video include information c...</td>\n",
       "      <td>[[would, really, like, video, include, informa...</td>\n",
       "      <td>[[I'd really like this video to include some i...</td>\n",
       "      <td>86.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1469892161, 1486826547, 1498046590, 1550346594]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 2, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 1, 2, 0, 1]</td>\n",
       "      <td>0 0 3 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>425</td>\n",
       "      <td>xenomouse</td>\n",
       "      <td>You're a guy, aren't you? I can definitely see...</td>\n",
       "      <td>[You're a guy, aren't you? I can definitely se...</td>\n",
       "      <td>[guy not definitely see would make boy scene f...</td>\n",
       "      <td>[[guy, not, definitely, see, would, make, boy,...</td>\n",
       "      <td>[[You're a guy, aren't you?, I can definitely ...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1506710219, 1502740906, 1517847908, 1506874589]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0]</td>\n",
       "      <td>[0, 0, 3, 1, 0]</td>\n",
       "      <td>0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>426</td>\n",
       "      <td>xeroctr3</td>\n",
       "      <td>man even the thought of it makes me depressed....</td>\n",
       "      <td>[man even the thought of it makes me depressed...</td>\n",
       "      <td>[man even thought makes depressed loving someo...</td>\n",
       "      <td>[[man, even, thought, makes, depressed, loving...</td>\n",
       "      <td>[[man even the thought of it makes me depresse...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1521414051]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>427</td>\n",
       "      <td>xzack18</td>\n",
       "      <td>Not all of us are out to kill</td>\n",
       "      <td>[Not all of us are out to kill]</td>\n",
       "      <td>[not us kill]</td>\n",
       "      <td>[[not, us, kill]]</td>\n",
       "      <td>[[Not all of us are out to kill]]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1533749569]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>428</td>\n",
       "      <td>zugzwang_03</td>\n",
       "      <td>Institutions should accommodate religious or s...</td>\n",
       "      <td>[Institutions should accommodate religious or ...</td>\n",
       "      <td>[institutions accommodate religious serious me...</td>\n",
       "      <td>[[institutions, accommodate, religious, seriou...</td>\n",
       "      <td>[[Institutions should accommodate religious or...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1514216199, 1459000262, 1500701643, 151759545...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1]</td>\n",
       "      <td>[0, 3, 2, 1, 0]</td>\n",
       "      <td>0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index       author                                      complete_body  \\\n",
       "417    424  xanthraxoid  I'd really like this video to include some inf...   \n",
       "418    425    xenomouse  You're a guy, aren't you? I can definitely see...   \n",
       "419    426     xeroctr3  man even the thought of it makes me depressed....   \n",
       "420    427      xzack18                      Not all of us are out to kill   \n",
       "421    428  zugzwang_03  Institutions should accommodate religious or s...   \n",
       "\n",
       "                                              doc_body  \\\n",
       "417  [I'd really like this video to include some in...   \n",
       "418  [You're a guy, aren't you? I can definitely se...   \n",
       "419  [man even the thought of it makes me depressed...   \n",
       "420                    [Not all of us are out to kill]   \n",
       "421  [Institutions should accommodate religious or ...   \n",
       "\n",
       "                                               probody  \\\n",
       "417  [would really like video include information c...   \n",
       "418  [guy not definitely see would make boy scene f...   \n",
       "419  [man even thought makes depressed loving someo...   \n",
       "420                                      [not us kill]   \n",
       "421  [institutions accommodate religious serious me...   \n",
       "\n",
       "                                                tokens  \\\n",
       "417  [[would, really, like, video, include, informa...   \n",
       "418  [[guy, not, definitely, see, would, make, boy,...   \n",
       "419  [[man, even, thought, makes, depressed, loving...   \n",
       "420                                  [[not, us, kill]]   \n",
       "421  [[institutions, accommodate, religious, seriou...   \n",
       "\n",
       "                                            senttokens  agreeableness  \\\n",
       "417  [[I'd really like this video to include some i...           86.0   \n",
       "418  [[You're a guy, aren't you?, I can definitely ...           26.0   \n",
       "419  [[man even the thought of it makes me depresse...            3.0   \n",
       "420                  [[Not all of us are out to kill]]            4.0   \n",
       "421  [[Institutions should accommodate religious or...           10.0   \n",
       "\n",
       "     openness  conscientiousness  ...  neuro  \\\n",
       "417      45.0                8.0  ...      1   \n",
       "418      93.0               49.0  ...      0   \n",
       "419      75.0               27.0  ...      1   \n",
       "420      19.0               11.0  ...      0   \n",
       "421      41.0               86.0  ...      0   \n",
       "\n",
       "                                               all_utc  mean_controversiality  \\\n",
       "417   [1469892161, 1486826547, 1498046590, 1550346594]                    0.0   \n",
       "418   [1506710219, 1502740906, 1517847908, 1506874589]                    0.0   \n",
       "419                                       [1521414051]                    0.0   \n",
       "420                                       [1533749569]                    0.0   \n",
       "421  [1514216199, 1459000262, 1500701643, 151759545...                    0.0   \n",
       "\n",
       "     mean_gilded  num_subreddits  \\\n",
       "417          0.0               4   \n",
       "418          0.0               2   \n",
       "419          0.0               1   \n",
       "420          0.0               1   \n",
       "421          0.0               5   \n",
       "\n",
       "                                        subreddit_dist           weekday_dist  \\\n",
       "417  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [0, 0, 0, 0, 0, 0, 0]   \n",
       "418  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [0, 0, 0, 0, 0, 0, 0]   \n",
       "419  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [0, 0, 0, 0, 0, 0, 0]   \n",
       "420  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [0, 0, 0, 0, 0, 0, 0]   \n",
       "421  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                               month_dist        year_dist     all_lang  \n",
       "417  [0, 2, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0]  [0, 1, 2, 0, 1]      0 0 3 0  \n",
       "418  [0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0]  [0, 0, 3, 1, 0]      0 0 0 0  \n",
       "419  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  [0, 0, 0, 1, 0]            0  \n",
       "420  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]  [0, 0, 0, 1, 0]            0  \n",
       "421  [0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1]  [0, 3, 2, 1, 0]  0 0 0 0 0 0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing for LDA...\n",
      "Start LDA...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd3f757ef70040a09bd239b7971740d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0                                                    [0]\n",
       "1                                                    [0]\n",
       "2      [(0, 0.051*\",\"), (1, 0.035*\"racism\"), (2, 0.03...\n",
       "3      [(0, 0.210*\"sorry\"), (1, 0.143*\"nothing\"), (2,...\n",
       "4      [(0, 0.071*\"day\"), (1, 0.115*\"get\"), (2, 0.125...\n",
       "                             ...                        \n",
       "417    [(0, 0.057*\"not\"), (1, 0.039*\"air\"), (2, 0.012...\n",
       "418    [(0, 0.041*\"would\"), (1, 0.047*\"not\"), (2, 0.0...\n",
       "419                                                  [0]\n",
       "420                                                  [0]\n",
       "421    [(0, 0.025*\"someone\"), (1, 0.021*\"first\"), (2,...\n",
       "Name: ldathree, Length: 422, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://rstudio-pubs-static.s3.amazonaws.com/79360_850b2a69980c4488b1db95987a24867a.html\n",
    "\n",
    "# problem: probody does not have punctuation anymore\n",
    "# multicore instead of lda model seems to be slower????\n",
    "\n",
    "def apply_lda(df, number, name):\n",
    "    print(\"Preprocessing for LDA...\")\n",
    "    lst = []\n",
    "    # filter out stopwords including negations for topic modeling\n",
    "#     stopwordList = stopwords.words('english')\n",
    "#     df['ldatokens'] = df['probody'].apply(lambda x: ' '.join([x for x in x.split() if (x not in stopwordList)]))\n",
    "#     df['ldatokens'] = df['ldatokens'].apply(lambda x: (word_tokenize(x)))\n",
    "#     print(df.iloc[421]['ldatokens'])\n",
    "    print(\"Start LDA...\")\n",
    "    for row in tqdm(df['tokens']):\n",
    "        if len(row) < 2:\n",
    "            lst.append([0])\n",
    "        else:\n",
    "            dictionary = corpora.Dictionary(row)\n",
    "            corpus = [dictionary.doc2bow(text) for text in row]\n",
    "            ldamodel = gensim.models.LdaMulticore(corpus, num_topics=number, id2word = dictionary, passes=20, workers=15)\n",
    "            result = ldamodel.print_topics(num_topics=number, num_words=1)\n",
    "            lst.append(result)\n",
    "    df[name] = lst\n",
    "    return df\n",
    "\n",
    "# print(df.iloc[220]['tokens'])\n",
    "# print(len(df.iloc[220]['tokens']))\n",
    "df = apply_lda(df, 3, \"ldathree\")\n",
    "df['ldathree']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_userfeatures(df):\n",
    "    df = apply_lda(df, 50, \"ldafifty\")\n",
    "    df = apply_lda(df, 100, \"ldahundred\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing for LDA...\n",
      "Start LDA...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a8b9fd16821489aba6939173be86be3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing for LDA...\n",
      "Start LDA...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf0868fc5a104f99affe98a6aa2c53fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_feat_df = extract_userfeatures(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_feat_df.to_pickle(\"user_feat_df.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
