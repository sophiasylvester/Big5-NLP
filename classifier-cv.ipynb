{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from time import time\n",
    "import random\n",
    "random.seed(32)\n",
    "import sklearn\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, VarianceThreshold, mutual_info_classif, RFE, SequentialFeatureSelector\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import f1_score, classification_report, precision_recall_curve, roc_auc_score, plot_roc_curve, confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1606 entries, -Areopagan- to zyzee\n",
      "Columns: 18201 entries, ('text', 'body') to ('lda', 'ldahundred')\n",
      "dtypes: float64(2091), int64(16103), object(7)\n",
      "memory usage: 223.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle(\"allfeat_df_allcomments.pkl\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictors = df.columns\n",
    "# i = 0\n",
    "# predictorsfile=open('featurelist.txt','w')\n",
    "# # predictorsfile.writelines(predictors)\n",
    "# for index in range(len(predictors)):\n",
    "#     predictorsfile.write(str(i))\n",
    "#     predictorsfile.write(predictors[index][0])\n",
    "#     predictorsfile.write(\" \")\n",
    "#     predictorsfile.write(predictors[index][1])\n",
    "#     predictorsfile.write('\\n')\n",
    "#     i+=1\n",
    "# predictorsfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.dropna(axis=0, how='all')\n",
    "# df = df.dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'post', 'x_feat', 'lda', 'ngram', 'psych', 'empath', 'trait', 'data', 'subreddit', 'time', 'text', 'lin_feat'}\n"
     ]
    }
   ],
   "source": [
    "# level 0 column names\n",
    "predictors = df.columns\n",
    "featurelst = []\n",
    "for i in range(len(predictors)):\n",
    "    featurelst.append(predictors[i][0])\n",
    "featureset = set(featurelst)\n",
    "print(featureset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create smaller dfs\n",
    "log_wordngrams_df = df[['trait', 'ngram']]\n",
    "log_charngrams_df = df[['trait', 'ngram']]\n",
    "log_wordlists_df =  df[['trait', 'x_feat', 'lin_feat', 'psych', 'empath']]\n",
    "log_posts_df = df[['trait', 'post', 'time', 'subreddit', 'lda']]\n",
    "log_postswithoutsubreddits_df = df[['trait', 'post', 'time', 'lda']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate word ngrams\n",
    "droplst = []\n",
    "index = 17124\n",
    "for i in range(1000):\n",
    "    index = index+1\n",
    "    droplst.append(predictors[index][1])\n",
    "\n",
    "log_wordngrams_df = log_wordngrams_df.drop(droplst, axis=1, level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate char ngrams\n",
    "worddroplst = []\n",
    "wordindex = 16125\n",
    "for i in range(1000):\n",
    "    wordindex = wordindex+1\n",
    "    worddroplst.append(predictors[wordindex][1])\n",
    "\n",
    "log_charngrams_df = log_charngrams_df.drop(worddroplst, axis=1, level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_hist_true(df):\n",
    "    plt.figure(figsize = (16, 16))\n",
    "#     plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\n",
    "    plt.subplot(3, 2, 1)\n",
    "    plt.hist(df['trait', 'openness'], bins = 20)\n",
    "    plt.title('Agreeableness')\n",
    "    \n",
    "    plt.subplot(3, 2, 2)\n",
    "    plt.hist(df['trait', 'conscientiousness'], bins = 20)\n",
    "    plt.title('Openness')\n",
    "    \n",
    "    plt.subplot(3, 2, 3)\n",
    "    plt.hist(df['trait', 'extraversion'], bins = 20)\n",
    "    plt.title('Conscientiousness')\n",
    "    \n",
    "    plt.subplot(3, 2, 4)\n",
    "    plt.hist(df['trait', 'agreeableness'], bins = 20)\n",
    "    plt.title('Extraversion')\n",
    "    \n",
    "    plt.subplot(3, 2, 5)\n",
    "    plt.hist(df['trait', 'neuroticism'], bins = 20)\n",
    "    plt.title('Neuroticism')\n",
    "    \n",
    "    plt.suptitle(\"Histograms of the true trait values\")\n",
    "    plt.subplots_adjust(left=0.1, \n",
    "                    bottom=0.1,  \n",
    "                    right=0.9,  \n",
    "                    top=0.9,  \n",
    "                    wspace=0.4,  \n",
    "                    hspace=0.4) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset in features and target variable depending on which trait to focus on\n",
    "def trait(df, classes, trait_name):\n",
    "    featuredf = df.drop(['data', 'trait', 'text'], axis=1, level=0)\n",
    "    feature_cols = featuredf.columns.tolist()\n",
    "    \n",
    "    x = df[feature_cols] \n",
    "    \n",
    "    if classes=='binary':\n",
    "    \n",
    "        if trait_name == 'agreeableness':\n",
    "            y = df['trait', 'big5_o']\n",
    "        elif trait_name == 'openness':\n",
    "            y = df['trait', 'big5_c']\n",
    "        elif trait_name == 'conscientiousness':\n",
    "            y = df['trait', 'big5_e']\n",
    "        elif trait_name == 'extraversion':\n",
    "            y = df['trait', 'big5_a']\n",
    "        elif trait_name == 'neuroticism':\n",
    "            y = df['trait', 'big5_n']   \n",
    "    elif classes=='multi':\n",
    "        if trait_name == 'agreeableness':\n",
    "            y = df['trait', 'big5_o_multi']\n",
    "        elif trait_name == 'openness':\n",
    "            y = df['trait', 'big5_c_multi']\n",
    "        elif trait_name == 'conscientiousness':\n",
    "            y = df['trait', 'big5_e_multi']\n",
    "        elif trait_name == 'extraversion':\n",
    "            y = df['trait', 'big5_a_multi']\n",
    "        elif trait_name == 'neuroticism':\n",
    "            y = df['trait', 'big5_n_multi'] \n",
    "    elif classes=='linear':\n",
    "        if trait_name == 'agreeableness':\n",
    "            y = df['trait', 'agreeableness']\n",
    "        elif trait_name == 'openness':\n",
    "            y = df['trait', 'openness']\n",
    "        elif trait_name == 'conscientiousness':\n",
    "            y = df['trait', 'conscientiousness']\n",
    "        elif trait_name == 'extraversion':\n",
    "            y = df['trait', 'extraversion']\n",
    "        elif trait_name == 'neuroticism':\n",
    "            y = df['trait', 'neuroticism']  \n",
    "    return x,y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get names of 30 most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get names of the features\n",
    "def get_names(x, pipeline):\n",
    "    features = pipeline.named_steps['feature_selection']\n",
    "    names = x.columns[features.get_support(indices=True)]\n",
    "    return names\n",
    "# names = get_names(logpipe)\n",
    "# print(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pvalues(pipeline, x):\n",
    "#     x_indices = np.arange(x.shape[-1])\n",
    "#     selector = SelectKBest(f_classif, k=30)\n",
    "#     selector.fit(x_train, y_train)\n",
    "#     scores = -np.log10(selector.pvalues_)\n",
    "    features = pipeline.named_steps['feature_selection']\n",
    "    pvalues = features.pvalues_\n",
    "#     pvalues /= pvalues.max()\n",
    "    dfpvalues = pd.DataFrame(features.pvalues_)\n",
    "    dfscores = pd.DataFrame(features.scores_)\n",
    "    dfcolumns = pd.DataFrame(x.columns)\n",
    "    #concat two dataframes for better visualization \n",
    "    featureScores = pd.concat([dfcolumns,dfscores, dfpvalues],axis=1)\n",
    "    featureScores.columns = ['specs','score', 'pvalue']\n",
    "    featureScores.sort_values(by='pvalue')\n",
    "\n",
    "    plt.figure(figsize = (12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(pvalues, bins=20)\n",
    "    plt.title('All p-values')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    smallpvalues = pvalues[pvalues<0.1]\n",
    "    plt.hist(smallpvalues, bins=10)\n",
    "    plt.title('Small p-values')\n",
    "    \n",
    "    plt.suptitle(\"Histograms of the p-values\")\n",
    "    plt.subplots_adjust(left=0.1, \n",
    "                    bottom=0.1,  \n",
    "                    right=0.9,  \n",
    "                    top=0.9,  \n",
    "                    wspace=0.4,  \n",
    "                    hspace=0.4) \n",
    "    plt.show()\n",
    "    \n",
    "    return featureScores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def scores(y_test, y_pred, presentationtype):\n",
    "    \n",
    "    if presentationtype == \"scores\":\n",
    "        accuracy=metrics.accuracy_score(y_test, y_pred)\n",
    "        precision=metrics.precision_score(y_test, y_pred)\n",
    "        recall=metrics.recall_score(y_test, y_pred)\n",
    "        f_one=metrics.f1_score(y_test, y_pred)\n",
    "        return accuracy, precision, recall, f_one\n",
    "    if presentationtype == \"report\":\n",
    "        report = classification_report(y_test, y_pred)\n",
    "        return report\n",
    "\n",
    "\n",
    "def score_plot(logreg, y_test, x_test):\n",
    "    lr_probs = logreg.predict_proba(x_test)\n",
    "    # keep probabilities for the positive outcome only\n",
    "    lr_probs = lr_probs[:, 1]\n",
    "    # predict class values\n",
    "#     yhat = logreg.predict(x_test)\n",
    "    lr_precision, lr_recall, _ = precision_recall_curve(y_test, lr_probs)\n",
    "#     lr_f1, lr_auc = f1_score(y_test, yhat), auc(lr_recall, lr_precision)\n",
    "\n",
    "    # plot the precision-recall curves\n",
    "    no_skill = len(y_test[y_test==1]) / len(y_test)\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "    plt.plot(lr_recall, lr_precision, marker='.', label='Classifier')\n",
    "    # axis labels\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    # show the legend\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return lr_precision, lr_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score plot\n",
    "Smaller values on the x-axis of the plot indicate lower false positives and higher true negatives.\n",
    "\n",
    "\n",
    "Larger values on the y-axis of the plot indicate higher true positives and lower false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and print confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnfmatrix(clf, x_test, y_test, y_pred, plotting, detailed):\n",
    "    cnfpipe_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    if detailed:\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        sumpositive = tp + fn\n",
    "        sumnegative = fp + tn\n",
    "        sumcorrect = tp + tn\n",
    "        sumwrong = fp + fn\n",
    "        sumall = tn+fp+fn+tp\n",
    "        print(\"TN, FP, FN, TP: \", tn, fp, fn, tp, \"\\nSum: \", sumall, \"\\nSum correct predictions: \", \n",
    "              sumcorrect, \"Percent: \", sumcorrect/sumall, \"\\nSum wrong predictions: \", sumwrong, \"\\tPercent: \",\n",
    "              sumwrong/sumall, \"\\nSum actual positives: \", sumpositive, \"\\tPercent: \", sumpositive/sumall,\n",
    "              \"\\nSum actual negatives: \", sumnegative, \"\\tPercent: \", sumnegative/sumall)\n",
    "\n",
    "    if plotting:\n",
    "        plot_confusion_matrix(clf, x_test, y_test,\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize='true')\n",
    "        plt.tight_layout()\n",
    "        plt.title('Confusion matrix', y=1.1)\n",
    "        plt.ylabel('Actual label')\n",
    "        plt.xlabel('Predicted label')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_aucscore(clf, x_test, y_test, classes, plotting, detailed):\n",
    "    if detailed:\n",
    "        print(roc_auc_score(y, clf.predict_proba(x), multi_class='ovo'))\n",
    "        return score\n",
    "    \n",
    "    if plotting and classes == 'binary':\n",
    "        plot_roc_curve(clf, x_test, y_test)\n",
    "        plt.title('ROC Curve', y=1.1)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "traits = ['openness', 'conscientiousness', 'extraversion', 'agreeableness', 'neuroticism']\n",
    "\n",
    "def switching(trait):\n",
    "    switcher={\n",
    "            'openness':30,\n",
    "            'conscientiousness': 30,\n",
    "            'agreeableness': 30,\n",
    "            'extraversion': 30,\n",
    "            'neuroticism':30\n",
    "         }\n",
    "    return switcher.get(trait,\"Invalid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper with nested stratified cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classifier(classifier):\n",
    "    if classifier == 'log':\n",
    "        return LogisticRegression(class_weight='balanced', n_jobs=-1)\n",
    "    elif classifier == 'mcc':\n",
    "        return DummyClassifier(strategy=\"most_frequent\")\n",
    "    elif classifier == 'mlp':\n",
    "        return MLPClassifier()\n",
    "    elif classifier == 'svm':\n",
    "        return svm.SVC(class_weight='balanced', probability=True)\n",
    "    elif classifier == 'linear':\n",
    "        return LinearRegression(n_jobs=-1)\n",
    "    elif classifier == 'multilog':\n",
    "        return LogisticRegression(multi_class='multinomial', n_jobs=-1)\n",
    "    elif classifier == 'knn':\n",
    "        return KNeighborsClassifier(n_neighbors=1, n_jobs=-1)\n",
    "    \n",
    "def get_featureselection(fs, classifier, X, y):\n",
    "    if fs == 'anova':\n",
    "        return SelectKBest(f_classif, k=30)\n",
    "    if fs == 'mutual':\n",
    "        return mutual_info_classif(X, y)\n",
    "    if fs == 'sequential_forward':\n",
    "        return SequentialFeatureSelector(get_classifier(classifier), n_features_to_select=30, direction='forward', n_jobs=-1)\n",
    "    if fs == 'sequential_backward':\n",
    "        return SequentialFeatureSelector(get_classifier(classifier), n_features_to_select=30, direction='backward', n_jobs=-1)\n",
    "\n",
    "\n",
    "    \n",
    "def create_pipeline_cv(classifier, fs, dim, X, y):\n",
    "    if dim:\n",
    "        pipeline = Pipeline([\n",
    "              ('variance_threshold', VarianceThreshold()),\n",
    "              ('scaler', StandardScaler()),\n",
    "              ('pca', PCA(n_components=100)),\n",
    "              ('feature_selection',  get_featureselection(fs, classifier, X, y)),\n",
    "              ('classification', get_classifier(classifier))\n",
    "            ])\n",
    "    else:\n",
    "        pipeline = Pipeline([\n",
    "              ('variance_threshold', VarianceThreshold()),\n",
    "              ('scaler', StandardScaler()),\n",
    "              ('feature_selection',  get_featureselection(fs, classifier, X, y)),\n",
    "              ('classification', get_classifier(classifier))\n",
    "            ])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(classifier):\n",
    "    if classifier == 'log':\n",
    "        params = {'classification__solver': ['lbfgs', 'liblinear', 'saga'], \n",
    "                  'classification__max_iter': [100, 200, 500, 1000],\n",
    "                  'classification__C': [10**x for x in range(-3,5)]}\n",
    "    if classifier == 'multilog':\n",
    "        params = {'classification__class_weight': [None, 'balanced'], \n",
    "                  'classification__solver': ['lbfgs', 'saga'], \n",
    "                  'classification__max_iter': [100, 200, 500, 1000]}\n",
    "    elif classifier == 'mlp':\n",
    "        params = {'classification__hidden_layer_sizes': [(50,), (100,), (200,), (500,)]}\n",
    "    elif classifier == 'svm':\n",
    "        params = {'classification__kernel': ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'],\n",
    "                  'classification__gamma': ['scale', 'auto'], \n",
    "                  'classification__max_iter': [100, 200, 500, 1000],\n",
    "                  'classification__C': [10**x for x in range(-3,5)]}\n",
    "    elif classifier == 'mcc':\n",
    "        params = {}\n",
    "    return params\n",
    "\n",
    "def classify_cv(df, classes, clf_lst, fs, dim):\n",
    "    for option in tqdm(clf_lst):\n",
    "        print(\"Classifier: \", option, \"\\n\")\n",
    "        for trait_name in tqdm(traits):\n",
    "            num_feat = switching(trait_name)\n",
    "            print(\"\\nTrait to predict: \", trait_name, \"\\n\")\n",
    "            x,y = trait(df, classes, trait_name)          \n",
    "            \n",
    "            cv_outer = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "            cv_outer_lst = cv_outer.split(x, y)\n",
    "\n",
    "            f1macro_lst = []\n",
    "            for train_idx, val_idx in tqdm(cv_outer_lst):\n",
    "                train_data, val_data = x.iloc[train_idx], x.iloc[val_idx]\n",
    "                train_target, val_target = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "                print(\"\\n\\tCreate pipeline with\", option, \"...\")\n",
    "                clf = create_pipeline_cv(option, fs, dim, train_data, train_target)\n",
    "                if option == 'log':\n",
    "                    cv_inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "                if option == 'svm' or option == 'mlp' or option == 'mcc':\n",
    "                    cv_inner = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "                params = get_params(option)\n",
    "                print(\"\\tStart grid search...\")\n",
    "                t0 = time()\n",
    "                gd_search = GridSearchCV(clf, params, scoring='f1_macro', n_jobs=-1, cv=cv_inner).fit(train_data, train_target)\n",
    "                print(\"\\tGrid search done in %0.3fs\" % (time() - t0))\n",
    "                print(\"\\tGet best model...\")\n",
    "                best_model = gd_search.best_estimator_\n",
    "                print(best_model)\n",
    "\n",
    "                print(\"\\tFit best model...\")\n",
    "                clfnew = best_model.fit(train_data, train_target)\n",
    "                y_pred = clfnew.predict(val_data)\n",
    "                f1_macro = f1_score(val_target, y_pred, average='macro')\n",
    "                f1macro_lst.append(f1_macro)\n",
    "                print(\"Val Acc:\",f1_macro , \"Best GS Acc:\",gd_search.best_score_, \"Best Params:\",gd_search.best_params_)\n",
    "\n",
    "              # Training final model\n",
    "            f1macro_avg = np.mean(f1macro_lst)\n",
    "            print(\"Average f1 macro score: \", f1macro_avg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodological replication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b666a183854b76bb609d7d5db272ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:  mcc \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2af8df75733543f696073338770486e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trait to predict:  openness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "861ad22cd20144f992f5c701503888f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 4.567s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.3831417624521073 Best GS Acc: 0.3829883396341315 Best Params: {}\n",
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 3.187s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.38269230769230766 Best GS Acc: 0.3831004427227449 Best Params: {}\n",
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 3.084s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.38269230769230766 Best GS Acc: 0.3831004427227449 Best Params: {}\n",
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.991s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.38269230769230766 Best GS Acc: 0.3831004427227449 Best Params: {}\n",
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.535s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.38387715930902105 Best GS Acc: 0.38280414130234275 Best Params: {}\n",
      "Average f1 macro score:  0.3830191689676103\n",
      "\n",
      "Trait to predict:  conscientiousness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6a7c2850e9e4261b821446ae61f2b98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.567s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.39245283018867927 Best GS Acc: 0.39233278864349774 Best Params: {}\n",
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.605s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.39204545454545453 Best GS Acc: 0.3924349881796691 Best Params: {}\n",
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.587s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.39204545454545453 Best GS Acc: 0.3924349881796691 Best Params: {}\n",
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.580s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.39204545454545453 Best GS Acc: 0.3924349881796691 Best Params: {}\n",
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.616s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.3931947069943289 Best GS Acc: 0.39214704267643674 Best Params: {}\n",
      "Average f1 macro score:  0.3923567801638744\n",
      "\n",
      "Trait to predict:  extraversion \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06698ba711c24136b2d02d62e44e633e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.558s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.3598409542743539 Best GS Acc: 0.3605572139303483 Best Params: {}\n",
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.590s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.36055776892430275 Best GS Acc: 0.36037766280815375 Best Params: {}\n",
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.644s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.36055776892430275 Best GS Acc: 0.36037766280815375 Best Params: {}\n",
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.718s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.36055776892430275 Best GS Acc: 0.36037766280815375 Best Params: {}\n",
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.596s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.36055776892430275 Best GS Acc: 0.36037766280815375 Best Params: {}\n",
      "Average f1 macro score:  0.36041440599431296\n",
      "\n",
      "Trait to predict:  agreeableness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08759079295c4dda81493c69420ee0e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.593s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.41666666666666663 Best GS Acc: 0.4163634649690621 Best Params: {}\n",
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.605s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.4163636363636364 Best GS Acc: 0.4164388785817358 Best Params: {}\n",
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.555s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.4163636363636364 Best GS Acc: 0.4164388785817358 Best Params: {}\n",
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.581s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.4163636363636364 Best GS Acc: 0.4164388785817358 Best Params: {}\n",
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.552s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.4163636363636364 Best GS Acc: 0.4164388785817358 Best Params: {}\n",
      "Average f1 macro score:  0.4164242424242425\n",
      "\n",
      "Trait to predict:  neuroticism \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce98fc34e5e842abb6fd58b2671a9109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.595s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.33608247422680415 Best GS Acc: 0.3360913630825668 Best Params: {}\n",
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.544s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.33540372670807456 Best GS Acc: 0.33625962332507525 Best Params: {}\n",
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.613s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.33540372670807456 Best GS Acc: 0.33625962332507525 Best Params: {}\n",
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.586s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.3367768595041322 Best GS Acc: 0.3359173126614987 Best Params: {}\n",
      "\n",
      "\tCreate pipeline with mcc ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 2.609s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', DummyClassifier(strategy='most_frequent'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.3367768595041322 Best GS Acc: 0.3359173126614987 Best Params: {}\n",
      "Average f1 macro score:  0.3360887293302436\n",
      "Classifier:  log \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8426e1354c3841f39c4badea1a73ec61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trait to predict:  openness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bec16b87acd2451ab58739026637b750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 232.941s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced', n_jobs=-1,\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5827242662685701 Best GS Acc: 0.4992020845897178 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 235.695s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced', n_jobs=-1,\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.537833946568549 Best GS Acc: 0.5377906602456449 Best Params: {'classification__C': 0.1, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 236.167s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5216673378977044 Best GS Acc: 0.5719979996597322 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 237.484s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced', n_jobs=-1,\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.543997077684877 Best GS Acc: 0.5433688122951021 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 233.706s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5322215025906736 Best GS Acc: 0.5418202500667647 Best Params: {'classification__C': 0.1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "Average f1 macro score:  0.5436888262020748\n",
      "\n",
      "Trait to predict:  conscientiousness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c625148a891457c9f06962416ad46be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 236.102s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced', n_jobs=-1,\n",
      "                                    solver='saga'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5980186855670102 Best GS Acc: 0.5658298907163929 Best Params: {'classification__C': 1, 'classification__max_iter': 100, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 235.396s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced', n_jobs=-1,\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5178981708954555 Best GS Acc: 0.5433507269353494 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 236.071s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=100, class_weight='balanced',\n",
      "                                    max_iter=200, n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5781273513448438 Best GS Acc: 0.5372678430681639 Best Params: {'classification__C': 100, 'classification__max_iter': 200, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 236.998s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced', n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.6232593548114236 Best GS Acc: 0.5351061473584406 Best Params: {'classification__C': 1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 233.312s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced', n_jobs=-1,\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5152244897959184 Best GS Acc: 0.5479335796034799 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "Average f1 macro score:  0.5665056104829302\n",
      "\n",
      "Trait to predict:  extraversion \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff6c19239f8a4d9eb3b0069adce34f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 234.270s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced', n_jobs=-1,\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5397450482774715 Best GS Acc: 0.5740825665174177 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 232.742s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced', n_jobs=-1,\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5523366796894318 Best GS Acc: 0.5787477935897274 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 235.189s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced', n_jobs=-1,\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5501401432575521 Best GS Acc: 0.5646882351340808 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 238.189s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    max_iter=1000, n_jobs=-1, solver='saga'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.6138846240355184 Best GS Acc: 0.5752401056981642 Best Params: {'classification__C': 0.001, 'classification__max_iter': 1000, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 236.846s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced', n_jobs=-1,\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5988126855178878 Best GS Acc: 0.5736852184339194 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "Average f1 macro score:  0.5709838361555724\n",
      "\n",
      "Trait to predict:  agreeableness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76c3791f774b4078b77d7a2ae4457373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 232.025s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5084983498349835 Best GS Acc: 0.5338507496025126 Best Params: {'classification__C': 0.1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 239.073s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.6074004975124379 Best GS Acc: 0.5178109918713596 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 232.926s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5541666666666667 Best GS Acc: 0.5231322714221102 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 233.548s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5139807200043571 Best GS Acc: 0.544830674573662 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 232.715s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=100, class_weight='balanced',\n",
      "                                    max_iter=200, n_jobs=-1, solver='saga'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5229334289960539 Best GS Acc: 0.5328110185949075 Best Params: {'classification__C': 100, 'classification__max_iter': 200, 'classification__solver': 'saga'}\n",
      "Average f1 macro score:  0.5413959326028998\n",
      "\n",
      "Trait to predict:  neuroticism \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "561fc5976f3243dfb37d6e66e096b969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 237.976s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5866335916913603 Best GS Acc: 0.5703980338469818 Best Params: {'classification__C': 0.1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 232.864s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced', n_jobs=-1,\n",
      "                                    solver='saga'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.532160901671201 Best GS Acc: 0.5749464806497834 Best Params: {'classification__C': 1, 'classification__max_iter': 100, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 234.669s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=10, class_weight='balanced', n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5762211695270638 Best GS Acc: 0.5798813330929906 Best Params: {'classification__C': 10, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 234.757s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=10, class_weight='balanced', n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5695880295375049 Best GS Acc: 0.590073402763868 Best Params: {'classification__C': 10, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 235.659s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced', n_jobs=-1,\n",
      "                                    solver='saga'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.581640989729225 Best GS Acc: 0.5816016544875616 Best Params: {'classification__C': 1, 'classification__max_iter': 100, 'classification__solver': 'saga'}\n",
      "Average f1 macro score:  0.569248936431271\n",
      "Classifier:  mlp \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54688f74f4b5462b8c6e76e349d2ecea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trait to predict:  openness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "641a27a9737f48a0aa14c5f10d4e36d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 13.239s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier(hidden_layer_sizes=(200,)))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5664984731236934 Best GS Acc: 0.5189042531472537 Best Params: {'classification__hidden_layer_sizes': (200,)}\n",
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 12.227s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier())])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5250532545620534 Best GS Acc: 0.5295883894054011 Best Params: {'classification__hidden_layer_sizes': (100,)}\n",
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 11.820s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier(hidden_layer_sizes=(50,)))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5349599695005719 Best GS Acc: 0.5448912150468008 Best Params: {'classification__hidden_layer_sizes': (50,)}\n",
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 11.955s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier(hidden_layer_sizes=(50,)))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5164227356197975 Best GS Acc: 0.5343425339723484 Best Params: {'classification__hidden_layer_sizes': (50,)}\n",
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 11.703s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier(hidden_layer_sizes=(50,)))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.4999134498874849 Best GS Acc: 0.5418769877923802 Best Params: {'classification__hidden_layer_sizes': (50,)}\n",
      "Average f1 macro score:  0.5285695765387202\n",
      "\n",
      "Trait to predict:  conscientiousness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a8897bf5fe842478b3ea6b016a86277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 13.434s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier(hidden_layer_sizes=(200,)))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5664984731236935 Best GS Acc: 0.5657899872997966 Best Params: {'classification__hidden_layer_sizes': (200,)}\n",
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 15.378s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier(hidden_layer_sizes=(500,)))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5279411764705882 Best GS Acc: 0.5504034811939269 Best Params: {'classification__hidden_layer_sizes': (500,)}\n",
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 13.076s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier(hidden_layer_sizes=(200,)))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5168896321070234 Best GS Acc: 0.529944820200195 Best Params: {'classification__hidden_layer_sizes': (200,)}\n",
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 12.927s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier(hidden_layer_sizes=(200,)))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.56151924037981 Best GS Acc: 0.5687043529782081 Best Params: {'classification__hidden_layer_sizes': (200,)}\n",
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 15.437s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier(hidden_layer_sizes=(500,)))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5253207753207754 Best GS Acc: 0.5395947133712882 Best Params: {'classification__hidden_layer_sizes': (500,)}\n",
      "Average f1 macro score:  0.5396338594803781\n",
      "\n",
      "Trait to predict:  extraversion \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5867e49988a04ac18b90b919e14842dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 12.999s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier(hidden_layer_sizes=(200,)))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5589258438038927 Best GS Acc: 0.5572227620923762 Best Params: {'classification__hidden_layer_sizes': (200,)}\n",
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 11.723s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier(hidden_layer_sizes=(50,)))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.6033445918115167 Best GS Acc: 0.5591476005023932 Best Params: {'classification__hidden_layer_sizes': (50,)}\n",
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 12.883s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier(hidden_layer_sizes=(200,)))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5185770276755719 Best GS Acc: 0.5665944267423096 Best Params: {'classification__hidden_layer_sizes': (200,)}\n",
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 12.870s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier())])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5479795918367347 Best GS Acc: 0.548367248312103 Best Params: {'classification__hidden_layer_sizes': (100,)}\n",
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 11.891s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier(hidden_layer_sizes=(50,)))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5729286065171115 Best GS Acc: 0.5388815338659698 Best Params: {'classification__hidden_layer_sizes': (50,)}\n",
      "Average f1 macro score:  0.5603511323289656\n",
      "\n",
      "Trait to predict:  agreeableness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df9ddb057d7143b2ab1a14c102453faf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 15.902s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier(hidden_layer_sizes=(500,)))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.48239973844812556 Best GS Acc: 0.5177872414558288 Best Params: {'classification__hidden_layer_sizes': (500,)}\n",
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 15.436s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier(hidden_layer_sizes=(500,)))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.529947498124933 Best GS Acc: 0.5062876846417101 Best Params: {'classification__hidden_layer_sizes': (500,)}\n",
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 15.280s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier(hidden_layer_sizes=(500,)))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.50886356441912 Best GS Acc: 0.5115079924612239 Best Params: {'classification__hidden_layer_sizes': (500,)}\n",
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 12.968s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier(hidden_layer_sizes=(200,)))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.4858783546232275 Best GS Acc: 0.5145327284838797 Best Params: {'classification__hidden_layer_sizes': (200,)}\n",
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 12.260s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier())])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5331921624655577 Best GS Acc: 0.535021692267196 Best Params: {'classification__hidden_layer_sizes': (100,)}\n",
      "Average f1 macro score:  0.5080562636161927\n",
      "\n",
      "Trait to predict:  neuroticism \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeabd60ecbaa4e398684d891055e82bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 12.276s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier())])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5154531774510939 Best GS Acc: 0.578923932530596 Best Params: {'classification__hidden_layer_sizes': (100,)}\n",
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 12.081s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier())])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.529595015576324 Best GS Acc: 0.566896732193787 Best Params: {'classification__hidden_layer_sizes': (100,)}\n",
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 11.707s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier(hidden_layer_sizes=(50,)))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5389005357558816 Best GS Acc: 0.5638377918880131 Best Params: {'classification__hidden_layer_sizes': (50,)}\n",
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 12.434s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier())])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5700892857142857 Best GS Acc: 0.5436314963184443 Best Params: {'classification__hidden_layer_sizes': (100,)}\n",
      "\n",
      "\tCreate pipeline with mlp ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 12.160s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification', MLPClassifier())])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.521507000126655 Best GS Acc: 0.5399999252788688 Best Params: {'classification__hidden_layer_sizes': (100,)}\n",
      "Average f1 macro score:  0.535109002924848\n",
      "Classifier:  svm \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb65d8b4d8aa48bebeb9f5081d52cbc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trait to predict:  openness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95039712c7b549b1bc8e2354d34db0b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.27498456 0.27498456 0.27498456 0.48191527 0.27498456 0.27498456\n",
      " 0.29761309 0.39093403 0.27498456 0.27498456 0.27498456 0.27498456\n",
      " 0.27498456 0.27498456 0.27498456 0.27498456        nan        nan\n",
      "        nan        nan 0.27498456 0.27498456 0.27498456 0.48191527\n",
      " 0.27498456 0.27498456 0.29761309 0.39093403 0.27498456 0.27498456\n",
      " 0.27498456 0.27498456 0.27498456 0.27498456 0.27498456 0.27498456\n",
      "        nan        nan        nan        nan 0.27498456 0.27457324\n",
      " 0.28517742 0.49736022 0.28014781 0.28531428 0.33263841 0.41545054\n",
      " 0.27498456 0.27498456 0.27498456 0.27498456 0.27498456 0.27498456\n",
      " 0.27498456 0.31897624        nan        nan        nan        nan\n",
      " 0.27498456 0.27457324 0.28517742 0.49736022 0.28014781 0.28531428\n",
      " 0.33263841 0.41545054 0.27498456 0.27498456 0.27498456 0.27498456\n",
      " 0.27498456 0.27498456 0.27498456 0.31897624        nan        nan\n",
      "        nan        nan 0.34552563 0.33308862 0.38326898 0.50541326\n",
      " 0.28592875 0.2940153  0.33036755 0.45668377 0.27498456 0.27498456\n",
      " 0.29217777 0.53160325 0.27498456 0.27778801 0.28337462 0.47919467\n",
      "        nan        nan        nan        nan 0.34552563 0.33308862\n",
      " 0.38326898 0.50541326 0.28592875 0.2940153  0.33036755 0.45668377\n",
      " 0.27498456 0.27498456 0.29217777 0.53160325 0.27498456 0.27778801\n",
      " 0.28337462 0.47919467        nan        nan        nan        nan\n",
      " 0.41618889 0.37351189 0.37812181 0.38368355 0.31553567 0.3374779\n",
      " 0.35197986 0.45324552 0.45347407 0.40386679 0.37669876 0.50878482\n",
      " 0.41634291 0.40952191 0.46545882 0.49361512        nan        nan\n",
      "        nan        nan 0.41618889 0.37351189 0.37812181 0.38368355\n",
      " 0.31553567 0.3374779  0.35197986 0.45324552 0.45347407 0.40386679\n",
      " 0.37669876 0.50878482 0.41634291 0.40952191 0.46545882 0.49361512\n",
      "        nan        nan        nan        nan 0.45002758 0.39620518\n",
      " 0.40834753 0.38093665 0.32425733 0.35357405 0.37866862 0.43854883\n",
      " 0.49974136 0.51065703 0.50543256 0.51739112 0.40301311 0.43745888\n",
      " 0.46111814 0.45974741        nan        nan        nan        nan\n",
      " 0.45002758 0.39620518 0.40834753 0.38093665 0.32425733 0.35357405\n",
      " 0.37866862 0.43854883 0.49974136 0.51065703 0.50543256 0.51739112\n",
      " 0.40301311 0.43745888 0.46111814 0.45974741        nan        nan\n",
      "        nan        nan 0.43074587 0.39379252 0.38895115 0.39118356\n",
      " 0.33027817 0.3509978  0.40765452 0.44123689 0.49625749 0.50950807\n",
      " 0.50456258 0.51624515 0.43712542 0.45126876 0.46482469 0.46524846\n",
      "        nan        nan        nan        nan 0.43074587 0.39379252\n",
      " 0.38895115 0.39118356 0.33027817 0.3509978  0.40765452 0.44123689\n",
      " 0.49625749 0.50950807 0.50456258 0.51624515 0.43712542 0.45126876\n",
      " 0.46482469 0.46524846        nan        nan        nan        nan\n",
      " 0.44846383 0.40968172 0.37870338 0.38345391 0.35158411 0.35489051\n",
      " 0.39522531 0.43380681 0.49625749 0.50950807 0.51395298 0.50590862\n",
      " 0.43460557 0.4422449  0.46888013 0.47259557        nan        nan\n",
      "        nan        nan 0.44846383 0.40968172 0.37870338 0.38345391\n",
      " 0.35158411 0.35489051 0.39522531 0.43380681 0.49625749 0.50950807\n",
      " 0.51395298 0.50590862 0.43460557 0.4422449  0.46888013 0.47259557\n",
      "        nan        nan        nan        nan 0.44846383 0.40968172\n",
      " 0.37870338 0.3826834  0.35330295 0.3520498  0.38306689 0.42181623\n",
      " 0.49625749 0.50950807 0.49840156 0.50186366 0.43642083 0.42677188\n",
      " 0.46740042 0.46802881        nan        nan        nan        nan\n",
      " 0.44846383 0.40968172 0.37870338 0.3826834  0.35330295 0.3520498\n",
      " 0.38306689 0.42181623 0.49625749 0.50950807 0.49840156 0.50186366\n",
      " 0.43642083 0.42677188 0.46740042 0.46802881        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 343.938s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=0.1, class_weight='balanced', max_iter=1000,\n",
      "                     probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.2747747747747748 Best GS Acc: 0.5316032482846069 Best Params: {'classification__C': 0.1, 'classification__gamma': 'scale', 'classification__kernel': 'rbf', 'classification__max_iter': 1000}\n",
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.27482931 0.27482931 0.27482931 0.54505306 0.27482931 0.27482931\n",
      " 0.34158033 0.36964486 0.3179967  0.29606035 0.27482931 0.27482931\n",
      " 0.27482931 0.27482931 0.27482931 0.27482931        nan        nan\n",
      "        nan        nan 0.27482931 0.27482931 0.27482931 0.54505306\n",
      " 0.27482931 0.27482931 0.34158033 0.36964486 0.3179967  0.29606035\n",
      " 0.27482931 0.27482931 0.27482931 0.27482931 0.27482931 0.27482931\n",
      "        nan        nan        nan        nan 0.27482931 0.27482931\n",
      " 0.30778761 0.54823677 0.27720456 0.2759729  0.36622465 0.41673099\n",
      " 0.29606035 0.29606035 0.27482931 0.27482931 0.27482931 0.27482931\n",
      " 0.27482931 0.27858759        nan        nan        nan        nan\n",
      " 0.27482931 0.27482931 0.30778761 0.54823677 0.27720456 0.2759729\n",
      " 0.36622465 0.41673099 0.29606035 0.29606035 0.27482931 0.27482931\n",
      " 0.27482931 0.27482931 0.27482931 0.27858759        nan        nan\n",
      "        nan        nan 0.31413545 0.30133499 0.43437511 0.54344452\n",
      " 0.28672986 0.29300457 0.39162351 0.44419349 0.33999361 0.29606035\n",
      " 0.31884595 0.52771362 0.27482931 0.27901579 0.28134002 0.53928769\n",
      "        nan        nan        nan        nan 0.31413545 0.30133499\n",
      " 0.43437511 0.54344452 0.28672986 0.29300457 0.39162351 0.44419349\n",
      " 0.33999361 0.29606035 0.31884595 0.52771362 0.27482931 0.27901579\n",
      " 0.28134002 0.53928769        nan        nan        nan        nan\n",
      " 0.40343824 0.39317829 0.39821237 0.38930863 0.30616925 0.3351399\n",
      " 0.34919871 0.49253117 0.42580531 0.44965578 0.455266   0.53078915\n",
      " 0.4246279  0.39577126 0.50575466 0.53115381        nan        nan\n",
      "        nan        nan 0.40343824 0.39317829 0.39821237 0.38930863\n",
      " 0.30616925 0.3351399  0.34919871 0.49253117 0.42580531 0.44965578\n",
      " 0.455266   0.53078915 0.4246279  0.39577126 0.50575466 0.53115381\n",
      "        nan        nan        nan        nan 0.46308395 0.40703521\n",
      " 0.36242974 0.40604096 0.34449927 0.36463512 0.4026134  0.5137551\n",
      " 0.48976739 0.48146883 0.48489311 0.51803166 0.4491917  0.46038875\n",
      " 0.51629459 0.52036678        nan        nan        nan        nan\n",
      " 0.46308395 0.40703521 0.36242974 0.40604096 0.34449927 0.36463512\n",
      " 0.4026134  0.5137551  0.48976739 0.48146883 0.48489311 0.51803166\n",
      " 0.4491917  0.46038875 0.51629459 0.52036678        nan        nan\n",
      "        nan        nan 0.42798402 0.44506555 0.39370157 0.38647314\n",
      " 0.31152769 0.3535074  0.42641169 0.44973848 0.48364969 0.47074068\n",
      " 0.48873108 0.51476987 0.44946399 0.44438507 0.52249049 0.51606254\n",
      "        nan        nan        nan        nan 0.42798402 0.44506555\n",
      " 0.39370157 0.38647314 0.31152769 0.3535074  0.42641169 0.44973848\n",
      " 0.48364969 0.47074068 0.48873108 0.51476987 0.44946399 0.44438507\n",
      " 0.52249049 0.51606254        nan        nan        nan        nan\n",
      " 0.4424908  0.45034708 0.39459902 0.41888808 0.36734023 0.3521886\n",
      " 0.41407291 0.46711709 0.471882   0.49362451 0.51650939 0.51988509\n",
      " 0.43112696 0.45087372 0.51817797 0.52311922        nan        nan\n",
      "        nan        nan 0.4424908  0.45034708 0.39459902 0.41888808\n",
      " 0.36734023 0.3521886  0.41407291 0.46711709 0.471882   0.49362451\n",
      " 0.51650939 0.51988509 0.43112696 0.45087372 0.51817797 0.52311922\n",
      "        nan        nan        nan        nan 0.45779389 0.46006537\n",
      " 0.40109446 0.42273033 0.37854126 0.34725881 0.39402414 0.44954755\n",
      " 0.483659   0.482308   0.49567206 0.49430667 0.43180629 0.465554\n",
      " 0.51865018 0.52180901        nan        nan        nan        nan\n",
      " 0.45779389 0.46006537 0.40109446 0.42273033 0.37854126 0.34725881\n",
      " 0.39402414 0.44954755 0.483659   0.482308   0.49567206 0.49430667\n",
      " 0.43180629 0.465554   0.51865018 0.52180901        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 347.719s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=0.01, class_weight='balanced', kernel='linear',\n",
      "                     max_iter=1000, probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.49795513935166746 Best GS Acc: 0.5482367734660896 Best Params: {'classification__C': 0.01, 'classification__gamma': 'scale', 'classification__kernel': 'linear', 'classification__max_iter': 1000}\n",
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.27482931 0.27482931 0.27482931 0.55020317 0.27482931 0.27482931\n",
      " 0.3179967  0.40065022 0.27482931 0.27482931 0.27482931 0.27482931\n",
      " 0.27482931 0.27482931 0.27482931 0.27482931        nan        nan\n",
      "        nan        nan 0.27482931 0.27482931 0.27482931 0.55020317\n",
      " 0.27482931 0.27482931 0.3179967  0.40065022 0.27482931 0.27482931\n",
      " 0.27482931 0.27482931 0.27482931 0.27482931 0.27482931 0.27482931\n",
      "        nan        nan        nan        nan 0.27482931 0.27482931\n",
      " 0.29337907 0.56549321 0.27539807 0.27776137 0.32471743 0.41947354\n",
      " 0.29676566 0.29606035 0.27482931 0.27482931 0.27482931 0.27482931\n",
      " 0.27482931 0.30151935        nan        nan        nan        nan\n",
      " 0.27482931 0.27482931 0.29337907 0.56549321 0.27539807 0.27776137\n",
      " 0.32471743 0.41947354 0.29676566 0.29606035 0.27482931 0.27482931\n",
      " 0.27482931 0.27482931 0.27482931 0.30151935        nan        nan\n",
      "        nan        nan 0.3291209  0.29445759 0.36571781 0.54058887\n",
      " 0.28573957 0.29671928 0.35585674 0.46027193 0.35475038 0.29606035\n",
      " 0.27482931 0.53955988 0.27857938 0.2802623  0.29495256 0.55349523\n",
      "        nan        nan        nan        nan 0.3291209  0.29445759\n",
      " 0.36571781 0.54058887 0.28573957 0.29671928 0.35585674 0.46027193\n",
      " 0.35475038 0.29606035 0.27482931 0.53955988 0.27857938 0.2802623\n",
      " 0.29495256 0.55349523        nan        nan        nan        nan\n",
      " 0.45270334 0.416327   0.40280632 0.41182729 0.31905979 0.3362956\n",
      " 0.35233936 0.50211882 0.46371224 0.46941735 0.44955708 0.54285992\n",
      " 0.45300239 0.42042905 0.5011152  0.52598107        nan        nan\n",
      "        nan        nan 0.45270334 0.416327   0.40280632 0.41182729\n",
      " 0.31905979 0.3362956  0.35233936 0.50211882 0.46371224 0.46941735\n",
      " 0.44955708 0.54285992 0.45300239 0.42042905 0.5011152  0.52598107\n",
      "        nan        nan        nan        nan 0.43390455 0.43056315\n",
      " 0.40437954 0.42641142 0.32687423 0.35415201 0.36626002 0.47375912\n",
      " 0.50903368 0.51239658 0.52475295 0.51798519 0.48265631 0.47341371\n",
      " 0.50909472 0.51492336        nan        nan        nan        nan\n",
      " 0.43390455 0.43056315 0.40437954 0.42641142 0.32687423 0.35415201\n",
      " 0.36626002 0.47375912 0.50903368 0.51239658 0.52475295 0.51798519\n",
      " 0.48265631 0.47341371 0.50909472 0.51492336        nan        nan\n",
      "        nan        nan 0.40296494 0.43874403 0.45988247 0.40040764\n",
      " 0.31392416 0.34169417 0.38797207 0.43880732 0.4896683  0.47676164\n",
      " 0.51184806 0.51664597 0.49611368 0.52048951 0.51339017 0.51726475\n",
      "        nan        nan        nan        nan 0.40296494 0.43874403\n",
      " 0.45988247 0.40040764 0.31392416 0.34169417 0.38797207 0.43880732\n",
      " 0.4896683  0.47676164 0.51184806 0.51664597 0.49611368 0.52048951\n",
      " 0.51339017 0.51726475        nan        nan        nan        nan\n",
      " 0.426015   0.44297855 0.45222167 0.40748836 0.33706789 0.37896527\n",
      " 0.3709254  0.41887626 0.4896683  0.47676164 0.51880495 0.51505657\n",
      " 0.4950698  0.49443344 0.50413467 0.50577272        nan        nan\n",
      "        nan        nan 0.426015   0.44297855 0.45222167 0.40748836\n",
      " 0.33706789 0.37896527 0.3709254  0.41887626 0.4896683  0.47676164\n",
      " 0.51880495 0.51505657 0.4950698  0.49443344 0.50413467 0.50577272\n",
      "        nan        nan        nan        nan 0.44772454 0.45710311\n",
      " 0.46657243 0.40744106 0.36443944 0.35799457 0.40159788 0.40760037\n",
      " 0.4896683  0.47676164 0.51257532 0.50943206 0.49288789 0.48637421\n",
      " 0.51134579 0.50548604        nan        nan        nan        nan\n",
      " 0.44772454 0.45710311 0.46657243 0.40744106 0.36443944 0.35799457\n",
      " 0.40159788 0.40760037 0.4896683  0.47676164 0.51257532 0.50943206\n",
      " 0.49288789 0.48637421 0.51134579 0.50548604        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 346.277s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=0.01, class_weight='balanced', kernel='linear',\n",
      "                     max_iter=1000, probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5368601855032634 Best GS Acc: 0.5654932114861868 Best Params: {'classification__C': 0.01, 'classification__gamma': 'scale', 'classification__kernel': 'linear', 'classification__max_iter': 1000}\n",
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.27482931 0.27482931 0.27482931 0.51334336 0.27482931 0.27482931\n",
      " 0.27582395 0.39774164 0.31870201 0.29676566 0.29606035 0.27482931\n",
      " 0.27482931 0.27482931 0.27482931 0.27482931        nan        nan\n",
      "        nan        nan 0.27482931 0.27482931 0.27482931 0.51334336\n",
      " 0.27482931 0.27482931 0.27582395 0.39774164 0.31870201 0.29676566\n",
      " 0.29606035 0.27482931 0.27482931 0.27482931 0.27482931 0.27482931\n",
      "        nan        nan        nan        nan 0.27580708 0.27482931\n",
      " 0.28218286 0.52570501 0.27400666 0.27331084 0.30528262 0.40547368\n",
      " 0.31870201 0.29676566 0.27482931 0.27482931 0.27482931 0.27482931\n",
      " 0.27482931 0.28881951        nan        nan        nan        nan\n",
      " 0.27580708 0.27482931 0.28218286 0.52570501 0.27400666 0.27331084\n",
      " 0.30528262 0.40547368 0.31870201 0.29676566 0.27482931 0.27482931\n",
      " 0.27482931 0.27482931 0.27482931 0.28881951        nan        nan\n",
      "        nan        nan 0.31811116 0.30070992 0.37556036 0.50793416\n",
      " 0.28091573 0.28994984 0.32758144 0.42791906 0.32755185 0.27482931\n",
      " 0.28340843 0.53074991 0.272352   0.27611898 0.2862116  0.52675038\n",
      "        nan        nan        nan        nan 0.31811116 0.30070992\n",
      " 0.37556036 0.50793416 0.28091573 0.28994984 0.32758144 0.42791906\n",
      " 0.32755185 0.27482931 0.28340843 0.53074991 0.272352   0.27611898\n",
      " 0.2862116  0.52675038        nan        nan        nan        nan\n",
      " 0.45838123 0.43009696 0.43610105 0.40780737 0.31038836 0.33041264\n",
      " 0.34530975 0.45342472 0.47661651 0.42797941 0.4152882  0.52925011\n",
      " 0.4481486  0.45859398 0.53013365 0.53550554        nan        nan\n",
      "        nan        nan 0.45838123 0.43009696 0.43610105 0.40780737\n",
      " 0.31038836 0.33041264 0.34530975 0.45342472 0.47661651 0.42797941\n",
      " 0.4152882  0.52925011 0.4481486  0.45859398 0.53013365 0.53550554\n",
      "        nan        nan        nan        nan 0.44535258 0.38563927\n",
      " 0.41334158 0.37919544 0.33401379 0.34996076 0.36991332 0.45369528\n",
      " 0.51763617 0.50327105 0.52482496 0.52611049 0.49373839 0.49983265\n",
      " 0.5283198  0.52855937        nan        nan        nan        nan\n",
      " 0.44535258 0.38563927 0.41334158 0.37919544 0.33401379 0.34996076\n",
      " 0.36991332 0.45369528 0.51763617 0.50327105 0.52482496 0.52611049\n",
      " 0.49373839 0.49983265 0.5283198  0.52855937        nan        nan\n",
      "        nan        nan 0.43275287 0.3911077  0.45829187 0.38018191\n",
      " 0.335397   0.36055338 0.41058083 0.45178426 0.50973309 0.47257303\n",
      " 0.50146433 0.49175156 0.48228262 0.50734486 0.52651292 0.53013538\n",
      "        nan        nan        nan        nan 0.43275287 0.3911077\n",
      " 0.45829187 0.38018191 0.335397   0.36055338 0.41058083 0.45178426\n",
      " 0.50973309 0.47257303 0.50146433 0.49175156 0.48228262 0.50734486\n",
      " 0.52651292 0.53013538        nan        nan        nan        nan\n",
      " 0.43606738 0.39582566 0.46308084 0.38135766 0.34638192 0.35885507\n",
      " 0.38914782 0.42732034 0.50973309 0.47257303 0.48813534 0.507349\n",
      " 0.50818787 0.5159018  0.52926056 0.53207769        nan        nan\n",
      "        nan        nan 0.43606738 0.39582566 0.46308084 0.38135766\n",
      " 0.34638192 0.35885507 0.38914782 0.42732034 0.50973309 0.47257303\n",
      " 0.48813534 0.507349   0.50818787 0.5159018  0.52926056 0.53207769\n",
      "        nan        nan        nan        nan 0.43606738 0.39582566\n",
      " 0.46308084 0.38569378 0.34638192 0.35885507 0.39779198 0.43621358\n",
      " 0.50973309 0.47257303 0.48813534 0.507349   0.5093523  0.50193283\n",
      " 0.52828803 0.53082503        nan        nan        nan        nan\n",
      " 0.43606738 0.39582566 0.46308084 0.38569378 0.34638192 0.35885507\n",
      " 0.39779198 0.43621358 0.50973309 0.47257303 0.48813534 0.507349\n",
      " 0.5093523  0.50193283 0.52828803 0.53082503        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 347.720s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=1, class_weight='balanced', kernel='sigmoid',\n",
      "                     max_iter=1000, probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5206093189964158 Best GS Acc: 0.535505535438984 Best Params: {'classification__C': 1, 'classification__gamma': 'scale', 'classification__kernel': 'sigmoid', 'classification__max_iter': 1000}\n",
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.27523832 0.27523832 0.27523832 0.53512507 0.27663581 0.27663581\n",
      " 0.27663581 0.38766499 0.27523832 0.27523832 0.27523832 0.27523832\n",
      " 0.27523832 0.27523832 0.27523832 0.27523832        nan        nan\n",
      "        nan        nan 0.27523832 0.27523832 0.27523832 0.53512507\n",
      " 0.27663581 0.27663581 0.27663581 0.38766499 0.27523832 0.27523832\n",
      " 0.27523832 0.27523832 0.27523832 0.27523832 0.27523832 0.27523832\n",
      "        nan        nan        nan        nan 0.27523832 0.27801883\n",
      " 0.29656477 0.54080981 0.27623296 0.2831108  0.29049956 0.40155925\n",
      " 0.27523832 0.27523832 0.27523832 0.27523832 0.27523832 0.27523832\n",
      " 0.27523832 0.28448535        nan        nan        nan        nan\n",
      " 0.27523832 0.27801883 0.29656477 0.54080981 0.27623296 0.2831108\n",
      " 0.29049956 0.40155925 0.27523832 0.27523832 0.27523832 0.27523832\n",
      " 0.27523832 0.27523832 0.27523832 0.28448535        nan        nan\n",
      "        nan        nan 0.30858334 0.31656692 0.36761729 0.52854744\n",
      " 0.29188381 0.29052052 0.31537748 0.44061414 0.29646936 0.29646936\n",
      " 0.27523832 0.52793333 0.27441799 0.2771819  0.28411966 0.53148208\n",
      "        nan        nan        nan        nan 0.30858334 0.31656692\n",
      " 0.36761729 0.52854744 0.29188381 0.29052052 0.31537748 0.44061414\n",
      " 0.29646936 0.29646936 0.27523832 0.52793333 0.27441799 0.2771819\n",
      " 0.28411966 0.53148208        nan        nan        nan        nan\n",
      " 0.40646953 0.40445641 0.38180437 0.39260812 0.31570381 0.33859842\n",
      " 0.35276793 0.50120311 0.43109864 0.44472063 0.38061538 0.5464044\n",
      " 0.36519616 0.4185542  0.49536455 0.50861617        nan        nan\n",
      "        nan        nan 0.40646953 0.40445641 0.38180437 0.39260812\n",
      " 0.31570381 0.33859842 0.35276793 0.50120311 0.43109864 0.44472063\n",
      " 0.38061538 0.5464044  0.36519616 0.4185542  0.49536455 0.50861617\n",
      "        nan        nan        nan        nan 0.41320802 0.44015043\n",
      " 0.36974074 0.39184176 0.32830084 0.36409023 0.3933721  0.47462896\n",
      " 0.51096812 0.50316037 0.5049451  0.53298895 0.44078466 0.46044112\n",
      " 0.49821348 0.49589413        nan        nan        nan        nan\n",
      " 0.41320802 0.44015043 0.36974074 0.39184176 0.32830084 0.36409023\n",
      " 0.3933721  0.47462896 0.51096812 0.50316037 0.5049451  0.53298895\n",
      " 0.44078466 0.46044112 0.49821348 0.49589413        nan        nan\n",
      "        nan        nan 0.43335686 0.43923957 0.44333778 0.41175603\n",
      " 0.34090279 0.37299438 0.41603145 0.44143893 0.50264657 0.49134484\n",
      " 0.49807922 0.49715993 0.46422058 0.47911283 0.5037635  0.50653031\n",
      "        nan        nan        nan        nan 0.43335686 0.43923957\n",
      " 0.44333778 0.41175603 0.34090279 0.37299438 0.41603145 0.44143893\n",
      " 0.50264657 0.49134484 0.49807922 0.49715993 0.46422058 0.47911283\n",
      " 0.5037635  0.50653031        nan        nan        nan        nan\n",
      " 0.42617863 0.43563721 0.43618432 0.4408457  0.35839866 0.37961407\n",
      " 0.40677381 0.44756911 0.50264657 0.49134484 0.51372886 0.50609212\n",
      " 0.46783662 0.46647916 0.50486489 0.50599052        nan        nan\n",
      "        nan        nan 0.42617863 0.43563721 0.43618432 0.4408457\n",
      " 0.35839866 0.37961407 0.40677381 0.44756911 0.50264657 0.49134484\n",
      " 0.51372886 0.50609212 0.46783662 0.46647916 0.50486489 0.50599052\n",
      "        nan        nan        nan        nan 0.42617863 0.43563721\n",
      " 0.44076595 0.42240334 0.35886531 0.37214664 0.38611569 0.42195053\n",
      " 0.50264657 0.49134484 0.51486035 0.50937134 0.46969395 0.47228888\n",
      " 0.51324833 0.50750135        nan        nan        nan        nan\n",
      " 0.42617863 0.43563721 0.44076595 0.42240334 0.35886531 0.37214664\n",
      " 0.38611569 0.42195053 0.50264657 0.49134484 0.51486035 0.50937134\n",
      " 0.46969395 0.47228888 0.51324833 0.50750135        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 342.487s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=1, class_weight='balanced', max_iter=1000,\n",
      "                     probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5260196344480805 Best GS Acc: 0.5464043955571454 Best Params: {'classification__C': 1, 'classification__gamma': 'scale', 'classification__kernel': 'rbf', 'classification__max_iter': 1000}\n",
      "Average f1 macro score:  0.47124381061484044\n",
      "\n",
      "Trait to predict:  conscientiousness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "906f14ff0cc94cc699525c3caada635f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.26164497 0.26164497 0.26164497 0.55354277 0.26121852 0.26256685\n",
      " 0.34919355 0.34273185 0.34160461 0.35855217 0.26164497 0.26164497\n",
      " 0.26164497 0.26164497 0.26164497 0.26164497        nan        nan\n",
      "        nan        nan 0.26164497 0.26164497 0.26164497 0.55354277\n",
      " 0.26121852 0.26256685 0.34919355 0.34273185 0.34160461 0.35855217\n",
      " 0.26164497 0.26164497 0.26164497 0.26164497 0.26164497 0.26164497\n",
      "        nan        nan        nan        nan 0.26779165 0.26348239\n",
      " 0.29632153 0.56317222 0.26878677 0.3150776  0.35512049 0.39907118\n",
      " 0.30567997 0.38474032 0.26164497 0.26164497 0.26164497 0.26164497\n",
      " 0.26164497 0.2718447         nan        nan        nan        nan\n",
      " 0.26779165 0.26348239 0.29632153 0.56317222 0.26878677 0.3150776\n",
      " 0.35512049 0.39907118 0.30567997 0.38474032 0.26164497 0.26164497\n",
      " 0.26164497 0.26164497 0.26164497 0.2718447         nan        nan\n",
      "        nan        nan 0.31273328 0.31639948 0.42713068 0.55435434\n",
      " 0.29317927 0.31687386 0.4058997  0.44736408 0.35760777 0.37669671\n",
      " 0.29634982 0.54559865 0.26299329 0.2732281  0.28619646 0.54915248\n",
      "        nan        nan        nan        nan 0.31273328 0.31639948\n",
      " 0.42713068 0.55435434 0.29317927 0.31687386 0.4058997  0.44736408\n",
      " 0.35760777 0.37669671 0.29634982 0.54559865 0.26299329 0.2732281\n",
      " 0.28619646 0.54915248        nan        nan        nan        nan\n",
      " 0.40969206 0.38187508 0.38957477 0.39276773 0.31869763 0.33935963\n",
      " 0.3624464  0.51174397 0.46883461 0.44661257 0.53951909 0.56984257\n",
      " 0.40847708 0.41899325 0.50607511 0.55322385        nan        nan\n",
      "        nan        nan 0.40969206 0.38187508 0.38957477 0.39276773\n",
      " 0.31869763 0.33935963 0.3624464  0.51174397 0.46883461 0.44661257\n",
      " 0.53951909 0.56984257 0.40847708 0.41899325 0.50607511 0.55322385\n",
      "        nan        nan        nan        nan 0.44219352 0.41021686\n",
      " 0.39128601 0.39205904 0.33212483 0.35708558 0.40092137 0.53158923\n",
      " 0.50309854 0.53118634 0.5287163  0.5288758  0.44777817 0.4978483\n",
      " 0.54519284 0.5446247         nan        nan        nan        nan\n",
      " 0.44219352 0.41021686 0.39128601 0.39205904 0.33212483 0.35708558\n",
      " 0.40092137 0.53158923 0.50309854 0.53118634 0.5287163  0.5288758\n",
      " 0.44777817 0.4978483  0.54519284 0.5446247         nan        nan\n",
      "        nan        nan 0.42738005 0.42877988 0.40738951 0.4067493\n",
      " 0.33993275 0.36979312 0.41078883 0.46076855 0.5198328  0.49219147\n",
      " 0.50933962 0.52110694 0.47125616 0.49923351 0.53808417 0.54413512\n",
      "        nan        nan        nan        nan 0.42738005 0.42877988\n",
      " 0.40738951 0.4067493  0.33993275 0.36979312 0.41078883 0.46076855\n",
      " 0.5198328  0.49219147 0.50933962 0.52110694 0.47125616 0.49923351\n",
      " 0.53808417 0.54413512        nan        nan        nan        nan\n",
      " 0.42738005 0.42197497 0.40194445 0.39901988 0.33756949 0.37774418\n",
      " 0.39139901 0.43956634 0.53718355 0.49752719 0.52331664 0.52284758\n",
      " 0.48577638 0.50099658 0.54565513 0.54698582        nan        nan\n",
      "        nan        nan 0.42738005 0.42197497 0.40194445 0.39901988\n",
      " 0.33756949 0.37774418 0.39139901 0.43956634 0.53718355 0.49752719\n",
      " 0.52331664 0.52284758 0.48577638 0.50099658 0.54565513 0.54698582\n",
      "        nan        nan        nan        nan 0.42738005 0.42003127\n",
      " 0.39773068 0.40110895 0.33756949 0.36628546 0.39547241 0.42002692\n",
      " 0.51902151 0.48256604 0.50848463 0.5318749  0.47338588 0.49709093\n",
      " 0.54610164 0.5471981         nan        nan        nan        nan\n",
      " 0.42738005 0.42003127 0.39773068 0.40110895 0.33756949 0.36628546\n",
      " 0.39547241 0.42002692 0.51902151 0.48256604 0.50848463 0.5318749\n",
      " 0.47338588 0.49709093 0.54610164 0.5471981         nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 347.216s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=1, class_weight='balanced', max_iter=1000,\n",
      "                     probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5953106305110648 Best GS Acc: 0.5698425699459257 Best Params: {'classification__C': 1, 'classification__gamma': 'scale', 'classification__kernel': 'rbf', 'classification__max_iter': 1000}\n",
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.26149425 0.26149425 0.26149425 0.5403433  0.26552583 0.26467207\n",
      " 0.34542521 0.29405921 0.39243499 0.36624684 0.26149425 0.26149425\n",
      " 0.26149425 0.26149425 0.26149425 0.26149425        nan        nan\n",
      "        nan        nan 0.26149425 0.26149425 0.26149425 0.5403433\n",
      " 0.26552583 0.26467207 0.34542521 0.29405921 0.39243499 0.36624684\n",
      " 0.26149425 0.26149425 0.26149425 0.26149425 0.26149425 0.26149425\n",
      "        nan        nan        nan        nan 0.2610686  0.26156316\n",
      " 0.27828288 0.54343435 0.26647954 0.33003234 0.38079921 0.41701422\n",
      " 0.36624684 0.34005869 0.31387055 0.26149425 0.26149425 0.26149425\n",
      " 0.26149425 0.28815827        nan        nan        nan        nan\n",
      " 0.2610686  0.26156316 0.27828288 0.54343435 0.26647954 0.33003234\n",
      " 0.38079921 0.41701422 0.36624684 0.34005869 0.31387055 0.26149425\n",
      " 0.26149425 0.26149425 0.26149425 0.28815827        nan        nan\n",
      "        nan        nan 0.32186373 0.31864397 0.40261353 0.54069022\n",
      " 0.28239148 0.31281695 0.3732083  0.45160573 0.37356387 0.37715491\n",
      " 0.32851458 0.52937429 0.26241692 0.26777638 0.27089033 0.55543775\n",
      "        nan        nan        nan        nan 0.32186373 0.31864397\n",
      " 0.40261353 0.54069022 0.28239148 0.31281695 0.3732083  0.45160573\n",
      " 0.37356387 0.37715491 0.32851458 0.52937429 0.26241692 0.26777638\n",
      " 0.27089033 0.55543775        nan        nan        nan        nan\n",
      " 0.42457514 0.41470194 0.37910874 0.42568232 0.30705447 0.32149025\n",
      " 0.34282446 0.48292105 0.43133198 0.50401267 0.53004823 0.54577588\n",
      " 0.43876085 0.413932   0.51078882 0.55196063        nan        nan\n",
      "        nan        nan 0.42457514 0.41470194 0.37910874 0.42568232\n",
      " 0.30705447 0.32149025 0.34282446 0.48292105 0.43133198 0.50401267\n",
      " 0.53004823 0.54577588 0.43876085 0.413932   0.51078882 0.55196063\n",
      "        nan        nan        nan        nan 0.41368237 0.3858336\n",
      " 0.36734545 0.38591704 0.32408419 0.35122723 0.39695568 0.51238841\n",
      " 0.49551161 0.52112283 0.53261371 0.54593706 0.45987474 0.4764105\n",
      " 0.55058418 0.53851622        nan        nan        nan        nan\n",
      " 0.41368237 0.3858336  0.36734545 0.38591704 0.32408419 0.35122723\n",
      " 0.39695568 0.51238841 0.49551161 0.52112283 0.53261371 0.54593706\n",
      " 0.45987474 0.4764105  0.55058418 0.53851622        nan        nan\n",
      "        nan        nan 0.39607067 0.39053022 0.39319975 0.37548271\n",
      " 0.33785501 0.36419514 0.42203887 0.48339894 0.48385569 0.50652647\n",
      " 0.50996214 0.53393976 0.46019461 0.48752399 0.54439596 0.54169895\n",
      "        nan        nan        nan        nan 0.39607067 0.39053022\n",
      " 0.39319975 0.37548271 0.33785501 0.36419514 0.42203887 0.48339894\n",
      " 0.48385569 0.50652647 0.50996214 0.53393976 0.46019461 0.48752399\n",
      " 0.54439596 0.54169895        nan        nan        nan        nan\n",
      " 0.40498362 0.41051147 0.38512119 0.4468356  0.33605435 0.35134368\n",
      " 0.39597324 0.42675869 0.49466124 0.51064104 0.5213476  0.52002583\n",
      " 0.46154465 0.51641991 0.54781883 0.54542147        nan        nan\n",
      "        nan        nan 0.40498362 0.41051147 0.38512119 0.4468356\n",
      " 0.33605435 0.35134368 0.39597324 0.42675869 0.49466124 0.51064104\n",
      " 0.5213476  0.52002583 0.46154465 0.51641991 0.54781883 0.54542147\n",
      "        nan        nan        nan        nan 0.41800659 0.41748862\n",
      " 0.41055295 0.42281854 0.32975353 0.34335407 0.38536618 0.40218374\n",
      " 0.46064817 0.47908869 0.48435404 0.4974437  0.44483558 0.49338823\n",
      " 0.54767321 0.5426454         nan        nan        nan        nan\n",
      " 0.41800659 0.41748862 0.41055295 0.42281854 0.32975353 0.34335407\n",
      " 0.38536618 0.40218374 0.46064817 0.47908869 0.48435404 0.4974437\n",
      " 0.44483558 0.49338823 0.54767321 0.5426454         nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 346.254s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=0.1, class_weight='balanced', kernel='sigmoid',\n",
      "                     max_iter=1000, probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.4081289081289081 Best GS Acc: 0.555437753914761 Best Params: {'classification__C': 0.1, 'classification__gamma': 'scale', 'classification__kernel': 'sigmoid', 'classification__max_iter': 1000}\n",
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.26149425 0.26149425 0.26149425 0.49839116 0.26284257 0.26284257\n",
      " 0.2641909  0.26642199 0.2876824  0.26149425 0.26149425 0.26149425\n",
      " 0.26149425 0.26149425 0.26149425 0.26149425        nan        nan\n",
      "        nan        nan 0.26149425 0.26149425 0.26149425 0.49839116\n",
      " 0.26284257 0.26284257 0.2641909  0.26642199 0.2876824  0.26149425\n",
      " 0.26149425 0.26149425 0.26149425 0.26149425 0.26149425 0.26149425\n",
      "        nan        nan        nan        nan 0.26638261 0.262409\n",
      " 0.26732643 0.53673788 0.26732139 0.26952696 0.30320095 0.36692044\n",
      " 0.2876824  0.26149425 0.26149425 0.26149425 0.26149425 0.26149425\n",
      " 0.26149425 0.2663519         nan        nan        nan        nan\n",
      " 0.26638261 0.262409   0.26732643 0.53673788 0.26732139 0.26952696\n",
      " 0.30320095 0.36692044 0.2876824  0.26149425 0.26149425 0.26149425\n",
      " 0.26149425 0.26149425 0.26149425 0.2663519         nan        nan\n",
      "        nan        nan 0.31899231 0.35490857 0.36626151 0.53091971\n",
      " 0.29635029 0.3092734  0.31335035 0.44672148 0.31387055 0.30873989\n",
      " 0.26149425 0.52858639 0.26284257 0.27031119 0.31515337 0.51133714\n",
      "        nan        nan        nan        nan 0.31899231 0.35490857\n",
      " 0.36626151 0.53091971 0.29635029 0.3092734  0.31335035 0.44672148\n",
      " 0.31387055 0.30873989 0.26149425 0.52858639 0.26284257 0.27031119\n",
      " 0.31515337 0.51133714        nan        nan        nan        nan\n",
      " 0.43336656 0.41486764 0.37497785 0.39466724 0.31880174 0.32883719\n",
      " 0.33634657 0.44732401 0.42987904 0.42790302 0.39675473 0.54406591\n",
      " 0.42240744 0.44344404 0.48344533 0.50319304        nan        nan\n",
      "        nan        nan 0.43336656 0.41486764 0.37497785 0.39466724\n",
      " 0.31880174 0.32883719 0.33634657 0.44732401 0.42987904 0.42790302\n",
      " 0.39675473 0.54406591 0.42240744 0.44344404 0.48344533 0.50319304\n",
      "        nan        nan        nan        nan 0.43286946 0.3827938\n",
      " 0.41729668 0.41408343 0.34030432 0.34761744 0.37924065 0.42208111\n",
      " 0.51013039 0.51603785 0.52873648 0.53549066 0.41532096 0.46058363\n",
      " 0.5028212  0.5096251         nan        nan        nan        nan\n",
      " 0.43286946 0.3827938  0.41729668 0.41408343 0.34030432 0.34761744\n",
      " 0.37924065 0.42208111 0.51013039 0.51603785 0.52873648 0.53549066\n",
      " 0.41532096 0.46058363 0.5028212  0.5096251         nan        nan\n",
      "        nan        nan 0.37329382 0.44616825 0.43000446 0.41106589\n",
      " 0.34263042 0.3587824  0.39174741 0.41432097 0.52368748 0.52624114\n",
      " 0.51917527 0.52603371 0.43015668 0.46847576 0.50155698 0.50236835\n",
      "        nan        nan        nan        nan 0.37329382 0.44616825\n",
      " 0.43000446 0.41106589 0.34263042 0.3587824  0.39174741 0.41432097\n",
      " 0.52368748 0.52624114 0.51917527 0.52603371 0.43015668 0.46847576\n",
      " 0.50155698 0.50236835        nan        nan        nan        nan\n",
      " 0.42051454 0.46873537 0.43525238 0.41049487 0.33836667 0.33600324\n",
      " 0.40485963 0.42691816 0.52857702 0.5251118  0.51700257 0.52490348\n",
      " 0.43454552 0.46365319 0.50066859 0.49698531        nan        nan\n",
      "        nan        nan 0.42051454 0.46873537 0.43525238 0.41049487\n",
      " 0.33836667 0.33600324 0.40485963 0.42691816 0.52857702 0.5251118\n",
      " 0.51700257 0.52490348 0.43454552 0.46365319 0.50066859 0.49698531\n",
      "        nan        nan        nan        nan 0.41011395 0.46239022\n",
      " 0.44880118 0.41770178 0.34232658 0.32774816 0.39619306 0.430911\n",
      " 0.52701021 0.52578329 0.51270182 0.5265778  0.45446975 0.47655315\n",
      " 0.50081618 0.4991904         nan        nan        nan        nan\n",
      " 0.41011395 0.46239022 0.44880118 0.41770178 0.34232658 0.32774816\n",
      " 0.39619306 0.430911   0.52701021 0.52578329 0.51270182 0.5265778\n",
      " 0.45446975 0.47655315 0.50081618 0.4991904         nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 345.558s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=1, class_weight='balanced', max_iter=1000,\n",
      "                     probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.55511998099311 Best GS Acc: 0.5440659146627036 Best Params: {'classification__C': 1, 'classification__gamma': 'scale', 'classification__kernel': 'rbf', 'classification__max_iter': 1000}\n",
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.26149425 0.26149425 0.26284257 0.51678627 0.26375732 0.26776239\n",
      " 0.34097344 0.3291641  0.31387055 0.36624684 0.32006852 0.26149425\n",
      " 0.26149425 0.26149425 0.26149425 0.26149425        nan        nan\n",
      "        nan        nan 0.26149425 0.26149425 0.26284257 0.51678627\n",
      " 0.26375732 0.26776239 0.34097344 0.3291641  0.31387055 0.36624684\n",
      " 0.32006852 0.26149425 0.26149425 0.26149425 0.26149425 0.26149425\n",
      "        nan        nan        nan        nan 0.26332375 0.2673156\n",
      " 0.26944966 0.554909   0.27263171 0.27645263 0.36439963 0.4162776\n",
      " 0.34005869 0.31387055 0.3242721  0.26149425 0.26149425 0.26149425\n",
      " 0.26149425 0.26241692        nan        nan        nan        nan\n",
      " 0.26332375 0.2673156  0.26944966 0.554909   0.27263171 0.27645263\n",
      " 0.36439963 0.4162776  0.34005869 0.31387055 0.3242721  0.26149425\n",
      " 0.26149425 0.26149425 0.26149425 0.26241692        nan        nan\n",
      "        nan        nan 0.2966652  0.29851149 0.35761903 0.54169274\n",
      " 0.28253193 0.30497892 0.33519024 0.4319622  0.31387055 0.34005869\n",
      " 0.33781008 0.54488555 0.2663519  0.27045102 0.28255318 0.54741188\n",
      "        nan        nan        nan        nan 0.2966652  0.29851149\n",
      " 0.35761903 0.54169274 0.28253193 0.30497892 0.33519024 0.4319622\n",
      " 0.31387055 0.34005869 0.33781008 0.54488555 0.2663519  0.27045102\n",
      " 0.28255318 0.54741188        nan        nan        nan        nan\n",
      " 0.39025245 0.43723222 0.36982808 0.38387263 0.31563819 0.333904\n",
      " 0.34749035 0.46030647 0.42388475 0.4553527  0.4731616  0.57273615\n",
      " 0.44026553 0.41162898 0.48877813 0.52623112        nan        nan\n",
      "        nan        nan 0.39025245 0.43723222 0.36982808 0.38387263\n",
      " 0.31563819 0.333904   0.34749035 0.46030647 0.42388475 0.4553527\n",
      " 0.4731616  0.57273615 0.44026553 0.41162898 0.48877813 0.52623112\n",
      "        nan        nan        nan        nan 0.44882427 0.41386983\n",
      " 0.39137996 0.40288397 0.3324016  0.33928288 0.35354962 0.46544257\n",
      " 0.4577282  0.48470893 0.52583991 0.55774071 0.44281142 0.45766653\n",
      " 0.51532545 0.5218768         nan        nan        nan        nan\n",
      " 0.44882427 0.41386983 0.39137996 0.40288397 0.3324016  0.33928288\n",
      " 0.35354962 0.46544257 0.4577282  0.48470893 0.52583991 0.55774071\n",
      " 0.44281142 0.45766653 0.51532545 0.5218768         nan        nan\n",
      "        nan        nan 0.4332551  0.43274289 0.38824322 0.42424191\n",
      " 0.32700358 0.35689027 0.38658208 0.43242848 0.4798152  0.48372958\n",
      " 0.50533283 0.52023822 0.45941282 0.47928125 0.52500075 0.51777664\n",
      "        nan        nan        nan        nan 0.4332551  0.43274289\n",
      " 0.38824322 0.42424191 0.32700358 0.35689027 0.38658208 0.43242848\n",
      " 0.4798152  0.48372958 0.50533283 0.52023822 0.45941282 0.47928125\n",
      " 0.52500075 0.51777664        nan        nan        nan        nan\n",
      " 0.42727346 0.40764679 0.38906577 0.41231309 0.36983977 0.35709352\n",
      " 0.43435694 0.39872945 0.49060329 0.48412608 0.50858635 0.50137489\n",
      " 0.45876308 0.44462397 0.50621953 0.51292567        nan        nan\n",
      "        nan        nan 0.42727346 0.40764679 0.38906577 0.41231309\n",
      " 0.36983977 0.35709352 0.43435694 0.39872945 0.49060329 0.48412608\n",
      " 0.50858635 0.50137489 0.45876308 0.44462397 0.50621953 0.51292567\n",
      "        nan        nan        nan        nan 0.42727346 0.40922565\n",
      " 0.40825221 0.4239425  0.34696833 0.34490024 0.39279861 0.42428993\n",
      " 0.48503889 0.48591279 0.49333824 0.48521662 0.4444009  0.45031162\n",
      " 0.5130774  0.51273403        nan        nan        nan        nan\n",
      " 0.42727346 0.40922565 0.40825221 0.4239425  0.34696833 0.34490024\n",
      " 0.39279861 0.42428993 0.48503889 0.48591279 0.49333824 0.48521662\n",
      " 0.4444009  0.45031162 0.5130774  0.51273403        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 345.970s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=1, class_weight='balanced', max_iter=1000,\n",
      "                     probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5832612082395707 Best GS Acc: 0.5727361513018681 Best Params: {'classification__C': 1, 'classification__gamma': 'scale', 'classification__kernel': 'rbf', 'classification__max_iter': 1000}\n",
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.26191747 0.26191747 0.26191747 0.54733662 0.26326579 0.26462211\n",
      " 0.34932759 0.38467871 0.3601566  0.3135826  0.28739445 0.26191747\n",
      " 0.26191747 0.26191747 0.26191747 0.26191747        nan        nan\n",
      "        nan        nan 0.26191747 0.26191747 0.26191747 0.54733662\n",
      " 0.26326579 0.26462211 0.34932759 0.38467871 0.3601566  0.3135826\n",
      " 0.28739445 0.26191747 0.26191747 0.26191747 0.26191747 0.26191747\n",
      "        nan        nan        nan        nan 0.26462211 0.26462211\n",
      " 0.29520873 0.54705102 0.26510564 0.27835573 0.3965789  0.41737424\n",
      " 0.3601566  0.3135826  0.28739445 0.26191747 0.26191747 0.26191747\n",
      " 0.26191747 0.2789597         nan        nan        nan        nan\n",
      " 0.26462211 0.26462211 0.29520873 0.54705102 0.26510564 0.27835573\n",
      " 0.3965789  0.41737424 0.3601566  0.3135826  0.28739445 0.26191747\n",
      " 0.26191747 0.26191747 0.26191747 0.2789597         nan        nan\n",
      "        nan        nan 0.3000984  0.32410008 0.42224638 0.54245161\n",
      " 0.2817317  0.30241965 0.38620697 0.44471286 0.36194062 0.43922621\n",
      " 0.28739445 0.53345628 0.26460072 0.2668452  0.27483479 0.54354055\n",
      "        nan        nan        nan        nan 0.3000984  0.32410008\n",
      " 0.42224638 0.54245161 0.2817317  0.30241965 0.38620697 0.44471286\n",
      " 0.36194062 0.43922621 0.28739445 0.53345628 0.26460072 0.2668452\n",
      " 0.27483479 0.54354055        nan        nan        nan        nan\n",
      " 0.40036269 0.39225341 0.38494245 0.39207849 0.30826417 0.33036794\n",
      " 0.36088853 0.50333306 0.451904   0.49154276 0.54116749 0.53968027\n",
      " 0.40081553 0.38297829 0.47609194 0.51795934        nan        nan\n",
      "        nan        nan 0.40036269 0.39225341 0.38494245 0.39207849\n",
      " 0.30826417 0.33036794 0.36088853 0.50333306 0.451904   0.49154276\n",
      " 0.54116749 0.53968027 0.40081553 0.38297829 0.47609194 0.51795934\n",
      "        nan        nan        nan        nan 0.38793374 0.41301387\n",
      " 0.38285589 0.37015242 0.33439642 0.34671734 0.37618709 0.51770923\n",
      " 0.48503651 0.49599552 0.53494549 0.54995454 0.47164112 0.46431025\n",
      " 0.50515883 0.5103403         nan        nan        nan        nan\n",
      " 0.38793374 0.41301387 0.38285589 0.37015242 0.33439642 0.34671734\n",
      " 0.37618709 0.51770923 0.48503651 0.49599552 0.53494549 0.54995454\n",
      " 0.47164112 0.46431025 0.50515883 0.5103403         nan        nan\n",
      "        nan        nan 0.40899654 0.38222855 0.39261494 0.38250319\n",
      " 0.33677899 0.34479951 0.39136519 0.44546926 0.50136031 0.490642\n",
      " 0.50259904 0.51258898 0.44408791 0.45755396 0.515447   0.52003255\n",
      "        nan        nan        nan        nan 0.40899654 0.38222855\n",
      " 0.39261494 0.38250319 0.33677899 0.34479951 0.39136519 0.44546926\n",
      " 0.50136031 0.490642   0.50259904 0.51258898 0.44408791 0.45755396\n",
      " 0.515447   0.52003255        nan        nan        nan        nan\n",
      " 0.40777087 0.40321254 0.37131311 0.4134297  0.34501922 0.35314865\n",
      " 0.39951259 0.44416726 0.50394114 0.50579435 0.5168607  0.51376747\n",
      " 0.46499352 0.50560973 0.51717718 0.52095554        nan        nan\n",
      "        nan        nan 0.40777087 0.40321254 0.37131311 0.4134297\n",
      " 0.34501922 0.35314865 0.39951259 0.44416726 0.50394114 0.50579435\n",
      " 0.5168607  0.51376747 0.46499352 0.50560973 0.51717718 0.52095554\n",
      "        nan        nan        nan        nan 0.39535487 0.40457619\n",
      " 0.37980506 0.35798567 0.35414301 0.36074521 0.38980476 0.42978685\n",
      " 0.48738599 0.50845958 0.54069855 0.51884245 0.4527156  0.47964954\n",
      " 0.50512061 0.5212134         nan        nan        nan        nan\n",
      " 0.39535487 0.40457619 0.37980506 0.35798567 0.35414301 0.36074521\n",
      " 0.38980476 0.42978685 0.48738599 0.50845958 0.54069855 0.51884245\n",
      " 0.4527156  0.47964954 0.50512061 0.5212134         nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 342.124s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=10, class_weight='balanced', max_iter=1000,\n",
      "                     probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5209331552902364 Best GS Acc: 0.549954536361018 Best Params: {'classification__C': 10, 'classification__gamma': 'scale', 'classification__kernel': 'rbf', 'classification__max_iter': 1000}\n",
      "Average f1 macro score:  0.5325507766325781\n",
      "\n",
      "Trait to predict:  extraversion \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81fcf231d029433e9304d95f59b7c763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.30368799 0.30368799 0.30368799 0.58083204 0.30368799 0.30368799\n",
      " 0.32890696 0.35390198 0.34668313 0.30368799 0.30368799 0.31512269\n",
      " 0.30368799 0.30368799 0.30368799 0.30368799        nan        nan\n",
      "        nan        nan 0.30368799 0.30368799 0.30368799 0.58083204\n",
      " 0.30368799 0.30368799 0.32890696 0.35390198 0.34668313 0.30368799\n",
      " 0.30368799 0.31512269 0.30368799 0.30368799 0.30368799 0.30368799\n",
      "        nan        nan        nan        nan 0.30330947 0.30368799\n",
      " 0.35652408 0.57670571 0.30863268 0.3101675  0.35876727 0.43758087\n",
      " 0.33524843 0.30368799 0.30368799 0.31572235 0.30368799 0.30368799\n",
      " 0.30368799 0.40467979        nan        nan        nan        nan\n",
      " 0.30330947 0.30368799 0.35652408 0.57670571 0.30863268 0.3101675\n",
      " 0.35876727 0.43758087 0.33524843 0.30368799 0.30368799 0.31572235\n",
      " 0.30368799 0.30368799 0.30368799 0.40467979        nan        nan\n",
      "        nan        nan 0.34766402 0.35607894 0.43573449 0.56101335\n",
      " 0.3253392  0.33656468 0.39077293 0.46447372 0.38510683 0.34453562\n",
      " 0.30522281 0.57190821 0.32655761 0.30284799 0.31107393 0.57181278\n",
      "        nan        nan        nan        nan 0.34766402 0.35607894\n",
      " 0.43573449 0.56101335 0.3253392  0.33656468 0.39077293 0.46447372\n",
      " 0.38510683 0.34453562 0.30522281 0.57190821 0.32655761 0.30284799\n",
      " 0.31107393 0.57181278        nan        nan        nan        nan\n",
      " 0.44634691 0.4264568  0.42975504 0.45677024 0.36005691 0.37497724\n",
      " 0.38539247 0.52496985 0.42737731 0.42308    0.41491242 0.57155398\n",
      " 0.49473657 0.50130532 0.53731692 0.54498433        nan        nan\n",
      "        nan        nan 0.44634691 0.4264568  0.42975504 0.45677024\n",
      " 0.36005691 0.37497724 0.38539247 0.52496985 0.42737731 0.42308\n",
      " 0.41491242 0.57155398 0.49473657 0.50130532 0.53731692 0.54498433\n",
      "        nan        nan        nan        nan 0.43765955 0.44463119\n",
      " 0.40624641 0.40568871 0.35909052 0.38763006 0.39063122 0.48836702\n",
      " 0.50672709 0.50227064 0.54051598 0.56560818 0.4864216  0.48410621\n",
      " 0.52787097 0.52938393        nan        nan        nan        nan\n",
      " 0.43765955 0.44463119 0.40624641 0.40568871 0.35909052 0.38763006\n",
      " 0.39063122 0.48836702 0.50672709 0.50227064 0.54051598 0.56560818\n",
      " 0.4864216  0.48410621 0.52787097 0.52938393        nan        nan\n",
      "        nan        nan 0.45232367 0.47326792 0.45277378 0.44338679\n",
      " 0.36587669 0.37729472 0.41063194 0.44019961 0.47158442 0.51088109\n",
      " 0.50315217 0.52029952 0.5253826  0.50251044 0.54013404 0.54021494\n",
      "        nan        nan        nan        nan 0.45232367 0.47326792\n",
      " 0.45277378 0.44338679 0.36587669 0.37729472 0.41063194 0.44019961\n",
      " 0.47158442 0.51088109 0.50315217 0.52029952 0.5253826  0.50251044\n",
      " 0.54013404 0.54021494        nan        nan        nan        nan\n",
      " 0.44798473 0.46546712 0.46162401 0.4168765  0.35679742 0.37793736\n",
      " 0.40048234 0.45208535 0.47158442 0.52157521 0.50495714 0.51900835\n",
      " 0.54859047 0.50804815 0.54548575 0.54164545        nan        nan\n",
      "        nan        nan 0.44798473 0.46546712 0.46162401 0.4168765\n",
      " 0.35679742 0.37793736 0.40048234 0.45208535 0.47158442 0.52157521\n",
      " 0.50495714 0.51900835 0.54859047 0.50804815 0.54548575 0.54164545\n",
      "        nan        nan        nan        nan 0.44798473 0.46546712\n",
      " 0.46162401 0.43541918 0.35510231 0.37339164 0.38076529 0.41993769\n",
      " 0.47158442 0.50876065 0.48826561 0.53055747 0.53928449 0.50466641\n",
      " 0.54121339 0.54147574        nan        nan        nan        nan\n",
      " 0.44798473 0.46546712 0.46162401 0.43541918 0.35510231 0.37339164\n",
      " 0.38076529 0.41993769 0.47158442 0.50876065 0.48826561 0.53055747\n",
      " 0.53928449 0.50466641 0.54121339 0.54147574        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 343.187s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=0.001, class_weight='balanced', kernel='linear',\n",
      "                     max_iter=1000, probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.35821305841924395 Best GS Acc: 0.5808320422488507 Best Params: {'classification__C': 0.001, 'classification__gamma': 'scale', 'classification__kernel': 'linear', 'classification__max_iter': 1000}\n",
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.30389951 0.30389951 0.30389951 0.58006777 0.30389951 0.30389951\n",
      " 0.3279153  0.38550409 0.3267689  0.3267689  0.30389951 0.35639\n",
      " 0.30389951 0.30389951 0.30389951 0.30389951        nan        nan\n",
      "        nan        nan 0.30389951 0.30389951 0.30389951 0.58006777\n",
      " 0.30389951 0.30389951 0.3279153  0.38550409 0.3267689  0.3267689\n",
      " 0.30389951 0.35639    0.30389951 0.30389951 0.30389951 0.30389951\n",
      "        nan        nan        nan        nan 0.30389951 0.30389951\n",
      " 0.3406978  0.5734761  0.30544435 0.30963301 0.34960592 0.42676929\n",
      " 0.3267689  0.3267689  0.30389951 0.39531518 0.30389951 0.30389951\n",
      " 0.30389951 0.38457407        nan        nan        nan        nan\n",
      " 0.30389951 0.30389951 0.3406978  0.5734761  0.30544435 0.30963301\n",
      " 0.34960592 0.42676929 0.3267689  0.3267689  0.30389951 0.39531518\n",
      " 0.30389951 0.30389951 0.30389951 0.38457407        nan        nan\n",
      "        nan        nan 0.36492327 0.35561575 0.38246844 0.54587208\n",
      " 0.32292538 0.33370521 0.3624214  0.46798037 0.3278545  0.38308118\n",
      " 0.35205669 0.56792526 0.38829515 0.30445859 0.312093   0.55940402\n",
      "        nan        nan        nan        nan 0.36492327 0.35561575\n",
      " 0.38246844 0.54587208 0.32292538 0.33370521 0.3624214  0.46798037\n",
      " 0.3278545  0.38308118 0.35205669 0.56792526 0.38829515 0.30445859\n",
      " 0.312093   0.55940402        nan        nan        nan        nan\n",
      " 0.41065248 0.42235843 0.38064739 0.41452476 0.35621189 0.37311956\n",
      " 0.37981845 0.52316903 0.43705129 0.44757051 0.44572528 0.56853357\n",
      " 0.53356061 0.50142021 0.52394713 0.53864773        nan        nan\n",
      "        nan        nan 0.41065248 0.42235843 0.38064739 0.41452476\n",
      " 0.35621189 0.37311956 0.37981845 0.52316903 0.43705129 0.44757051\n",
      " 0.44572528 0.56853357 0.53356061 0.50142021 0.52394713 0.53864773\n",
      "        nan        nan        nan        nan 0.40045123 0.44723083\n",
      " 0.3952627  0.38067341 0.3593198  0.37903697 0.39348263 0.44886749\n",
      " 0.49295693 0.48603952 0.53771409 0.54254293 0.53476076 0.5151644\n",
      " 0.53557697 0.53716744        nan        nan        nan        nan\n",
      " 0.40045123 0.44723083 0.3952627  0.38067341 0.3593198  0.37903697\n",
      " 0.39348263 0.44886749 0.49295693 0.48603952 0.53771409 0.54254293\n",
      " 0.53476076 0.5151644  0.53557697 0.53716744        nan        nan\n",
      "        nan        nan 0.39912841 0.41875416 0.38523747 0.40150265\n",
      " 0.37246115 0.38454281 0.41836936 0.42670954 0.45705944 0.4900186\n",
      " 0.4830114  0.52765401 0.5191889  0.5153872  0.53250639 0.5383739\n",
      "        nan        nan        nan        nan 0.39912841 0.41875416\n",
      " 0.38523747 0.40150265 0.37246115 0.38454281 0.41836936 0.42670954\n",
      " 0.45705944 0.4900186  0.4830114  0.52765401 0.5191889  0.5153872\n",
      " 0.53250639 0.5383739         nan        nan        nan        nan\n",
      " 0.39912841 0.41875416 0.38523747 0.41103635 0.36013105 0.37430934\n",
      " 0.37602293 0.39501711 0.45705944 0.48684743 0.4765836  0.48807287\n",
      " 0.53372755 0.50096672 0.53592989 0.53695267        nan        nan\n",
      "        nan        nan 0.39912841 0.41875416 0.38523747 0.41103635\n",
      " 0.36013105 0.37430934 0.37602293 0.39501711 0.45705944 0.48684743\n",
      " 0.4765836  0.48807287 0.53372755 0.50096672 0.53592989 0.53695267\n",
      "        nan        nan        nan        nan 0.39912841 0.41875416\n",
      " 0.38523747 0.41103635 0.36063343 0.37610614 0.38407235 0.40479425\n",
      " 0.45705944 0.48684743 0.46846633 0.48486663 0.53747645 0.50876566\n",
      " 0.5376622  0.5369323         nan        nan        nan        nan\n",
      " 0.39912841 0.41875416 0.38523747 0.41103635 0.36063343 0.37610614\n",
      " 0.38407235 0.40479425 0.45705944 0.48684743 0.46846633 0.48486663\n",
      " 0.53747645 0.50876566 0.5376622  0.5369323         nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 340.430s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=0.001, class_weight='balanced', kernel='linear',\n",
      "                     max_iter=1000, probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.3681674208144797 Best GS Acc: 0.5800677704665587 Best Params: {'classification__C': 0.001, 'classification__gamma': 'scale', 'classification__kernel': 'linear', 'classification__max_iter': 1000}\n",
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.30389951 0.30389951 0.30389951 0.57647688 0.30389951 0.30389951\n",
      " 0.30768826 0.35597662 0.33109836 0.34183491 0.30389951 0.34845774\n",
      " 0.30389951 0.30389951 0.30389951 0.30389951        nan        nan\n",
      "        nan        nan 0.30389951 0.30389951 0.30389951 0.57647688\n",
      " 0.30389951 0.30389951 0.30768826 0.35597662 0.33109836 0.34183491\n",
      " 0.30389951 0.34845774 0.30389951 0.30389951 0.30389951 0.30389951\n",
      "        nan        nan        nan        nan 0.30848623 0.31002106\n",
      " 0.34854944 0.55835943 0.31268454 0.31681071 0.321869   0.45741519\n",
      " 0.31680717 0.31533421 0.30389951 0.34514279 0.30389951 0.30389951\n",
      " 0.30389951 0.38332669        nan        nan        nan        nan\n",
      " 0.30848623 0.31002106 0.34854944 0.55835943 0.31268454 0.31681071\n",
      " 0.321869   0.45741519 0.31680717 0.31533421 0.30389951 0.34514279\n",
      " 0.30389951 0.30389951 0.30389951 0.38332669        nan        nan\n",
      "        nan        nan 0.33251034 0.35655352 0.42926992 0.55134885\n",
      " 0.33269247 0.33948344 0.35542805 0.4641246  0.32782224 0.34711025\n",
      " 0.34882573 0.55205409 0.36215077 0.30385023 0.31042932 0.55644455\n",
      "        nan        nan        nan        nan 0.33251034 0.35655352\n",
      " 0.42926992 0.55134885 0.33269247 0.33948344 0.35542805 0.4641246\n",
      " 0.32782224 0.34711025 0.34882573 0.55205409 0.36215077 0.30385023\n",
      " 0.31042932 0.55644455        nan        nan        nan        nan\n",
      " 0.40783323 0.42335597 0.40098149 0.40743955 0.35044565 0.36480153\n",
      " 0.37794989 0.49605374 0.44689596 0.45839801 0.43530632 0.56255289\n",
      " 0.49404764 0.49588156 0.52248411 0.54277348        nan        nan\n",
      "        nan        nan 0.40783323 0.42335597 0.40098149 0.40743955\n",
      " 0.35044565 0.36480153 0.37794989 0.49605374 0.44689596 0.45839801\n",
      " 0.43530632 0.56255289 0.49404764 0.49588156 0.52248411 0.54277348\n",
      "        nan        nan        nan        nan 0.417285   0.41426386\n",
      " 0.44977253 0.38964614 0.36691711 0.38801145 0.38989832 0.46893895\n",
      " 0.4888786  0.50125753 0.53324256 0.55277599 0.53216642 0.51553724\n",
      " 0.53532289 0.5374798         nan        nan        nan        nan\n",
      " 0.417285   0.41426386 0.44977253 0.38964614 0.36691711 0.38801145\n",
      " 0.38989832 0.46893895 0.4888786  0.50125753 0.53324256 0.55277599\n",
      " 0.53216642 0.51553724 0.53532289 0.5374798         nan        nan\n",
      "        nan        nan 0.4454149  0.42074402 0.42786762 0.39648771\n",
      " 0.37852389 0.38586446 0.40393596 0.43176941 0.45896558 0.48353731\n",
      " 0.4936382  0.49379078 0.5224178  0.50243561 0.53696498 0.53286175\n",
      "        nan        nan        nan        nan 0.4454149  0.42074402\n",
      " 0.42786762 0.39648771 0.37852389 0.38586446 0.40393596 0.43176941\n",
      " 0.45896558 0.48353731 0.4936382  0.49379078 0.5224178  0.50243561\n",
      " 0.53696498 0.53286175        nan        nan        nan        nan\n",
      " 0.449658   0.47190768 0.47048189 0.40450125 0.3785403  0.39443587\n",
      " 0.41134106 0.432226   0.48186061 0.50259134 0.49108541 0.51380669\n",
      " 0.53653937 0.52609839 0.54797962 0.54613196        nan        nan\n",
      "        nan        nan 0.449658   0.47190768 0.47048189 0.40450125\n",
      " 0.3785403  0.39443587 0.41134106 0.432226   0.48186061 0.50259134\n",
      " 0.49108541 0.51380669 0.53653937 0.52609839 0.54797962 0.54613196\n",
      "        nan        nan        nan        nan 0.449658   0.47190768\n",
      " 0.48758237 0.45185429 0.38357142 0.38819851 0.41097082 0.42037868\n",
      " 0.48186061 0.50259134 0.49108541 0.51380669 0.53208073 0.52831734\n",
      " 0.54549414 0.54208043        nan        nan        nan        nan\n",
      " 0.449658   0.47190768 0.48758237 0.45185429 0.38357142 0.38819851\n",
      " 0.41097082 0.42037868 0.48186061 0.50259134 0.49108541 0.51380669\n",
      " 0.53208073 0.52831734 0.54549414 0.54208043        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 345.292s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=0.001, class_weight='balanced', kernel='linear',\n",
      "                     max_iter=1000, probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.3421518397764322 Best GS Acc: 0.5764768794706159 Best Params: {'classification__C': 0.001, 'classification__gamma': 'scale', 'classification__kernel': 'linear', 'classification__max_iter': 1000}\n",
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.30389951 0.30389951 0.30389951 0.56878633 0.30389951 0.30389951\n",
      " 0.31802737 0.39645713 0.31533421 0.31463888 0.30389951 0.35181721\n",
      " 0.30389951 0.30389951 0.30389951 0.30389951        nan        nan\n",
      "        nan        nan 0.30389951 0.30389951 0.30389951 0.56878633\n",
      " 0.30389951 0.30389951 0.31802737 0.39645713 0.31533421 0.31463888\n",
      " 0.30389951 0.35181721 0.30389951 0.30389951 0.30389951 0.30389951\n",
      "        nan        nan        nan        nan 0.30389951 0.30389951\n",
      " 0.33750045 0.57057814 0.30698204 0.30698204 0.32026612 0.42525803\n",
      " 0.31533421 0.31463888 0.30389951 0.34052738 0.30389951 0.30389951\n",
      " 0.30389951 0.33103533        nan        nan        nan        nan\n",
      " 0.30389951 0.30389951 0.33750045 0.57057814 0.30698204 0.30698204\n",
      " 0.32026612 0.42525803 0.31533421 0.31463888 0.30389951 0.34052738\n",
      " 0.30389951 0.30389951 0.30389951 0.33103533        nan        nan\n",
      "        nan        nan 0.33144642 0.3288793  0.40663844 0.56942232\n",
      " 0.31310977 0.31733659 0.36471307 0.45018153 0.3494407  0.34282917\n",
      " 0.30389951 0.57499704 0.30687947 0.30508245 0.30638677 0.56020912\n",
      "        nan        nan        nan        nan 0.33144642 0.3288793\n",
      " 0.40663844 0.56942232 0.31310977 0.31733659 0.36471307 0.45018153\n",
      " 0.3494407  0.34282917 0.30389951 0.57499704 0.30687947 0.30508245\n",
      " 0.30638677 0.56020912        nan        nan        nan        nan\n",
      " 0.43306399 0.42518355 0.4007633  0.43577355 0.33876823 0.35022965\n",
      " 0.36822334 0.49201437 0.46208053 0.45719237 0.41699245 0.57615109\n",
      " 0.43975947 0.43925691 0.50799577 0.53286227        nan        nan\n",
      "        nan        nan 0.43306399 0.42518355 0.4007633  0.43577355\n",
      " 0.33876823 0.35022965 0.36822334 0.49201437 0.46208053 0.45719237\n",
      " 0.41699245 0.57615109 0.43975947 0.43925691 0.50799577 0.53286227\n",
      "        nan        nan        nan        nan 0.4399965  0.42714444\n",
      " 0.38226419 0.39862341 0.35793733 0.37324979 0.38257937 0.47328363\n",
      " 0.49718326 0.52848249 0.51845376 0.55077879 0.44271562 0.49133905\n",
      " 0.53638244 0.53110915        nan        nan        nan        nan\n",
      " 0.4399965  0.42714444 0.38226419 0.39862341 0.35793733 0.37324979\n",
      " 0.38257937 0.47328363 0.49718326 0.52848249 0.51845376 0.55077879\n",
      " 0.44271562 0.49133905 0.53638244 0.53110915        nan        nan\n",
      "        nan        nan 0.4399965  0.41829729 0.40372079 0.41122156\n",
      " 0.34507813 0.36732749 0.41377795 0.43128301 0.47359349 0.46436618\n",
      " 0.51793301 0.50945546 0.5069218  0.49730131 0.52189293 0.52496947\n",
      "        nan        nan        nan        nan 0.4399965  0.41829729\n",
      " 0.40372079 0.41122156 0.34507813 0.36732749 0.41377795 0.43128301\n",
      " 0.47359349 0.46436618 0.51793301 0.50945546 0.5069218  0.49730131\n",
      " 0.52189293 0.52496947        nan        nan        nan        nan\n",
      " 0.4399965  0.40162455 0.43025731 0.40727363 0.34442653 0.37811577\n",
      " 0.41735161 0.44251484 0.47359349 0.47638363 0.49442332 0.49988713\n",
      " 0.50946458 0.4927528  0.53572571 0.53103855        nan        nan\n",
      "        nan        nan 0.4399965  0.40162455 0.43025731 0.40727363\n",
      " 0.34442653 0.37811577 0.41735161 0.44251484 0.47359349 0.47638363\n",
      " 0.49442332 0.49988713 0.50946458 0.4927528  0.53572571 0.53103855\n",
      "        nan        nan        nan        nan 0.4399965  0.40533225\n",
      " 0.42297914 0.43093543 0.36500101 0.38983257 0.41082741 0.44566926\n",
      " 0.47359349 0.46850344 0.50969625 0.50886214 0.52695686 0.4895492\n",
      " 0.5227146  0.52879863        nan        nan        nan        nan\n",
      " 0.4399965  0.40533225 0.42297914 0.43093543 0.36500101 0.38983257\n",
      " 0.41082741 0.44566926 0.47359349 0.46850344 0.50969625 0.50886214\n",
      " 0.52695686 0.4895492  0.5227146  0.52879863        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 347.479s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=1, class_weight='balanced', max_iter=1000,\n",
      "                     probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.6289380877742947 Best GS Acc: 0.5761510944225849 Best Params: {'classification__C': 1, 'classification__gamma': 'scale', 'classification__kernel': 'rbf', 'classification__max_iter': 1000}\n",
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.30389951 0.30389951 0.30389951 0.56938252 0.30389951 0.30389951\n",
      " 0.33750827 0.37564896 0.30389951 0.31533421 0.30389951 0.31533421\n",
      " 0.30389951 0.30389951 0.30389951 0.30389951        nan        nan\n",
      "        nan        nan 0.30389951 0.30389951 0.30389951 0.56938252\n",
      " 0.30389951 0.30389951 0.33750827 0.37564896 0.30389951 0.31533421\n",
      " 0.30389951 0.31533421 0.30389951 0.30389951 0.30389951 0.30389951\n",
      "        nan        nan        nan        nan 0.30389951 0.30389951\n",
      " 0.32541298 0.56960784 0.30389951 0.30389951 0.33969766 0.42506393\n",
      " 0.30389951 0.31533421 0.30389951 0.34263679 0.30389951 0.30389951\n",
      " 0.30389951 0.42787777        nan        nan        nan        nan\n",
      " 0.30389951 0.30389951 0.32541298 0.56960784 0.30389951 0.30389951\n",
      " 0.33969766 0.42506393 0.30389951 0.31533421 0.30389951 0.34263679\n",
      " 0.30389951 0.30389951 0.30389951 0.42787777        nan        nan\n",
      "        nan        nan 0.34176112 0.33711183 0.4200832  0.54913657\n",
      " 0.30347652 0.314544   0.38238972 0.45840182 0.3267689  0.34581367\n",
      " 0.31011866 0.56817234 0.39332477 0.29986181 0.30609014 0.57452655\n",
      "        nan        nan        nan        nan 0.34176112 0.33711183\n",
      " 0.4200832  0.54913657 0.30347652 0.314544   0.38238972 0.45840182\n",
      " 0.3267689  0.34581367 0.31011866 0.56817234 0.39332477 0.29986181\n",
      " 0.30609014 0.57452655        nan        nan        nan        nan\n",
      " 0.44455619 0.41816592 0.42717105 0.3825608  0.3431854  0.3551852\n",
      " 0.37689684 0.50086016 0.44157687 0.46370072 0.43273225 0.56818431\n",
      " 0.49666594 0.50485149 0.53012592 0.53113462        nan        nan\n",
      "        nan        nan 0.44455619 0.41816592 0.42717105 0.3825608\n",
      " 0.3431854  0.3551852  0.37689684 0.50086016 0.44157687 0.46370072\n",
      " 0.43273225 0.56818431 0.49666594 0.50485149 0.53012592 0.53113462\n",
      "        nan        nan        nan        nan 0.49978301 0.40097844\n",
      " 0.45683646 0.42459494 0.34247958 0.35655214 0.39225367 0.4460581\n",
      " 0.45612925 0.48814895 0.51165377 0.53799366 0.52292755 0.5043926\n",
      " 0.52854864 0.53033416        nan        nan        nan        nan\n",
      " 0.49978301 0.40097844 0.45683646 0.42459494 0.34247958 0.35655214\n",
      " 0.39225367 0.4460581  0.45612925 0.48814895 0.51165377 0.53799366\n",
      " 0.52292755 0.5043926  0.52854864 0.53033416        nan        nan\n",
      "        nan        nan 0.47065781 0.41974454 0.41559079 0.44290664\n",
      " 0.36604717 0.35741371 0.38669198 0.40361244 0.45078878 0.47675324\n",
      " 0.47679833 0.49588315 0.51755586 0.50070052 0.52622306 0.53043491\n",
      "        nan        nan        nan        nan 0.47065781 0.41974454\n",
      " 0.41559079 0.44290664 0.36604717 0.35741371 0.38669198 0.40361244\n",
      " 0.45078878 0.47675324 0.47679833 0.49588315 0.51755586 0.50070052\n",
      " 0.52622306 0.53043491        nan        nan        nan        nan\n",
      " 0.47065781 0.41974454 0.42924484 0.45095214 0.343319   0.35601984\n",
      " 0.39113961 0.41448071 0.44512013 0.47064762 0.50609124 0.48419478\n",
      " 0.53091354 0.49899842 0.52525409 0.53191434        nan        nan\n",
      "        nan        nan 0.47065781 0.41974454 0.42924484 0.45095214\n",
      " 0.343319   0.35601984 0.39113961 0.41448071 0.44512013 0.47064762\n",
      " 0.50609124 0.48419478 0.53091354 0.49899842 0.52525409 0.53191434\n",
      "        nan        nan        nan        nan 0.47065781 0.41974454\n",
      " 0.42924484 0.45095214 0.34289952 0.35709206 0.37068028 0.39294259\n",
      " 0.41353647 0.44743459 0.49087958 0.46229768 0.51676363 0.50050778\n",
      " 0.52891824 0.53111608        nan        nan        nan        nan\n",
      " 0.47065781 0.41974454 0.42924484 0.45095214 0.34289952 0.35709206\n",
      " 0.37068028 0.39294259 0.41353647 0.44743459 0.49087958 0.46229768\n",
      " 0.51676363 0.50050778 0.52891824 0.53111608        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 347.609s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=0.1, class_weight='balanced', kernel='sigmoid',\n",
      "                     max_iter=1000, probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5389363354037267 Best GS Acc: 0.574526548009607 Best Params: {'classification__C': 0.1, 'classification__gamma': 'scale', 'classification__kernel': 'sigmoid', 'classification__max_iter': 1000}\n",
      "Average f1 macro score:  0.44728134843763545\n",
      "\n",
      "Trait to predict:  agreeableness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f8f97c78df45d5acb38bf372020b20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.2227583  0.2227583  0.2227583  0.56008705 0.2227583  0.2227583\n",
      " 0.2227583  0.35089447 0.2227583  0.2227583  0.33816478 0.40131431\n",
      " 0.41636346 0.41636346 0.41636346 0.41636346        nan        nan\n",
      "        nan        nan 0.2227583  0.2227583  0.2227583  0.56008705\n",
      " 0.2227583  0.2227583  0.2227583  0.35089447 0.2227583  0.2227583\n",
      " 0.33816478 0.40131431 0.41636346 0.41636346 0.41636346 0.41636346\n",
      "        nan        nan        nan        nan 0.22398075 0.25868567\n",
      " 0.3563503  0.54801928 0.2227583  0.2227583  0.2227583  0.40341602\n",
      " 0.2227583  0.2227583  0.29969595 0.37596114 0.41636346 0.41636346\n",
      " 0.41636346 0.50845991        nan        nan        nan        nan\n",
      " 0.22398075 0.25868567 0.3563503  0.54801928 0.2227583  0.2227583\n",
      " 0.2227583  0.40341602 0.2227583  0.2227583  0.29969595 0.37596114\n",
      " 0.41636346 0.41636346 0.41636346 0.50845991        nan        nan\n",
      "        nan        nan 0.39410687 0.44866634 0.48617714 0.55182049\n",
      " 0.22398075 0.2227583  0.22519227 0.44330939 0.2227583  0.2227583\n",
      " 0.32239711 0.5452777  0.4437441  0.41591228 0.41624905 0.54835351\n",
      "        nan        nan        nan        nan 0.39410687 0.44866634\n",
      " 0.48617714 0.55182049 0.22398075 0.2227583  0.22519227 0.44330939\n",
      " 0.2227583  0.2227583  0.32239711 0.5452777  0.4437441  0.41591228\n",
      " 0.41624905 0.54835351        nan        nan        nan        nan\n",
      " 0.47392499 0.47947933 0.49022167 0.47611291 0.34632502 0.28403853\n",
      " 0.41524121 0.49004    0.2227583  0.2227583  0.34473131 0.54457987\n",
      " 0.52069472 0.51243705 0.50131043 0.51459659        nan        nan\n",
      "        nan        nan 0.47392499 0.47947933 0.49022167 0.47611291\n",
      " 0.34632502 0.28403853 0.41524121 0.49004    0.2227583  0.2227583\n",
      " 0.34473131 0.54457987 0.52069472 0.51243705 0.50131043 0.51459659\n",
      "        nan        nan        nan        nan 0.46420521 0.47458677\n",
      " 0.47932123 0.45971332 0.44812368 0.47541122 0.48938218 0.50667553\n",
      " 0.35413074 0.41238728 0.51294416 0.53650724 0.5036363  0.50874754\n",
      " 0.49798685 0.50239804        nan        nan        nan        nan\n",
      " 0.46420521 0.47458677 0.47932123 0.45971332 0.44812368 0.47541122\n",
      " 0.48938218 0.50667553 0.35413074 0.41238728 0.51294416 0.53650724\n",
      " 0.5036363  0.50874754 0.49798685 0.50239804        nan        nan\n",
      "        nan        nan 0.47760372 0.48811365 0.49118622 0.46235661\n",
      " 0.45979359 0.47901381 0.48897827 0.50201959 0.41450388 0.43033814\n",
      " 0.49249965 0.5086403  0.51629635 0.50165289 0.49958314 0.50051094\n",
      "        nan        nan        nan        nan 0.47760372 0.48811365\n",
      " 0.49118622 0.46235661 0.45979359 0.47901381 0.48897827 0.50201959\n",
      " 0.41450388 0.43033814 0.49249965 0.5086403  0.51629635 0.50165289\n",
      " 0.49958314 0.50051094        nan        nan        nan        nan\n",
      " 0.45906919 0.4803641  0.46547001 0.45293966 0.45599734 0.47661914\n",
      " 0.50352831 0.49710238 0.40989116 0.44355052 0.49668063 0.52544433\n",
      " 0.51324426 0.50326013 0.49928222 0.4982196         nan        nan\n",
      "        nan        nan 0.45906919 0.4803641  0.46547001 0.45293966\n",
      " 0.45599734 0.47661914 0.50352831 0.49710238 0.40989116 0.44355052\n",
      " 0.49668063 0.52544433 0.51324426 0.50326013 0.49928222 0.4982196\n",
      "        nan        nan        nan        nan 0.45906919 0.47576004\n",
      " 0.46086595 0.44877604 0.45398087 0.46000301 0.49423218 0.48653988\n",
      " 0.39533328 0.4529252  0.53821588 0.49793299 0.51433217 0.49793079\n",
      " 0.49890331 0.49667203        nan        nan        nan        nan\n",
      " 0.45906919 0.47576004 0.46086595 0.44877604 0.45398087 0.46000301\n",
      " 0.49423218 0.48653988 0.39533328 0.4529252  0.53821588 0.49793299\n",
      " 0.51433217 0.49793079 0.49890331 0.49667203        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 341.433s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=0.001, class_weight='balanced', kernel='linear',\n",
      "                     max_iter=1000, probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.283025773982004 Best GS Acc: 0.5600870459485006 Best Params: {'classification__C': 0.001, 'classification__gamma': 'scale', 'classification__kernel': 'linear', 'classification__max_iter': 1000}\n",
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.22262382 0.22262382 0.30327586 0.51652608 0.22262382 0.22262382\n",
      " 0.22262382 0.34502276 0.22262382 0.22262382 0.33876576 0.37723459\n",
      " 0.41643888 0.41643888 0.41643888 0.41643888        nan        nan\n",
      "        nan        nan 0.22262382 0.22262382 0.30327586 0.51652608\n",
      " 0.22262382 0.22262382 0.22262382 0.34502276 0.22262382 0.22262382\n",
      " 0.33876576 0.37723459 0.41643888 0.41643888 0.41643888 0.41643888\n",
      "        nan        nan        nan        nan 0.22262382 0.27042613\n",
      " 0.41392787 0.50440564 0.22262382 0.22262382 0.22262382 0.423884\n",
      " 0.22262382 0.22262382 0.42349105 0.4334627  0.41643888 0.41643888\n",
      " 0.41643888 0.45730405        nan        nan        nan        nan\n",
      " 0.22262382 0.27042613 0.41392787 0.50440564 0.22262382 0.22262382\n",
      " 0.22262382 0.423884   0.22262382 0.22262382 0.42349105 0.4334627\n",
      " 0.41643888 0.41643888 0.41643888 0.45730405        nan        nan\n",
      "        nan        nan 0.4606832  0.46444745 0.4772901  0.50710291\n",
      " 0.22383938 0.22383938 0.22505493 0.47530747 0.22262382 0.22262382\n",
      " 0.44355394 0.50732324 0.45164136 0.41484103 0.41484103 0.506091\n",
      "        nan        nan        nan        nan 0.4606832  0.46444745\n",
      " 0.4772901  0.50710291 0.22383938 0.22383938 0.22505493 0.47530747\n",
      " 0.22262382 0.22262382 0.44355394 0.50732324 0.45164136 0.41484103\n",
      " 0.41484103 0.506091          nan        nan        nan        nan\n",
      " 0.50608683 0.47868076 0.49534161 0.48221848 0.29361022 0.27299865\n",
      " 0.38962876 0.481456   0.22262382 0.22262382 0.40241403 0.51372132\n",
      " 0.48169971 0.49924574 0.50440154 0.49737429        nan        nan\n",
      "        nan        nan 0.50608683 0.47868076 0.49534161 0.48221848\n",
      " 0.29361022 0.27299865 0.38962876 0.481456   0.22262382 0.22262382\n",
      " 0.40241403 0.51372132 0.48169971 0.49924574 0.50440154 0.49737429\n",
      "        nan        nan        nan        nan 0.49492326 0.49962991\n",
      " 0.48058584 0.47044374 0.45740892 0.47119487 0.47082171 0.50707266\n",
      " 0.35414415 0.44517577 0.49627356 0.51742829 0.49135688 0.49316149\n",
      " 0.48112916 0.4896647         nan        nan        nan        nan\n",
      " 0.49492326 0.49962991 0.48058584 0.47044374 0.45740892 0.47119487\n",
      " 0.47082171 0.50707266 0.35414415 0.44517577 0.49627356 0.51742829\n",
      " 0.49135688 0.49316149 0.48112916 0.4896647         nan        nan\n",
      "        nan        nan 0.46336584 0.48489283 0.48056893 0.53821471\n",
      " 0.45836619 0.49220395 0.47990251 0.52028666 0.44869357 0.46346357\n",
      " 0.50846008 0.51104258 0.48917604 0.4917203  0.48431693 0.49107966\n",
      "        nan        nan        nan        nan 0.46336584 0.48489283\n",
      " 0.48056893 0.53821471 0.45836619 0.49220395 0.47990251 0.52028666\n",
      " 0.44869357 0.46346357 0.50846008 0.51104258 0.48917604 0.4917203\n",
      " 0.48431693 0.49107966        nan        nan        nan        nan\n",
      " 0.48918784 0.50972    0.49105155 0.49137205 0.42240055 0.47311352\n",
      " 0.49579648 0.51302753 0.46139194 0.47125095 0.46994172 0.50592042\n",
      " 0.48182547 0.48162149 0.48413484 0.48732243        nan        nan\n",
      "        nan        nan 0.48918784 0.50972    0.49105155 0.49137205\n",
      " 0.42240055 0.47311352 0.49579648 0.51302753 0.46139194 0.47125095\n",
      " 0.46994172 0.50592042 0.48182547 0.48162149 0.48413484 0.48732243\n",
      "        nan        nan        nan        nan 0.51561039 0.51638602\n",
      " 0.49335513 0.48621206 0.4220168  0.46757112 0.48230853 0.51225996\n",
      " 0.4338245  0.46157552 0.47484387 0.5053305  0.49048645 0.49144903\n",
      " 0.48058759 0.48413833        nan        nan        nan        nan\n",
      " 0.51561039 0.51638602 0.49335513 0.48621206 0.4220168  0.46757112\n",
      " 0.48230853 0.51225996 0.4338245  0.46157552 0.47484387 0.5053305\n",
      " 0.49048645 0.49144903 0.48058759 0.48413833        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 344.066s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=100, class_weight='balanced', kernel='linear',\n",
      "                     max_iter=1000, probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5198591678939617 Best GS Acc: 0.5382147088498743 Best Params: {'classification__C': 100, 'classification__gamma': 'scale', 'classification__kernel': 'linear', 'classification__max_iter': 1000}\n",
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.22262382 0.26334576 0.30215152 0.52168892 0.22262382 0.22262382\n",
      " 0.22262382 0.38097564 0.22262382 0.22262382 0.41643888 0.44082724\n",
      " 0.41643888 0.41643888 0.41643888 0.42625401        nan        nan\n",
      "        nan        nan 0.22262382 0.26334576 0.30215152 0.52168892\n",
      " 0.22262382 0.22262382 0.22262382 0.38097564 0.22262382 0.22262382\n",
      " 0.41643888 0.44082724 0.41643888 0.41643888 0.41643888 0.42625401\n",
      "        nan        nan        nan        nan 0.22579601 0.2961656\n",
      " 0.41621653 0.51934292 0.22384627 0.22384627 0.22384627 0.41025989\n",
      " 0.22262382 0.22262382 0.41643888 0.43442038 0.41643888 0.41643888\n",
      " 0.41643888 0.45805399        nan        nan        nan        nan\n",
      " 0.22579601 0.2961656  0.41621653 0.51934292 0.22384627 0.22384627\n",
      " 0.22384627 0.41025989 0.22262382 0.22262382 0.41643888 0.43442038\n",
      " 0.41643888 0.41643888 0.41643888 0.45805399        nan        nan\n",
      "        nan        nan 0.3674265  0.4576699  0.5012624  0.51631987\n",
      " 0.22262382 0.22262382 0.22262382 0.42712729 0.22262382 0.22262382\n",
      " 0.50594462 0.51395001 0.41674973 0.41762758 0.4176288  0.52023922\n",
      "        nan        nan        nan        nan 0.3674265  0.4576699\n",
      " 0.5012624  0.51631987 0.22262382 0.22262382 0.22262382 0.42712729\n",
      " 0.22262382 0.22262382 0.50594462 0.51395001 0.41674973 0.41762758\n",
      " 0.4176288  0.52023922        nan        nan        nan        nan\n",
      " 0.47318921 0.47959512 0.48915874 0.50077577 0.32560941 0.28988138\n",
      " 0.42192734 0.49582559 0.22262382 0.2436484  0.39467486 0.52527862\n",
      " 0.50116434 0.52015562 0.52805307 0.51869808        nan        nan\n",
      "        nan        nan 0.47318921 0.47959512 0.48915874 0.50077577\n",
      " 0.32560941 0.28988138 0.42192734 0.49582559 0.22262382 0.2436484\n",
      " 0.39467486 0.52527862 0.50116434 0.52015562 0.52805307 0.51869808\n",
      "        nan        nan        nan        nan 0.49942866 0.50194271\n",
      " 0.48583512 0.47188987 0.46368621 0.49109976 0.4983269  0.51603277\n",
      " 0.3525246  0.43173872 0.5121894  0.53643006 0.51248744 0.52197671\n",
      " 0.50432889 0.50992167        nan        nan        nan        nan\n",
      " 0.49942866 0.50194271 0.48583512 0.47188987 0.46368621 0.49109976\n",
      " 0.4983269  0.51603277 0.3525246  0.43173872 0.5121894  0.53643006\n",
      " 0.51248744 0.52197671 0.50432889 0.50992167        nan        nan\n",
      "        nan        nan 0.4892375  0.51745898 0.47849396 0.49236924\n",
      " 0.4778986  0.48577007 0.50402414 0.49779891 0.44384435 0.45551314\n",
      " 0.49321247 0.49442696 0.48808554 0.51303914 0.50412722 0.50883599\n",
      "        nan        nan        nan        nan 0.4892375  0.51745898\n",
      " 0.47849396 0.49236924 0.4778986  0.48577007 0.50402414 0.49779891\n",
      " 0.44384435 0.45551314 0.49321247 0.49442696 0.48808554 0.51303914\n",
      " 0.50412722 0.50883599        nan        nan        nan        nan\n",
      " 0.48135862 0.49632612 0.46977021 0.47136401 0.47885981 0.47858197\n",
      " 0.50802243 0.50891643 0.44384435 0.4662111  0.48347817 0.50593146\n",
      " 0.47148004 0.49888823 0.50979314 0.51000007        nan        nan\n",
      "        nan        nan 0.48135862 0.49632612 0.46977021 0.47136401\n",
      " 0.47885981 0.47858197 0.50802243 0.50891643 0.44384435 0.4662111\n",
      " 0.48347817 0.50593146 0.47148004 0.49888823 0.50979314 0.51000007\n",
      "        nan        nan        nan        nan 0.48135862 0.49632612\n",
      " 0.46977021 0.47310371 0.47885981 0.47354922 0.50252066 0.5026904\n",
      " 0.44384435 0.4579743  0.49250332 0.51181205 0.47237981 0.50886259\n",
      " 0.50517527 0.50528464        nan        nan        nan        nan\n",
      " 0.48135862 0.49632612 0.46977021 0.47310371 0.47885981 0.47354922\n",
      " 0.50252066 0.5026904  0.44384435 0.4579743  0.49250332 0.51181205\n",
      " 0.47237981 0.50886259 0.50517527 0.50528464        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 341.325s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=10, class_weight='balanced', max_iter=1000,\n",
      "                     probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.53992628992629 Best GS Acc: 0.5364300552443025 Best Params: {'classification__C': 10, 'classification__gamma': 'scale', 'classification__kernel': 'rbf', 'classification__max_iter': 1000}\n",
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.22262382 0.22262382 0.22641908 0.53563466 0.22262382 0.22262382\n",
      " 0.22262382 0.30726025 0.22262382 0.22262382 0.27435888 0.40089478\n",
      " 0.41643888 0.41643888 0.41643888 0.41643888        nan        nan\n",
      "        nan        nan 0.22262382 0.22262382 0.22641908 0.53563466\n",
      " 0.22262382 0.22262382 0.22262382 0.30726025 0.22262382 0.22262382\n",
      " 0.27435888 0.40089478 0.41643888 0.41643888 0.41643888 0.41643888\n",
      "        nan        nan        nan        nan 0.22215039 0.22215325\n",
      " 0.34591768 0.52176322 0.22262382 0.22262382 0.22262382 0.42488096\n",
      " 0.22262382 0.22262382 0.3194047  0.35625175 0.41643888 0.41643888\n",
      " 0.41643888 0.54825347        nan        nan        nan        nan\n",
      " 0.22215039 0.22215325 0.34591768 0.52176322 0.22262382 0.22262382\n",
      " 0.22262382 0.42488096 0.22262382 0.22262382 0.3194047  0.35625175\n",
      " 0.41643888 0.41643888 0.41643888 0.54825347        nan        nan\n",
      "        nan        nan 0.4077123  0.47379919 0.47679123 0.52303562\n",
      " 0.22262382 0.22262382 0.22262382 0.46204792 0.22262382 0.22262382\n",
      " 0.24126779 0.53514513 0.46588487 0.41853292 0.42767438 0.53572231\n",
      "        nan        nan        nan        nan 0.4077123  0.47379919\n",
      " 0.47679123 0.52303562 0.22262382 0.22262382 0.22262382 0.46204792\n",
      " 0.22262382 0.22262382 0.24126779 0.53514513 0.46588487 0.41853292\n",
      " 0.42767438 0.53572231        nan        nan        nan        nan\n",
      " 0.49263563 0.484835   0.49156344 0.50577246 0.28166986 0.28211458\n",
      " 0.31823944 0.48544554 0.22262382 0.22262382 0.30854297 0.54014221\n",
      " 0.50671385 0.50592244 0.51801388 0.5149652         nan        nan\n",
      "        nan        nan 0.49263563 0.484835   0.49156344 0.50577246\n",
      " 0.28166986 0.28211458 0.31823944 0.48544554 0.22262382 0.22262382\n",
      " 0.30854297 0.54014221 0.50671385 0.50592244 0.51801388 0.5149652\n",
      "        nan        nan        nan        nan 0.48716141 0.47616042\n",
      " 0.49220336 0.48028386 0.47973241 0.50927561 0.5002055  0.53210875\n",
      " 0.37100776 0.44210445 0.50381192 0.53921979 0.50047113 0.50200955\n",
      " 0.49985402 0.50538288        nan        nan        nan        nan\n",
      " 0.48716141 0.47616042 0.49220336 0.48028386 0.47973241 0.50927561\n",
      " 0.5002055  0.53210875 0.37100776 0.44210445 0.50381192 0.53921979\n",
      " 0.50047113 0.50200955 0.49985402 0.50538288        nan        nan\n",
      "        nan        nan 0.49122918 0.47988276 0.48971234 0.47440201\n",
      " 0.50001042 0.50873346 0.50515526 0.51024609 0.44018639 0.47032283\n",
      " 0.487017   0.52155244 0.49669853 0.48848883 0.50765272 0.49801479\n",
      "        nan        nan        nan        nan 0.49122918 0.47988276\n",
      " 0.48971234 0.47440201 0.50001042 0.50873346 0.50515526 0.51024609\n",
      " 0.44018639 0.47032283 0.487017   0.52155244 0.49669853 0.48848883\n",
      " 0.50765272 0.49801479        nan        nan        nan        nan\n",
      " 0.4678248  0.46704066 0.48145821 0.47295159 0.48243668 0.48341629\n",
      " 0.51670227 0.51112415 0.45827074 0.45564804 0.50339289 0.51161511\n",
      " 0.51557704 0.49976789 0.50312009 0.50158204        nan        nan\n",
      "        nan        nan 0.4678248  0.46704066 0.48145821 0.47295159\n",
      " 0.48243668 0.48341629 0.51670227 0.51112415 0.45827074 0.45564804\n",
      " 0.50339289 0.51161511 0.51557704 0.49976789 0.50312009 0.50158204\n",
      "        nan        nan        nan        nan 0.47765025 0.47686611\n",
      " 0.49319515 0.47307552 0.48635408 0.48876564 0.49798792 0.50383883\n",
      " 0.43729103 0.46812312 0.52052819 0.51979963 0.49290564 0.50286535\n",
      " 0.49828051 0.49835811        nan        nan        nan        nan\n",
      " 0.47765025 0.47686611 0.49319515 0.47307552 0.48635408 0.48876564\n",
      " 0.49798792 0.50383883 0.43729103 0.46812312 0.52052819 0.51979963\n",
      " 0.49290564 0.50286535 0.49828051 0.49835811        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 342.826s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=0.01, class_weight='balanced', kernel='sigmoid',\n",
      "                     max_iter=1000, probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.4163636363636364 Best GS Acc: 0.5482534744995174 Best Params: {'classification__C': 0.01, 'classification__gamma': 'scale', 'classification__kernel': 'sigmoid', 'classification__max_iter': 1000}\n",
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.22262382 0.22262382 0.39467404 0.51814012 0.22262382 0.22262382\n",
      " 0.22262382 0.38253028 0.22262382 0.22262382 0.41643888 0.41643888\n",
      " 0.41643888 0.41643888 0.41643888 0.41643888        nan        nan\n",
      "        nan        nan 0.22262382 0.22262382 0.39467404 0.51814012\n",
      " 0.22262382 0.22262382 0.22262382 0.38253028 0.22262382 0.22262382\n",
      " 0.41643888 0.41643888 0.41643888 0.41643888 0.41643888 0.41643888\n",
      "        nan        nan        nan        nan 0.22262382 0.25825759\n",
      " 0.48958501 0.51646424 0.22262382 0.22262382 0.22262382 0.42522587\n",
      " 0.22262382 0.22262382 0.37723459 0.38100493 0.41643888 0.41643888\n",
      " 0.41643888 0.47874355        nan        nan        nan        nan\n",
      " 0.22262382 0.25825759 0.48958501 0.51646424 0.22262382 0.22262382\n",
      " 0.22262382 0.42522587 0.22262382 0.22262382 0.37723459 0.38100493\n",
      " 0.41643888 0.41643888 0.41643888 0.47874355        nan        nan\n",
      "        nan        nan 0.43760944 0.48772155 0.51824306 0.53061296\n",
      " 0.22384627 0.22384627 0.22384627 0.45845305 0.22262382 0.22262382\n",
      " 0.43649435 0.50683391 0.45431941 0.42220536 0.42325647 0.51857546\n",
      "        nan        nan        nan        nan 0.43760944 0.48772155\n",
      " 0.51824306 0.53061296 0.22384627 0.22384627 0.22384627 0.45845305\n",
      " 0.22262382 0.22262382 0.43649435 0.50683391 0.45431941 0.42220536\n",
      " 0.42325647 0.51857546        nan        nan        nan        nan\n",
      " 0.5008897  0.51471391 0.49632608 0.4908627  0.36894224 0.29207193\n",
      " 0.5046739  0.5091193  0.22262382 0.22262382 0.37498351 0.53930118\n",
      " 0.51221231 0.51661004 0.51203897 0.50454366        nan        nan\n",
      "        nan        nan 0.5008897  0.51471391 0.49632608 0.4908627\n",
      " 0.36894224 0.29207193 0.5046739  0.5091193  0.22262382 0.22262382\n",
      " 0.37498351 0.53930118 0.51221231 0.51661004 0.51203897 0.50454366\n",
      "        nan        nan        nan        nan 0.50194965 0.50285837\n",
      " 0.47439299 0.4908111  0.46091677 0.48440682 0.47733784 0.50063831\n",
      " 0.35646776 0.43098887 0.51951624 0.54830098 0.48827097 0.51990193\n",
      " 0.50527574 0.50826956        nan        nan        nan        nan\n",
      " 0.50194965 0.50285837 0.47439299 0.4908111  0.46091677 0.48440682\n",
      " 0.47733784 0.50063831 0.35646776 0.43098887 0.51951624 0.54830098\n",
      " 0.48827097 0.51990193 0.50527574 0.50826956        nan        nan\n",
      "        nan        nan 0.48965342 0.48742556 0.4740685  0.47129239\n",
      " 0.46223479 0.48110461 0.48543078 0.50004528 0.43454689 0.46993992\n",
      " 0.50012414 0.50354584 0.48841409 0.51512357 0.50217419 0.50075201\n",
      "        nan        nan        nan        nan 0.48965342 0.48742556\n",
      " 0.4740685  0.47129239 0.46223479 0.48110461 0.48543078 0.50004528\n",
      " 0.43454689 0.46993992 0.50012414 0.50354584 0.48841409 0.51512357\n",
      " 0.50217419 0.50075201        nan        nan        nan        nan\n",
      " 0.51005246 0.49570031 0.47519003 0.48139625 0.46597827 0.47919619\n",
      " 0.50027111 0.47919624 0.43454689 0.46620794 0.48071107 0.49715942\n",
      " 0.50356745 0.53129253 0.50522726 0.50411823        nan        nan\n",
      "        nan        nan 0.51005246 0.49570031 0.47519003 0.48139625\n",
      " 0.46597827 0.47919619 0.50027111 0.47919624 0.43454689 0.46620794\n",
      " 0.48071107 0.49715942 0.50356745 0.53129253 0.50522726 0.50411823\n",
      "        nan        nan        nan        nan 0.51005246 0.50332963\n",
      " 0.4654305  0.47242124 0.46707834 0.48703741 0.48502953 0.49327884\n",
      " 0.43454689 0.46620794 0.48710946 0.49948442 0.5086102  0.52268852\n",
      " 0.51088692 0.51115755        nan        nan        nan        nan\n",
      " 0.51005246 0.50332963 0.4654305  0.47242124 0.46707834 0.48703741\n",
      " 0.48502953 0.49327884 0.43454689 0.46620794 0.48710946 0.49948442\n",
      " 0.5086102  0.52268852 0.51088692 0.51115755        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 342.111s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=10, class_weight='balanced', max_iter=1000,\n",
      "                     probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5545740684333436 Best GS Acc: 0.5483009849909999 Best Params: {'classification__C': 10, 'classification__gamma': 'scale', 'classification__kernel': 'rbf', 'classification__max_iter': 1000}\n",
      "Average f1 macro score:  0.4627497873198472\n",
      "\n",
      "Trait to predict:  neuroticism \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b22a162d89294082906abc69e1365cd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.33328941 0.41192232 0.38354871 0.5498727  0.33055192 0.33055192\n",
      " 0.33055192 0.33624116 0.33055192 0.33055192 0.33505373 0.36080333\n",
      " 0.33609136 0.33609136 0.33609136 0.33609136        nan        nan\n",
      "        nan        nan 0.33328941 0.41192232 0.38354871 0.5498727\n",
      " 0.33055192 0.33055192 0.33055192 0.33624116 0.33055192 0.33055192\n",
      " 0.33505373 0.36080333 0.33609136 0.33609136 0.33609136 0.33609136\n",
      "        nan        nan        nan        nan 0.36845825 0.44762632\n",
      " 0.52055507 0.55554729 0.33055192 0.33055192 0.33055192 0.37400614\n",
      " 0.33055192 0.33055192 0.3771377  0.36064045 0.33609136 0.33609136\n",
      " 0.33609136 0.34630711        nan        nan        nan        nan\n",
      " 0.36845825 0.44762632 0.52055507 0.55554729 0.33055192 0.33055192\n",
      " 0.33055192 0.37400614 0.33055192 0.33055192 0.3771377  0.36064045\n",
      " 0.33609136 0.33609136 0.33609136 0.34630711        nan        nan\n",
      "        nan        nan 0.49397301 0.42466139 0.47334361 0.55592469\n",
      " 0.35009993 0.38403384 0.34701199 0.43093753 0.33055192 0.33055192\n",
      " 0.42973224 0.56817045 0.3579574  0.35276108 0.36284297 0.54114374\n",
      "        nan        nan        nan        nan 0.49397301 0.42466139\n",
      " 0.47334361 0.55592469 0.35009993 0.38403384 0.34701199 0.43093753\n",
      " 0.33055192 0.33055192 0.42973224 0.56817045 0.3579574  0.35276108\n",
      " 0.36284297 0.54114374        nan        nan        nan        nan\n",
      " 0.46757469 0.47048675 0.42778914 0.46657078 0.40938933 0.44396233\n",
      " 0.45473425 0.49084869 0.33647329 0.3753582  0.53775868 0.58111588\n",
      " 0.48740046 0.50675862 0.52043216 0.53314537        nan        nan\n",
      "        nan        nan 0.46757469 0.47048675 0.42778914 0.46657078\n",
      " 0.40938933 0.44396233 0.45473425 0.49084869 0.33647329 0.3753582\n",
      " 0.53775868 0.58111588 0.48740046 0.50675862 0.52043216 0.53314537\n",
      "        nan        nan        nan        nan 0.49125664 0.4934123\n",
      " 0.44550258 0.43066939 0.39228945 0.44104777 0.4631521  0.49670928\n",
      " 0.5228785  0.52892362 0.54830965 0.56936205 0.5171691  0.52299206\n",
      " 0.50824565 0.50425487        nan        nan        nan        nan\n",
      " 0.49125664 0.4934123  0.44550258 0.43066939 0.39228945 0.44104777\n",
      " 0.4631521  0.49670928 0.5228785  0.52892362 0.54830965 0.56936205\n",
      " 0.5171691  0.52299206 0.50824565 0.50425487        nan        nan\n",
      "        nan        nan 0.49125664 0.48533745 0.4685129  0.46949404\n",
      " 0.39224558 0.43300818 0.46484158 0.51593174 0.53286681 0.53532108\n",
      " 0.53584028 0.53677007 0.52176146 0.52141201 0.51462718 0.52302541\n",
      "        nan        nan        nan        nan 0.49125664 0.48533745\n",
      " 0.4685129  0.46949404 0.39224558 0.43300818 0.46484158 0.51593174\n",
      " 0.53286681 0.53532108 0.53584028 0.53677007 0.52176146 0.52141201\n",
      " 0.51462718 0.52302541        nan        nan        nan        nan\n",
      " 0.49125664 0.48475812 0.46973807 0.45334239 0.38411444 0.44475319\n",
      " 0.46555674 0.49831276 0.53286681 0.5272888  0.53847559 0.52618833\n",
      " 0.51448844 0.51314562 0.52089409 0.52394382        nan        nan\n",
      "        nan        nan 0.49125664 0.48475812 0.46973807 0.45334239\n",
      " 0.38411444 0.44475319 0.46555674 0.49831276 0.53286681 0.5272888\n",
      " 0.53847559 0.52618833 0.51448844 0.51314562 0.52089409 0.52394382\n",
      "        nan        nan        nan        nan 0.49125664 0.48475812\n",
      " 0.46973807 0.45334239 0.38411444 0.44493383 0.45861149 0.49107266\n",
      " 0.53286681 0.5272888  0.53847559 0.53547743 0.51228201 0.52012161\n",
      " 0.52559598 0.52792062        nan        nan        nan        nan\n",
      " 0.49125664 0.48475812 0.46973807 0.45334239 0.38411444 0.44493383\n",
      " 0.45861149 0.49107266 0.53286681 0.5272888  0.53847559 0.53547743\n",
      " 0.51228201 0.52012161 0.52559598 0.52792062        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 347.683s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=1, class_weight='balanced', max_iter=1000,\n",
      "                     probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5403017324536019 Best GS Acc: 0.5811158809201297 Best Params: {'classification__C': 1, 'classification__gamma': 'scale', 'classification__kernel': 'rbf', 'classification__max_iter': 1000}\n",
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.33037968 0.36386421 0.35719254 0.55572925 0.33037968 0.33037968\n",
      " 0.33037968 0.33267861 0.33037968 0.33037968 0.33141731 0.35941893\n",
      " 0.33625962 0.33625962 0.33625962 0.33625962        nan        nan\n",
      "        nan        nan 0.33037968 0.36386421 0.35719254 0.55572925\n",
      " 0.33037968 0.33037968 0.33037968 0.33267861 0.33037968 0.33037968\n",
      " 0.33141731 0.35941893 0.33625962 0.33625962 0.33625962 0.33625962\n",
      "        nan        nan        nan        nan 0.39325461 0.46678269\n",
      " 0.50136629 0.5640524  0.33037968 0.33037968 0.33037968 0.39292815\n",
      " 0.33037968 0.33037968 0.36259893 0.47215082 0.33625962 0.33625962\n",
      " 0.33625962 0.41140663        nan        nan        nan        nan\n",
      " 0.39325461 0.46678269 0.50136629 0.5640524  0.33037968 0.33037968\n",
      " 0.33037968 0.39292815 0.33037968 0.33037968 0.36259893 0.47215082\n",
      " 0.33625962 0.33625962 0.33625962 0.41140663        nan        nan\n",
      "        nan        nan 0.43904428 0.47149779 0.4739604  0.56589897\n",
      " 0.33003019 0.33003019 0.3296807  0.47260927 0.33037968 0.33037968\n",
      " 0.39808829 0.55424595 0.34214863 0.33798557 0.34371175 0.55796637\n",
      "        nan        nan        nan        nan 0.43904428 0.47149779\n",
      " 0.4739604  0.56589897 0.33003019 0.33003019 0.3296807  0.47260927\n",
      " 0.33037968 0.33037968 0.39808829 0.55424595 0.34214863 0.33798557\n",
      " 0.34371175 0.55796637        nan        nan        nan        nan\n",
      " 0.43064019 0.42543093 0.42170517 0.43936941 0.41670426 0.46639943\n",
      " 0.46048383 0.53022219 0.33037968 0.33037968 0.42868879 0.56486684\n",
      " 0.50623203 0.5036851  0.51356603 0.53337804        nan        nan\n",
      "        nan        nan 0.43064019 0.42543093 0.42170517 0.43936941\n",
      " 0.41670426 0.46639943 0.46048383 0.53022219 0.33037968 0.33037968\n",
      " 0.42868879 0.56486684 0.50623203 0.5036851  0.51356603 0.53337804\n",
      "        nan        nan        nan        nan 0.4561395  0.44357676\n",
      " 0.4166621  0.41496563 0.39228509 0.42506098 0.45991066 0.50756276\n",
      " 0.47546668 0.48346838 0.52785846 0.56138374 0.5312325  0.51790404\n",
      " 0.52282473 0.5237443         nan        nan        nan        nan\n",
      " 0.4561395  0.44357676 0.4166621  0.41496563 0.39228509 0.42506098\n",
      " 0.45991066 0.50756276 0.47546668 0.48346838 0.52785846 0.56138374\n",
      " 0.5312325  0.51790404 0.52282473 0.5237443         nan        nan\n",
      "        nan        nan 0.45044632 0.4533187  0.43799594 0.42228996\n",
      " 0.39240154 0.40727309 0.47133712 0.47915916 0.4782244  0.47200159\n",
      " 0.50954793 0.50621169 0.52207462 0.52017803 0.52046284 0.51853051\n",
      "        nan        nan        nan        nan 0.45044632 0.4533187\n",
      " 0.43799594 0.42228996 0.39240154 0.40727309 0.47133712 0.47915916\n",
      " 0.4782244  0.47200159 0.50954793 0.50621169 0.52207462 0.52017803\n",
      " 0.52046284 0.51853051        nan        nan        nan        nan\n",
      " 0.45162661 0.44367881 0.43973848 0.42503528 0.40143913 0.41570791\n",
      " 0.45546194 0.48013546 0.48933928 0.4919887  0.50379324 0.5015422\n",
      " 0.51349459 0.52479603 0.51747479 0.52011278        nan        nan\n",
      "        nan        nan 0.45162661 0.44367881 0.43973848 0.42503528\n",
      " 0.40143913 0.41570791 0.45546194 0.48013546 0.48933928 0.4919887\n",
      " 0.50379324 0.5015422  0.51349459 0.52479603 0.51747479 0.52011278\n",
      "        nan        nan        nan        nan 0.45941877 0.44246388\n",
      " 0.46872498 0.41763402 0.4050229  0.40472743 0.4511307  0.46984212\n",
      " 0.49070828 0.4698572  0.49377397 0.5190877  0.51715955 0.52095313\n",
      " 0.52296289 0.52741704        nan        nan        nan        nan\n",
      " 0.45941877 0.44246388 0.46872498 0.41763402 0.4050229  0.40472743\n",
      " 0.4511307  0.46984212 0.49070828 0.4698572  0.49377397 0.5190877\n",
      " 0.51715955 0.52095313 0.52296289 0.52741704        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 340.821s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=0.1, class_weight='balanced', kernel='linear',\n",
      "                     max_iter=1000, probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.4802461139896373 Best GS Acc: 0.5658989717395284 Best Params: {'classification__C': 0.1, 'classification__gamma': 'scale', 'classification__kernel': 'linear', 'classification__max_iter': 1000}\n",
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.33037968 0.36460869 0.36783596 0.55469992 0.33037968 0.33037968\n",
      " 0.33037968 0.33300839 0.33037968 0.33037968 0.33625962 0.33453019\n",
      " 0.33625962 0.33625962 0.33625962 0.33625962        nan        nan\n",
      "        nan        nan 0.33037968 0.36460869 0.36783596 0.55469992\n",
      " 0.33037968 0.33037968 0.33037968 0.33300839 0.33037968 0.33037968\n",
      " 0.33625962 0.33453019 0.33625962 0.33625962 0.33625962 0.33625962\n",
      "        nan        nan        nan        nan 0.39784713 0.40908117\n",
      " 0.48801941 0.55765011 0.33037968 0.33037968 0.33037968 0.35752439\n",
      " 0.33037968 0.33037968 0.33625962 0.39265985 0.33625962 0.33625962\n",
      " 0.33625962 0.37634225        nan        nan        nan        nan\n",
      " 0.39784713 0.40908117 0.48801941 0.55765011 0.33037968 0.33037968\n",
      " 0.33037968 0.35752439 0.33037968 0.33037968 0.33625962 0.39265985\n",
      " 0.33625962 0.33625962 0.33625962 0.37634225        nan        nan\n",
      "        nan        nan 0.45838089 0.44932779 0.47417877 0.55723858\n",
      " 0.32967887 0.33003019 0.33003019 0.42217962 0.33037968 0.33037968\n",
      " 0.48848773 0.56019807 0.34897067 0.33557323 0.33936709 0.55821328\n",
      "        nan        nan        nan        nan 0.45838089 0.44932779\n",
      " 0.47417877 0.55723858 0.32967887 0.33003019 0.33003019 0.42217962\n",
      " 0.33037968 0.33037968 0.48848773 0.56019807 0.34897067 0.33557323\n",
      " 0.33936709 0.55821328        nan        nan        nan        nan\n",
      " 0.48410908 0.4395819  0.42797321 0.44465629 0.40593121 0.43981999\n",
      " 0.44622006 0.46874192 0.33037968 0.38649253 0.53355758 0.56304084\n",
      " 0.50556432 0.47273572 0.53800847 0.55530433        nan        nan\n",
      "        nan        nan 0.48410908 0.4395819  0.42797321 0.44465629\n",
      " 0.40593121 0.43981999 0.44622006 0.46874192 0.33037968 0.38649253\n",
      " 0.53355758 0.56304084 0.50556432 0.47273572 0.53800847 0.55530433\n",
      "        nan        nan        nan        nan 0.45217428 0.45428372\n",
      " 0.45002916 0.4321854  0.40242144 0.42557808 0.45529968 0.51146063\n",
      " 0.49587619 0.52938341 0.55603561 0.56580578 0.52819927 0.53589434\n",
      " 0.54914816 0.54382545        nan        nan        nan        nan\n",
      " 0.45217428 0.45428372 0.45002916 0.4321854  0.40242144 0.42557808\n",
      " 0.45529968 0.51146063 0.49587619 0.52938341 0.55603561 0.56580578\n",
      " 0.52819927 0.53589434 0.54914816 0.54382545        nan        nan\n",
      "        nan        nan 0.46626216 0.46844865 0.43768942 0.44961446\n",
      " 0.39087668 0.43024661 0.49832028 0.51653963 0.49977762 0.50482648\n",
      " 0.52659816 0.53563401 0.51221533 0.53469594 0.53050731 0.5280007\n",
      "        nan        nan        nan        nan 0.46626216 0.46844865\n",
      " 0.43768942 0.44961446 0.39087668 0.43024661 0.49832028 0.51653963\n",
      " 0.49977762 0.50482648 0.52659816 0.53563401 0.51221533 0.53469594\n",
      " 0.53050731 0.5280007         nan        nan        nan        nan\n",
      " 0.48521676 0.45618661 0.44769494 0.44674474 0.38261124 0.41738163\n",
      " 0.47224571 0.51858252 0.49754587 0.50881493 0.53927962 0.53522014\n",
      " 0.51082362 0.54308815 0.53687349 0.53594006        nan        nan\n",
      "        nan        nan 0.48521676 0.45618661 0.44769494 0.44674474\n",
      " 0.38261124 0.41738163 0.47224571 0.51858252 0.49754587 0.50881493\n",
      " 0.53927962 0.53522014 0.51082362 0.54308815 0.53687349 0.53594006\n",
      "        nan        nan        nan        nan 0.46561893 0.46432816\n",
      " 0.46764492 0.46763974 0.36992409 0.40262649 0.44992143 0.50567804\n",
      " 0.50501372 0.48934181 0.51280688 0.53046044 0.53661036 0.5479174\n",
      " 0.53483922 0.5460343         nan        nan        nan        nan\n",
      " 0.46561893 0.46432816 0.46764492 0.46763974 0.36992409 0.40262649\n",
      " 0.44992143 0.50567804 0.50501372 0.48934181 0.51280688 0.53046044\n",
      " 0.53661036 0.5479174  0.53483922 0.5460343         nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 344.872s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=10, class_weight='balanced', max_iter=1000,\n",
      "                     probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5699891279024618 Best GS Acc: 0.5658057842475704 Best Params: {'classification__C': 10, 'classification__gamma': 'scale', 'classification__kernel': 'rbf', 'classification__max_iter': 1000}\n",
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.3516354  0.33246034 0.33687938 0.55644393 0.33072917 0.33072917\n",
      " 0.33072917 0.33107322 0.33072917 0.3317668  0.33487968 0.33591731\n",
      " 0.33591731 0.33591731 0.33591731 0.33591731        nan        nan\n",
      "        nan        nan 0.3516354  0.33246034 0.33687938 0.55644393\n",
      " 0.33072917 0.33072917 0.33072917 0.33107322 0.33072917 0.3317668\n",
      " 0.33487968 0.33591731 0.33591731 0.33591731 0.33591731 0.33591731\n",
      "        nan        nan        nan        nan 0.39393763 0.50582608\n",
      " 0.53527649 0.56610279 0.33072917 0.33072917 0.33072917 0.34992131\n",
      " 0.33072917 0.33314671 0.33487968 0.38776935 0.33591731 0.33591731\n",
      " 0.33591731 0.39357626        nan        nan        nan        nan\n",
      " 0.39393763 0.50582608 0.53527649 0.56610279 0.33072917 0.33072917\n",
      " 0.33072917 0.34992131 0.33072917 0.33314671 0.33487968 0.38776935\n",
      " 0.33591731 0.33591731 0.33591731 0.39357626        nan        nan\n",
      "        nan        nan 0.45826265 0.43704133 0.47240647 0.56332859\n",
      " 0.33072917 0.33072917 0.33072917 0.45894125 0.33072917 0.33072917\n",
      " 0.50946834 0.55412873 0.34382886 0.33591731 0.33939041 0.56042857\n",
      "        nan        nan        nan        nan 0.45826265 0.43704133\n",
      " 0.47240647 0.56332859 0.33072917 0.33072917 0.33072917 0.45894125\n",
      " 0.33072917 0.33072917 0.50946834 0.55412873 0.34382886 0.33591731\n",
      " 0.33939041 0.56042857        nan        nan        nan        nan\n",
      " 0.46934852 0.42054752 0.43759687 0.42726391 0.40735453 0.45440056\n",
      " 0.45996201 0.50259686 0.33660325 0.33037968 0.49056142 0.54839432\n",
      " 0.50517654 0.51296058 0.54848098 0.5684824         nan        nan\n",
      "        nan        nan 0.46934852 0.42054752 0.43759687 0.42726391\n",
      " 0.40735453 0.45440056 0.45996201 0.50259686 0.33660325 0.33037968\n",
      " 0.49056142 0.54839432 0.50517654 0.51296058 0.54848098 0.5684824\n",
      "        nan        nan        nan        nan 0.45064435 0.44231496\n",
      " 0.42791073 0.43126969 0.4037798  0.44390325 0.45185073 0.50163309\n",
      " 0.49288382 0.48597579 0.53501034 0.53362934 0.52310603 0.54084585\n",
      " 0.54953527 0.54519069        nan        nan        nan        nan\n",
      " 0.45064435 0.44231496 0.42791073 0.43126969 0.4037798  0.44390325\n",
      " 0.45185073 0.50163309 0.49288382 0.48597579 0.53501034 0.53362934\n",
      " 0.52310603 0.54084585 0.54953527 0.54519069        nan        nan\n",
      "        nan        nan 0.45064435 0.49534183 0.45230058 0.44753697\n",
      " 0.40936573 0.43665332 0.48674105 0.51548363 0.48054157 0.50388386\n",
      " 0.51152142 0.52433342 0.53038263 0.55318408 0.54493541 0.54674172\n",
      "        nan        nan        nan        nan 0.45064435 0.49534183\n",
      " 0.45230058 0.44753697 0.40936573 0.43665332 0.48674105 0.51548363\n",
      " 0.48054157 0.50388386 0.51152142 0.52433342 0.53038263 0.55318408\n",
      " 0.54493541 0.54674172        nan        nan        nan        nan\n",
      " 0.45064435 0.49534183 0.45230058 0.46141729 0.40652869 0.4370355\n",
      " 0.45586892 0.49732159 0.48054157 0.50388386 0.5115413  0.52018535\n",
      " 0.51841295 0.55937321 0.55238634 0.54791451        nan        nan\n",
      "        nan        nan 0.45064435 0.49534183 0.45230058 0.46141729\n",
      " 0.40652869 0.4370355  0.45586892 0.49732159 0.48054157 0.50388386\n",
      " 0.5115413  0.52018535 0.51841295 0.55937321 0.55238634 0.54791451\n",
      "        nan        nan        nan        nan 0.45064435 0.49534183\n",
      " 0.45230058 0.46141729 0.40652869 0.4370355  0.47873996 0.49188659\n",
      " 0.48054157 0.50388386 0.51310057 0.51319016 0.52070892 0.55536184\n",
      " 0.54902368 0.54806681        nan        nan        nan        nan\n",
      " 0.45064435 0.49534183 0.45230058 0.46141729 0.40652869 0.4370355\n",
      " 0.47873996 0.49188659 0.48054157 0.50388386 0.51310057 0.51319016\n",
      " 0.52070892 0.55536184 0.54902368 0.54806681        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 343.935s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=1, class_weight='balanced', kernel='sigmoid',\n",
      "                     max_iter=1000, probability=True))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5856536972155634 Best GS Acc: 0.5684823961551178 Best Params: {'classification__C': 1, 'classification__gamma': 'scale', 'classification__kernel': 'sigmoid', 'classification__max_iter': 1000}\n",
      "\n",
      "\tCreate pipeline with svm ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.3320791  0.37931844 0.35718906 0.58887762 0.33072917 0.33072917\n",
      " 0.33072917 0.333417   0.33072917 0.33072917 0.37456486 0.34443483\n",
      " 0.33591731 0.33591731 0.33591731 0.33591731        nan        nan\n",
      "        nan        nan 0.3320791  0.37931844 0.35718906 0.58887762\n",
      " 0.33072917 0.33072917 0.33072917 0.333417   0.33072917 0.33072917\n",
      " 0.37456486 0.34443483 0.33591731 0.33591731 0.33591731 0.33591731\n",
      "        nan        nan        nan        nan 0.39613466 0.50259057\n",
      " 0.54297341 0.58250613 0.33072917 0.33072917 0.33072917 0.39691089\n",
      " 0.33072917 0.33072917 0.33072917 0.33557323 0.33591731 0.33591731\n",
      " 0.33591731 0.36492807        nan        nan        nan        nan\n",
      " 0.39613466 0.50259057 0.54297341 0.58250613 0.33072917 0.33072917\n",
      " 0.33072917 0.39691089 0.33072917 0.33072917 0.33072917 0.33557323\n",
      " 0.33591731 0.33591731 0.33591731 0.36492807        nan        nan\n",
      "        nan        nan 0.46938129 0.43131341 0.47335312 0.57949432\n",
      " 0.3575319  0.33303361 0.3296807  0.45910236 0.33072917 0.33072917\n",
      " 0.3745006  0.57247806 0.34059529 0.34239203 0.34206381 0.58593442\n",
      "        nan        nan        nan        nan 0.46938129 0.43131341\n",
      " 0.47335312 0.57949432 0.3575319  0.33303361 0.3296807  0.45910236\n",
      " 0.33072917 0.33072917 0.3745006  0.57247806 0.34059529 0.34239203\n",
      " 0.34206381 0.58593442        nan        nan        nan        nan\n",
      " 0.47389195 0.48266843 0.44261915 0.44233836 0.42148261 0.44008748\n",
      " 0.46404988 0.524177   0.33072917 0.33072917 0.44705703 0.54872936\n",
      " 0.54324954 0.51244411 0.53597694 0.54780294        nan        nan\n",
      "        nan        nan 0.47389195 0.48266843 0.44261915 0.44233836\n",
      " 0.42148261 0.44008748 0.46404988 0.524177   0.33072917 0.33072917\n",
      " 0.44705703 0.54872936 0.54324954 0.51244411 0.53597694 0.54780294\n",
      "        nan        nan        nan        nan 0.48126361 0.49270785\n",
      " 0.4159164  0.42093381 0.39798958 0.42455755 0.44823685 0.49888919\n",
      " 0.49797406 0.50968278 0.52700792 0.53949004 0.54561367 0.53959982\n",
      " 0.55479802 0.55103694        nan        nan        nan        nan\n",
      " 0.48126361 0.49270785 0.4159164  0.42093381 0.39798958 0.42455755\n",
      " 0.44823685 0.49888919 0.49797406 0.50968278 0.52700792 0.53949004\n",
      " 0.54561367 0.53959982 0.55479802 0.55103694        nan        nan\n",
      "        nan        nan 0.46599563 0.44829678 0.42697988 0.41090202\n",
      " 0.38767774 0.41349147 0.4569947  0.48972871 0.48333897 0.50683206\n",
      " 0.5193925  0.5337086  0.53052059 0.55019234 0.55466729 0.54570675\n",
      "        nan        nan        nan        nan 0.46599563 0.44829678\n",
      " 0.42697988 0.41090202 0.38767774 0.41349147 0.4569947  0.48972871\n",
      " 0.48333897 0.50683206 0.5193925  0.5337086  0.53052059 0.55019234\n",
      " 0.55466729 0.54570675        nan        nan        nan        nan\n",
      " 0.47082356 0.46809894 0.46478219 0.41565025 0.39337114 0.41193044\n",
      " 0.45882916 0.48556455 0.48333897 0.50369624 0.51773286 0.52129188\n",
      " 0.53718194 0.53015023 0.54138155 0.53087346        nan        nan\n",
      "        nan        nan 0.47082356 0.46809894 0.46478219 0.41565025\n",
      " 0.39337114 0.41193044 0.45882916 0.48556455 0.48333897 0.50369624\n",
      " 0.51773286 0.52129188 0.53718194 0.53015023 0.54138155 0.53087346\n",
      "        nan        nan        nan        nan 0.4795559  0.47752565\n",
      " 0.45420546 0.44743852 0.39467273 0.40762551 0.4468011  0.49000441\n",
      " 0.48333897 0.5131037  0.51218186 0.51578468 0.55366926 0.53627454\n",
      " 0.5458183  0.54481706        nan        nan        nan        nan\n",
      " 0.4795559  0.47752565 0.45420546 0.44743852 0.39467273 0.40762551\n",
      " 0.4468011  0.49000441 0.48333897 0.5131037  0.51218186 0.51578468\n",
      " 0.55366926 0.53627454 0.5458183  0.54481706        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 346.383s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 SVC(C=0.001, class_weight='balanced', kernel='linear',\n",
      "                     max_iter=1000, probability=True))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.45675603455954394 Best GS Acc: 0.5888776195024077 Best Params: {'classification__C': 0.001, 'classification__gamma': 'scale', 'classification__kernel': 'linear', 'classification__max_iter': 1000}\n",
      "Average f1 macro score:  0.5265893412241617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    }
   ],
   "source": [
    "clf_lst = ['mcc', 'log', 'mlp', 'svm']\n",
    "classify_cv(df, 'binary', clf_lst, 'anova', dim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression with subsets of the features\n",
      "LR with word ngrams\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e9ef178b1a84ffeb5bd9c4a762a4e11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:  log \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b6498945ef4e1698cde902e71f4224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trait to predict:  openness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d61f5aafd41f4e9789690b9efe23a7e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 13.781s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.6080200501253132 Best GS Acc: 0.5139708362623485 Best Params: {'classification__C': 0.1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 13.708s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced', n_jobs=-1,\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5288400507775309 Best GS Acc: 0.5483258130952888 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 13.721s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced', n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5163720369626357 Best GS Acc: 0.5394892767975861 Best Params: {'classification__C': 1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 13.752s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced', n_jobs=-1,\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.4864821628539434 Best GS Acc: 0.5227199290447601 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 14.447s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced', n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5133713153331683 Best GS Acc: 0.5563486393281919 Best Params: {'classification__C': 1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "Average f1 macro score:  0.5306171232105183\n",
      "\n",
      "Trait to predict:  conscientiousness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f64fc5ab2454e75b0e98bc11e4ead9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 14.735s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=10, class_weight='balanced', max_iter=200,\n",
      "                                    n_jobs=-1, solver='saga'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5866077656358987 Best GS Acc: 0.5421639347285986 Best Params: {'classification__C': 10, 'classification__max_iter': 200, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 14.410s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5620294102784376 Best GS Acc: 0.5507921034026084 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 17.237s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced', n_jobs=-1,\n",
      "                                    solver='saga'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5570908654615261 Best GS Acc: 0.5585235950991518 Best Params: {'classification__C': 1, 'classification__max_iter': 100, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 15.500s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=10, class_weight='balanced', n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5944716761837385 Best GS Acc: 0.5367773179385658 Best Params: {'classification__C': 10, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 12.989s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5179397678382984 Best GS Acc: 0.5543344659282415 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "Average f1 macro score:  0.5636278970795799\n",
      "\n",
      "Trait to predict:  extraversion \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "776312c950754a10baea05edda84a5b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 12.862s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced', n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5357880381842977 Best GS Acc: 0.5797161814074788 Best Params: {'classification__C': 1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 13.758s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5917329093799681 Best GS Acc: 0.569958100376134 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 13.170s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    max_iter=500, n_jobs=-1, solver='saga'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.545747328356024 Best GS Acc: 0.5796944698824866 Best Params: {'classification__C': 0.001, 'classification__max_iter': 500, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 13.064s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.6585106382978724 Best GS Acc: 0.5749345741501694 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 13.026s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5734618148173667 Best GS Acc: 0.5731083112572882 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "Average f1 macro score:  0.5810481458071057\n",
      "\n",
      "Trait to predict:  agreeableness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1150999c8a343b8b032d27eddbcaff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 13.146s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5213017269468883 Best GS Acc: 0.5538443789909021 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 13.007s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5914018231091401 Best GS Acc: 0.5189534477475692 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 13.880s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5374827502232324 Best GS Acc: 0.5250955444035894 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 12.993s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5131792549555707 Best GS Acc: 0.558705294423669 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 13.112s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5153366773065816 Best GS Acc: 0.537900353784105 Best Params: {'classification__C': 0.1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "Average f1 macro score:  0.5357404465082827\n",
      "\n",
      "Trait to predict:  neuroticism \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ef4a97bd9c64246a582720e25056c96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 14.344s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5775745649573638 Best GS Acc: 0.5539248906710565 Best Params: {'classification__C': 0.1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 13.743s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced', n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5383987563155849 Best GS Acc: 0.6014496515437132 Best Params: {'classification__C': 1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 13.852s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced', n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5416112141906528 Best GS Acc: 0.5741911227759505 Best Params: {'classification__C': 1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 13.049s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.554084378430363 Best GS Acc: 0.5931539293324152 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 13.820s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced', n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.535537061673966 Best GS Acc: 0.5721416930973492 Best Params: {'classification__C': 1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "Average f1 macro score:  0.5494411951135861\n"
     ]
    }
   ],
   "source": [
    "small_clf_lst = ['log']\n",
    "print(\"Logistic regression with subsets of the features\")\n",
    "print(\"LR with word ngrams\")\n",
    "classify_cv(log_wordngrams_df, 'binary', small_clf_lst, 'anova', dim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR with char ngrams\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8edb1a35b6004876aad9495b03967acd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:  log \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a68bf22044a470e9e5ed227ea3bc5e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trait to predict:  openness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "041f43a148e0451383e5f529f5a1ce47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 14.357s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=100, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5402388369678088 Best GS Acc: 0.5392401366974038 Best Params: {'classification__C': 100, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 14.271s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.49323996113989643 Best GS Acc: 0.5296247848999082 Best Params: {'classification__C': 0.1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 14.454s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5434399896559613 Best GS Acc: 0.5484435931495957 Best Params: {'classification__C': 0.1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 16.080s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced', n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5558345718239123 Best GS Acc: 0.5155704729807918 Best Params: {'classification__C': 1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 15.158s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5215620031796503 Best GS Acc: 0.5639980625792947 Best Params: {'classification__C': 0.1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "Average f1 macro score:  0.5308630725534458\n",
      "\n",
      "Trait to predict:  conscientiousness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f064629d03634b08ac0193d9c9c9514f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 16.998s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.580149603443036 Best GS Acc: 0.5328250815924269 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 18.380s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=100, class_weight='balanced', n_jobs=-1,\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5345952476842529 Best GS Acc: 0.5377589506504448 Best Params: {'classification__C': 100, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 17.415s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1000, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5322215025906736 Best GS Acc: 0.5538186786793513 Best Params: {'classification__C': 1000, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 18.335s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced', n_jobs=-1,\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5378339465685491 Best GS Acc: 0.541312122367377 Best Params: {'classification__C': 0.1, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 16.824s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced', n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5107916632342038 Best GS Acc: 0.5493935929149606 Best Params: {'classification__C': 1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "Average f1 macro score:  0.5391183927041431\n",
      "\n",
      "Trait to predict:  extraversion \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb0fd660ffb342cca3fd704923095559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 13.961s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=10, class_weight='balanced', n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5330084696600534 Best GS Acc: 0.5857819135346445 Best Params: {'classification__C': 10, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 14.050s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced', n_jobs=-1,\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5277189265536723 Best GS Acc: 0.5793512070883364 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 14.976s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced', n_jobs=-1,\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5887714288508366 Best GS Acc: 0.5525977426654849 Best Params: {'classification__C': 0.1, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 14.727s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=10, class_weight='balanced', n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5876284646527561 Best GS Acc: 0.5736718507144205 Best Params: {'classification__C': 10, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 15.024s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5471615508099431 Best GS Acc: 0.5570782420232228 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "Average f1 macro score:  0.5568577681054523\n",
      "\n",
      "Trait to predict:  agreeableness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b08685217bc450a920cb6a1f79799da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 13.401s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.506809620399884 Best GS Acc: 0.5309079454311204 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 13.805s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5499534445669275 Best GS Acc: 0.4996493666516967 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 13.295s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5350137982807659 Best GS Acc: 0.5262866484162045 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 14.471s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5042471042471042 Best GS Acc: 0.5372605293833789 Best Params: {'classification__C': 0.1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 14.512s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5229334289960539 Best GS Acc: 0.5348812076285981 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "Average f1 macro score:  0.5237914792981471\n",
      "\n",
      "Trait to predict:  neuroticism \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4cd089a85934fc2aec78c82e24979c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 14.057s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.518600497048773 Best GS Acc: 0.5399961669056991 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 16.466s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5605941459152469 Best GS Acc: 0.5450187344340952 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 13.981s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced', n_jobs=-1,\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5388289197794517 Best GS Acc: 0.5663034763333817 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 16.255s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=10, class_weight='balanced', n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5631464344039194 Best GS Acc: 0.5379382739249567 Best Params: {'classification__C': 10, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 15.531s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5599105449948951 Best GS Acc: 0.5718295270310927 Best Params: {'classification__C': 0.1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "Average f1 macro score:  0.5482161084284571\n"
     ]
    }
   ],
   "source": [
    "print(\"LR with char ngrams\")\n",
    "classify_cv(log_charngrams_df, 'binary', small_clf_lst, 'anova', dim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR with wordlists\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe98f0ce266d4ccbbde16027cc848f5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:  log \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b83796d4e0f84e95a89befa7313a925e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trait to predict:  openness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d818fe175ee2488d83ac69a7adeb82c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 10.102s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=100, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5544750158127767 Best GS Acc: 0.5200156816215756 Best Params: {'classification__C': 100, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 9.670s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    max_iter=200, n_jobs=-1, solver='saga'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5411618576315297 Best GS Acc: 0.5425424587781766 Best Params: {'classification__C': 0.001, 'classification__max_iter': 200, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 6.998s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.4997170850829387 Best GS Acc: 0.5563763681341308 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 10.113s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    max_iter=1000, n_jobs=-1, solver='saga'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5348533211734305 Best GS Acc: 0.527659454758112 Best Params: {'classification__C': 0.001, 'classification__max_iter': 1000, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 6.152s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5242836255855821 Best GS Acc: 0.5488582778412391 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "Average f1 macro score:  0.5308981810572515\n",
      "\n",
      "Trait to predict:  conscientiousness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12790ad450cb49b6b9c3e90952ff1bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 9.339s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced', n_jobs=-1,\n",
      "                                    solver='saga'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5211919802800314 Best GS Acc: 0.553949653153396 Best Params: {'classification__C': 0.1, 'classification__max_iter': 100, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 7.518s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced', n_jobs=-1,\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5475231574708015 Best GS Acc: 0.5614525010448131 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 7.821s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=100, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5669150221506242 Best GS Acc: 0.5499391136610392 Best Params: {'classification__C': 100, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 8.031s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=100, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.564874121749568 Best GS Acc: 0.5541187462510713 Best Params: {'classification__C': 100, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 11.989s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1000, class_weight='balanced',\n",
      "                                    max_iter=1000, n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.540205969993204 Best GS Acc: 0.5355677165457141 Best Params: {'classification__C': 1000, 'classification__max_iter': 1000, 'classification__solver': 'lbfgs'}\n",
      "Average f1 macro score:  0.5481420503288458\n",
      "\n",
      "Trait to predict:  extraversion \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bb9bf63c3944641adaad691e0da4ccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 5.311s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5498602050326189 Best GS Acc: 0.5557718815101651 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 5.768s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced', n_jobs=-1,\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5692975532754538 Best GS Acc: 0.5593360207434144 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 4.943s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5477103718199609 Best GS Acc: 0.558764265006598 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 4.818s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.6235045742434905 Best GS Acc: 0.5627658778633382 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 4.751s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5505918289423445 Best GS Acc: 0.5808036342778327 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "Average f1 macro score:  0.5681929066627738\n",
      "\n",
      "Trait to predict:  agreeableness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7935fea5f89f42d1b05633d7077b6c53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 6.556s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=10000, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5043339015445012 Best GS Acc: 0.549911210175348 Best Params: {'classification__C': 10000, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 11.743s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=10000, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5610816326530612 Best GS Acc: 0.5097067778384801 Best Params: {'classification__C': 10000, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 8.631s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=10, class_weight='balanced', n_jobs=-1,\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5374827502232324 Best GS Acc: 0.5225389054650346 Best Params: {'classification__C': 10, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 7.267s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced', n_jobs=-1,\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5309760374050263 Best GS Acc: 0.525680801047986 Best Params: {'classification__C': 0.1, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 5.046s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced', n_jobs=-1,\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.4710112359550562 Best GS Acc: 0.531533390067257 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "Average f1 macro score:  0.5209771115561754\n",
      "\n",
      "Trait to predict:  neuroticism \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bbceeff90ea4cd99b779a871136e3ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 5.969s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5620061933840766 Best GS Acc: 0.5691438212239133 Best Params: {'classification__C': 0.1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 11.114s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.46695864124998787 Best GS Acc: 0.5738772984684515 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 10.073s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced', n_jobs=-1,\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5506649039583171 Best GS Acc: 0.5562562802560127 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 10.424s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    max_iter=1000, n_jobs=-1, solver='saga'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5419849551079834 Best GS Acc: 0.541654491374841 Best Params: {'classification__C': 0.001, 'classification__max_iter': 1000, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 6.136s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1000, class_weight='balanced',\n",
      "                                    max_iter=200, n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.6230529595015576 Best GS Acc: 0.5675381844749867 Best Params: {'classification__C': 1000, 'classification__max_iter': 200, 'classification__solver': 'lbfgs'}\n",
      "Average f1 macro score:  0.5489335306403845\n"
     ]
    }
   ],
   "source": [
    "print(\"LR with wordlists\")\n",
    "classify_cv(log_wordlists_df, 'binary', small_clf_lst, 'anova', dim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR with posts features\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "816a3ca3511d4112923a32f4e071c45c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:  log \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "395b93f3c8fc40cbb24caff2ef62547a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trait to predict:  openness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "331517e1c5e04d999e0f049463f3caa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 202.777s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=10, class_weight='balanced', max_iter=200,\n",
      "                                    n_jobs=-1, solver='saga'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5816495676716993 Best GS Acc: 0.49481883873314636 Best Params: {'classification__C': 10, 'classification__max_iter': 200, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 205.729s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=100, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.48545732639951056 Best GS Acc: 0.5032966597973922 Best Params: {'classification__C': 100, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 204.553s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=100, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.511939182452642 Best GS Acc: 0.4991284869946333 Best Params: {'classification__C': 100, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 205.648s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=100, class_weight='balanced', n_jobs=-1,\n",
      "                                    solver='saga'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.507587064676617 Best GS Acc: 0.5161943928438619 Best Params: {'classification__C': 100, 'classification__max_iter': 100, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 202.009s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=10, class_weight='balanced', n_jobs=-1,\n",
      "                                    solver='saga'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5359581594875713 Best GS Acc: 0.5177552889040429 Best Params: {'classification__C': 10, 'classification__max_iter': 100, 'classification__solver': 'saga'}\n",
      "Average f1 macro score:  0.5245182601376082\n",
      "\n",
      "Trait to predict:  conscientiousness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "774bfe7220024d3aaffcc573e263d8fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 205.590s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=100, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5974370995468041 Best GS Acc: 0.5433195770992472 Best Params: {'classification__C': 100, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 204.358s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=10, class_weight='balanced', n_jobs=-1,\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5254927385892116 Best GS Acc: 0.5417140838205505 Best Params: {'classification__C': 10, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 204.562s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=100, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.613826693296892 Best GS Acc: 0.5365918605202072 Best Params: {'classification__C': 100, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 205.845s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=100, class_weight='balanced', n_jobs=-1,\n",
      "                                    solver='saga'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.556585292344786 Best GS Acc: 0.551225876169311 Best Params: {'classification__C': 100, 'classification__max_iter': 100, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 202.065s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced', n_jobs=-1,\n",
      "                                    solver='saga'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5622928055843976 Best GS Acc: 0.5507636019412077 Best Params: {'classification__C': 1, 'classification__max_iter': 100, 'classification__solver': 'saga'}\n",
      "Average f1 macro score:  0.5711269258724183\n",
      "\n",
      "Trait to predict:  extraversion \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5464698d2dfa4a148e5535da2aebe835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 203.291s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=100, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5162871600253004 Best GS Acc: 0.48065932522227833 Best Params: {'classification__C': 100, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 201.437s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.44918550379793165 Best GS Acc: 0.5125829084647847 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 203.406s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=10000, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.4509091761177243 Best GS Acc: 0.47577341659682426 Best Params: {'classification__C': 10000, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 207.712s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.49065642528677544 Best GS Acc: 0.468767887964462 Best Params: {'classification__C': 0.1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 206.639s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    max_iter=1000, n_jobs=-1, solver='saga'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.42217998612242436 Best GS Acc: 0.5020339266457328 Best Params: {'classification__C': 0.001, 'classification__max_iter': 1000, 'classification__solver': 'saga'}\n",
      "Average f1 macro score:  0.4658436502700313\n",
      "\n",
      "Trait to predict:  agreeableness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efa35b02c08847b8aed7719c6eb25ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 202.546s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=100, class_weight='balanced', n_jobs=-1,\n",
      "                                    solver='saga'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.48299518318493656 Best GS Acc: 0.48179744230502475 Best Params: {'classification__C': 100, 'classification__max_iter': 100, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 206.083s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.498321083172147 Best GS Acc: 0.48353051515668116 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 202.192s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1000, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.49123431233018505 Best GS Acc: 0.49892097705300953 Best Params: {'classification__C': 1000, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 202.537s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=10, class_weight='balanced', n_jobs=-1,\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.48970883534136544 Best GS Acc: 0.5102441318849491 Best Params: {'classification__C': 10, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 202.967s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=10000, class_weight='balanced', n_jobs=-1,\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.552469570938484 Best GS Acc: 0.49504458271888974 Best Params: {'classification__C': 10000, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "Average f1 macro score:  0.5029457969934236\n",
      "\n",
      "Trait to predict:  neuroticism \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a0a8f01aff9458e87e9457e3f2311b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 206.039s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1000, class_weight='balanced',\n",
      "                                    max_iter=500, n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.4374563242487771 Best GS Acc: 0.48645742518671853 Best Params: {'classification__C': 1000, 'classification__max_iter': 500, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 201.402s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced', max_iter=500,\n",
      "                                    n_jobs=-1, solver='saga'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.44527649769585254 Best GS Acc: 0.4961321598427654 Best Params: {'classification__C': 1, 'classification__max_iter': 500, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 204.238s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced', n_jobs=-1,\n",
      "                                    solver='saga'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.48602215682880384 Best GS Acc: 0.47771107426637754 Best Params: {'classification__C': 1, 'classification__max_iter': 100, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 203.229s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.4897064486507302 Best GS Acc: 0.4620835118696583 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 206.162s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced', n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.4721308637701229 Best GS Acc: 0.4903387530866131 Best Params: {'classification__C': 1, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "Average f1 macro score:  0.46611845823885734\n"
     ]
    }
   ],
   "source": [
    "print(\"LR with posts features\")\n",
    "classify_cv(log_posts_df, 'binary', small_clf_lst, 'anova', dim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR with posts features but without subreddit\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7de12f8ca2454bfd9c4e0f672a3f8b3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:  log \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a8307bb6964b2abe68998a8570b24f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trait to predict:  openness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e755187973040eb9873991cafebbbdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 10.344s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced', n_jobs=-1,\n",
      "                                    solver='saga'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5123485554520038 Best GS Acc: 0.48124736817811886 Best Params: {'classification__C': 1, 'classification__max_iter': 100, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 10.182s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced', max_iter=500,\n",
      "                                    n_jobs=-1, solver='saga'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.46627449073849 Best GS Acc: 0.4805581585221609 Best Params: {'classification__C': 1, 'classification__max_iter': 500, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 10.148s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=10, class_weight='balanced', n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.48849591916051305 Best GS Acc: 0.4858618386501764 Best Params: {'classification__C': 10, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 10.381s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.468881252386407 Best GS Acc: 0.48679145598309903 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 9.835s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced', n_jobs=-1,\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.4653116281921579 Best GS Acc: 0.5044723494011946 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "Average f1 macro score:  0.4802623691859143\n",
      "\n",
      "Trait to predict:  conscientiousness \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a86a1a3d65d4e08bed5b48a2cef1c52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 10.930s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=100, class_weight='balanced',\n",
      "                                    max_iter=1000, n_jobs=-1, solver='saga'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.47995797011207975 Best GS Acc: 0.47444273862745057 Best Params: {'classification__C': 100, 'classification__max_iter': 1000, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 10.331s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=10, class_weight='balanced', max_iter=200,\n",
      "                                    n_jobs=-1, solver='saga'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5142174432497013 Best GS Acc: 0.4882318605486578 Best Params: {'classification__C': 10, 'classification__max_iter': 200, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 10.220s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    max_iter=200, n_jobs=-1, solver='saga'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.45851575221584095 Best GS Acc: 0.48956890684380283 Best Params: {'classification__C': 0.001, 'classification__max_iter': 200, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 10.200s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.4697888333910291 Best GS Acc: 0.5118187165076227 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 10.984s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=100, class_weight='balanced',\n",
      "                                    max_iter=1000, n_jobs=-1, solver='saga'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.4788538030684309 Best GS Acc: 0.5061951776528597 Best Params: {'classification__C': 100, 'classification__max_iter': 1000, 'classification__solver': 'saga'}\n",
      "Average f1 macro score:  0.48026676040741645\n",
      "\n",
      "Trait to predict:  extraversion \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e1c18d329a64723ae92b3eb6de9b2da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 10.499s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=100, class_weight='balanced',\n",
      "                                    max_iter=200, n_jobs=-1, solver='saga'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.4999803435939773 Best GS Acc: 0.5354450157062127 Best Params: {'classification__C': 100, 'classification__max_iter': 200, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 10.000s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced', n_jobs=-1,\n",
      "                                    solver='saga'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5295767539815794 Best GS Acc: 0.5360356392803642 Best Params: {'classification__C': 0.001, 'classification__max_iter': 100, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 11.305s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1000, class_weight='balanced', n_jobs=-1,\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.49459694690828016 Best GS Acc: 0.5272756375999531 Best Params: {'classification__C': 1000, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 10.466s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    max_iter=1000, n_jobs=-1, solver='saga'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.48646012174184483 Best GS Acc: 0.5179148650835721 Best Params: {'classification__C': 0.001, 'classification__max_iter': 1000, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 10.095s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=100, class_weight='balanced',\n",
      "                                    max_iter=200, n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5373198285936891 Best GS Acc: 0.5111347981923583 Best Params: {'classification__C': 100, 'classification__max_iter': 200, 'classification__solver': 'lbfgs'}\n",
      "Average f1 macro score:  0.509586798963874\n",
      "\n",
      "Trait to predict:  agreeableness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da6c0240394b4b8094ff966b4063fb93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 10.112s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced', n_jobs=-1,\n",
      "                                    solver='liblinear'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.4942815721649484 Best GS Acc: 0.47300672512892944 Best Params: {'classification__C': 1, 'classification__max_iter': 100, 'classification__solver': 'liblinear'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 10.376s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.01, class_weight='balanced',\n",
      "                                    n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.4531625781625781 Best GS Acc: 0.4808116402616188 Best Params: {'classification__C': 0.01, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 10.213s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=10, class_weight='balanced', n_jobs=-1))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.4715368137099334 Best GS Acc: 0.476733906250295 Best Params: {'classification__C': 10, 'classification__max_iter': 100, 'classification__solver': 'lbfgs'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 10.774s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=100, class_weight='balanced',\n",
      "                                    max_iter=1000, n_jobs=-1, solver='saga'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5113662711573939 Best GS Acc: 0.4643313964894866 Best Params: {'classification__C': 100, 'classification__max_iter': 1000, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 10.153s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced', n_jobs=-1,\n",
      "                                    solver='saga'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.437635924285139 Best GS Acc: 0.48331121610910877 Best Params: {'classification__C': 0.1, 'classification__max_iter': 100, 'classification__solver': 'saga'}\n",
      "Average f1 macro score:  0.4735966318959986\n",
      "\n",
      "Trait to predict:  neuroticism \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd80223e53e24e50adc9e88eebf84d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 10.279s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=1, class_weight='balanced', max_iter=500,\n",
      "                                    n_jobs=-1, solver='saga'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.47510971786833855 Best GS Acc: 0.47750225393713536 Best Params: {'classification__C': 1, 'classification__max_iter': 500, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 10.719s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=100, class_weight='balanced',\n",
      "                                    max_iter=500, n_jobs=-1, solver='saga'))])\n",
      "\tFit best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.4734998107475955 Best GS Acc: 0.49937019109342484 Best Params: {'classification__C': 100, 'classification__max_iter': 500, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 10.007s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=100, class_weight='balanced',\n",
      "                                    max_iter=200, n_jobs=-1, solver='saga'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.507745166550198 Best GS Acc: 0.4970693723286611 Best Params: {'classification__C': 100, 'classification__max_iter': 200, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n",
      "\tGrid search done in 10.077s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=0.001, class_weight='balanced',\n",
      "                                    max_iter=500, n_jobs=-1, solver='saga'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.4671035386631717 Best GS Acc: 0.5291614006018569 Best Params: {'classification__C': 0.001, 'classification__max_iter': 500, 'classification__solver': 'saga'}\n",
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGrid search done in 10.771s\n",
      "\tGet best model...\n",
      "Pipeline(steps=[('variance_threshold', VarianceThreshold()),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest(k=30)),\n",
      "                ('classification',\n",
      "                 LogisticRegression(C=10, class_weight='balanced',\n",
      "                                    max_iter=1000, n_jobs=-1, solver='saga'))])\n",
      "\tFit best model...\n",
      "Val Acc: 0.5201327949056458 Best GS Acc: 0.48632133479752004 Best Params: {'classification__C': 10, 'classification__max_iter': 1000, 'classification__solver': 'saga'}\n",
      "Average f1 macro score:  0.4887182057469898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "print(\"LR with posts features but without subreddit\")\n",
    "classify_cv(log_postswithoutsubreddits_df, 'binary', small_clf_lst, 'anova', dim=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR with posts features but without subreddit\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00471302555243b987e7a924a506aa1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:  log \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac4a3118069545e29a7a21b60f7ad123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trait to predict:  openness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ee45008568146ee829673b5802d1ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophia/ma_py/.venv/lib/python3.8/site-packages/sklearn/pipeline.py:164: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if t is None or t == 'passthrough':\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' '[0.00199603 0.00513292 0.00935525 ... 0.00608401 0.         0.        ]' (type <class 'numpy.ndarray'>) doesn't",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c5d7a20b1011>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LR with posts features but without subreddit\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclassify_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'binary'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'log'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mutual'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-9f142b1aa49e>\u001b[0m in \u001b[0;36mclassify_cv\u001b[0;34m(df, classes, clf_lst, fs, dim)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\tCreate pipeline with\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moption\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                 \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_pipeline_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0moption\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'log'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                     \u001b[0mcv_inner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-7fc2e31705b0>\u001b[0m in \u001b[0;36mcreate_pipeline_cv\u001b[0;34m(classifier, fs, dim, X, y)\u001b[0m\n\u001b[1;32m     34\u001b[0m             ])\n\u001b[1;32m     35\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         pipeline = Pipeline([\n\u001b[0m\u001b[1;32m     37\u001b[0m               \u001b[0;34m(\u001b[0m\u001b[0;34m'variance_threshold'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVarianceThreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m               \u001b[0;34m(\u001b[0m\u001b[0;34m'scaler'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ma_py/.venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ma_py/.venv/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, steps, memory, verbose)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_steps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ma_py/.venv/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_validate_steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    166\u001b[0m             if (not (hasattr(t, \"fit\") or hasattr(t, \"fit_transform\")) or not\n\u001b[1;32m    167\u001b[0m                     hasattr(t, \"transform\")):\n\u001b[0;32m--> 168\u001b[0;31m                 raise TypeError(\"All intermediate steps should be \"\n\u001b[0m\u001b[1;32m    169\u001b[0m                                 \u001b[0;34m\"transformers and implement fit and transform \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                                 \u001b[0;34m\"or be the string 'passthrough' \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' '[0.00199603 0.00513292 0.00935525 ... 0.00608401 0.         0.        ]' (type <class 'numpy.ndarray'>) doesn't"
     ]
    }
   ],
   "source": [
    "print(\"LR with posts features but without subreddit\")\n",
    "classify_cv(df, 'binary', ['log'], 'mutual', dim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR with posts features but without subreddit\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78230f7ed628479b8b25432ea27407a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:  log \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac911547aeb74cf2a53a3b25b6a565cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trait to predict:  openness \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a40a475805ca4f0987fc607ec127ae47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCreate pipeline with log ...\n",
      "\tStart grid search...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-245800a51d77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LR with posts features but without subreddit\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclassify_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'binary'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'log'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sequential'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-9f142b1aa49e>\u001b[0m in \u001b[0;36mclassify_cv\u001b[0;34m(df, classes, clf_lst, fs, dim)\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\tStart grid search...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 \u001b[0mgd_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f1_macro'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv_inner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\tGrid search done in %0.3fs\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\tGet best model...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ma_py/.venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1288\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ma_py/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ma_py/.venv/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ma_py/.venv/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ma_py/.venv/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"LR with posts features but without subreddit\")\n",
    "classify_cv(df, 'binary', ['log'], 'sequential', dim=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram of true traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of the true trait values in the classes (in %):\n",
      "\n",
      "openness \n",
      "\tBinary:  [0.2864259 0.7135741] \n",
      "\t5 classes:  [0.12515567 0.09900374 0.16874222 0.21855542 0.38854296] \n",
      "\n",
      "conscientiousness \n",
      "\tBinary:  [0.62079701 0.37920299] \n",
      "\t5 classes:  [0.3486924  0.18617684 0.17185554 0.11955168 0.17372354] \n",
      "\n",
      "extraversion \n",
      "\tBinary:  [0.64570361 0.35429639] \n",
      "\t5 classes:  [0.40161893 0.17496887 0.16562889 0.10958904 0.14819427] \n",
      "\n",
      "agreeableness \n",
      "\tBinary:  [0.56351183 0.43648817] \n",
      "\t5 classes:  [0.33125778 0.16811955 0.16998755 0.15379826 0.17683686] \n",
      "\n",
      "neuroticism \n",
      "\tBinary:  [0.49377335 0.50622665] \n",
      "\t5 classes:  [0.26027397 0.14259029 0.16998755 0.14321295 0.28393524] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def check_imbalance(df, traits):\n",
    "    length = len(df)\n",
    "    o = df['trait', 'big5_o']\n",
    "    c = df['trait', 'big5_c']\n",
    "    e = df['trait', 'big5_e']\n",
    "    a = df['trait', 'big5_a']\n",
    "    n = df['trait', 'big5_n']\n",
    "    binarylst = [o, c, e, a, n]\n",
    "    o5 = df['trait', 'big5_o_multi']\n",
    "    c5 = df['trait', 'big5_c_multi']\n",
    "    e5 = df['trait', 'big5_e_multi']\n",
    "    a5 = df['trait', 'big5_a_multi']\n",
    "    n5 = df['trait', 'big5_n_multi']\n",
    "    multilst = [o5, c5, e5, a5, n5]\n",
    "    \n",
    "    result = []\n",
    "    for trait in binarylst: \n",
    "        result.append(np.bincount(trait) / length)\n",
    "    result5 = []\n",
    "    for trait in multilst:\n",
    "        result5.append(np.bincount(trait) / len(trait))\n",
    "    \n",
    "    print(\"Distribution of the true trait values in the classes (in %):\\n\")\n",
    "    for i in range(len(traits)):\n",
    "        print(traits[i], \"\\n\\tBinary: \", result[i], \"\\n\\t5 classes: \", result5[i], \"\\n\")\n",
    "    \n",
    "#     result =np.bincount(o) / len(o)\n",
    "#     result5 =np.bincount(o5) / len(o)\n",
    "#     print(\"Openness\\n\\tBinary: \", result, \"\\n\\t5 classes: \", result5)\n",
    "\n",
    "    \n",
    "check_imbalance(df, traits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1152 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# true histogram plots\n",
    "all_hist_true(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
