{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "random.seed(32)\n",
    "from time import time, gmtime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data, only b5:\n",
    "df = pd.read_csv('/home/sophia/ma_py/pandora_bigfive.csv')\n",
    "# Import dataset authors and delete not needed columns (big five labels)\n",
    "authors = pd.read_csv('/home/sophia/ma_py/author_profiles.csv')\n",
    "bigfive = authors[['author','agreeableness','openness','conscientiousness','extraversion','neuroticism']]\n",
    "bigfive = bigfive[bigfive['openness'].notna()]\n",
    "bigfive = bigfive[bigfive['conscientiousness'].notna()]\n",
    "bigfive = bigfive[bigfive['extraversion'].notna()]\n",
    "bigfive = bigfive[bigfive['agreeableness'].notna()]\n",
    "bigfive = bigfive[bigfive['neuroticism'].notna()]\n",
    "del authors\n",
    "\n",
    "authorlst = bigfive['author'].unique()\n",
    "print(len(authorlst))\n",
    "df = df[df.author.isin(authorlst)]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# deterministic\n",
    "\n",
    "def augment_comments(df):\n",
    "    newdf = df\n",
    "    t0 = time()\n",
    "    originalauthors = df['author'].unique()\n",
    "    currentn = len(originalauthors)\n",
    "    values = np.arange(0.1, 1.0, 0.1, float)\n",
    "    print(\"Number of authors at the beginning: \", currentn)\n",
    "    for index, person in enumerate(tqdm(originalauthors)):\n",
    "#         newtime = time() - t0\n",
    "#         newtime = newtime/60\n",
    "#         print(\"Author\", index, \", time %0.1fmin\" % newtime)\n",
    "        oneauthordf = df.loc[df['author'] == person]\n",
    "        if len(oneauthordf) > 100:\n",
    "            for number in values:\n",
    "                newcomments = oneauthordf.sample(frac=number, replace=False, random_state=1)\n",
    "                newcomments.reset_index(drop=True, inplace=True)\n",
    "                newcomments['author'] = person + '_new' + str(number)\n",
    "                newdf = newdf.append(newcomments)\n",
    "        \n",
    "    mul = len(newdf['author'].unique())/len(originalauthors)\n",
    "    endtime = time() - t0\n",
    "    printtime = endtime/3600\n",
    "    print(\"\\n\\nAugmentation done in  %0.1fs\" % (time() - t0), \", in hours %0.1fh\" % printtime,\n",
    "          \"\\nNew number of authors: \", len(newdf['author'].unique()), \n",
    "          \", Multiplication factor: \", mul)\n",
    "    return newdf\n",
    "\n",
    "aug_df = augment_comments(df)\n",
    "aug_df.to_pickle(\"pandora_b5_deter.pkl\")\n",
    "aug_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in preprocessed augmented data and correct trait scores for the new authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in aug_df\n",
    "filepath = \"aug_b5feat.pkl\"\n",
    "with open(filepath, 'rb') as f:\n",
    "    aug_df = pickle.load(f)\n",
    "aug_df.name = 'augmented_df'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in authorlist\n",
    "filepath = \"originalauthors.pkl\"\n",
    "with open(filepath, 'rb') as f:\n",
    "    authors = pickle.load(f)\n",
    "\n",
    "del filepath\n",
    "del f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for original in tqdm(authors):\n",
    "    res = [idx for idx in aug_df.index if idx[0:(len(original))] == original]\n",
    "    if len(res) >1:\n",
    "        # create df with trait values of original author and multiindex\n",
    "        r = aug_df.loc[original, 'trait']\n",
    "        r = pd.DataFrame(r)\n",
    "        r = r.transpose()\n",
    "        head = 15*['trait']\n",
    "        columns = r.columns.values\n",
    "        arrays = [head] + [columns]\n",
    "        r.columns=pd.MultiIndex.from_arrays(arrays)\n",
    "        # delete original author from list\n",
    "        res.pop(0)\n",
    "        # copy the row of the original author as many times as fake authors exist\n",
    "        rows = pd.concat([r]*(len(res)))\n",
    "        # change index to fake authors' names\n",
    "        rows.index = res\n",
    "        # update aug_df such that all fake authors copy their trait values from originala uthor\n",
    "        aug_df.update(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Create pickle\")\n",
    "filepath = \"aug_b5feat_label.pkl\"\n",
    "with open(filepath, \"wb\") as f:\n",
    "    pickled = pickle.dumps(aug_df, protocol=-1)\n",
    "    f.write(pickled)\n",
    "\n",
    "del f\n",
    "del filepath\n",
    "del pickled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aug_df['trait']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split df for cv: one version with only original authors, one with only new authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_augdf = aug_df.copy()\n",
    "new_augdf = new_augdf.query('index not in @authors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Create pickle\")\n",
    "filepath = \"aug_b5feat_label_new.pkl\"\n",
    "with open(filepath, \"wb\") as f:\n",
    "    pickled = pickle.dumps(new_augdf, protocol=-1)\n",
    "    f.write(pickled)\n",
    "\n",
    "del f\n",
    "del filepath\n",
    "del pickled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_augdf = aug_df.copy()\n",
    "original_augdf = original_augdf.query('index in @authors')\n",
    "original_augdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Create pickle\")\n",
    "filepath = \"aug_b5feat_label_original.pkl\"\n",
    "with open(filepath, \"wb\") as f:\n",
    "    pickled = pickle.dumps(original_augdf, protocol=-1)\n",
    "    f.write(pickled)\n",
    "\n",
    "del f\n",
    "del filepath\n",
    "del pickled"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
